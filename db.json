{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/Resume/index.html","path":"Resume/index.html","modified":0,"renderable":0},{"_id":"themes/fexo/source/css/styles.css","path":"css/styles.css","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.eot","path":"fonts/PoiretOne-Regular.eot","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.ttf","path":"fonts/PoiretOne-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.woff","path":"fonts/PoiretOne-Regular.woff","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.eot","path":"fonts/calligraffitti-regular-webfont.eot","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.eot","path":"fonts/fontello.eot","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff2","path":"fonts/calligraffitti-regular-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.svg","path":"fonts/fontello.svg","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.ttf","path":"fonts/fontello.ttf","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.woff","path":"fonts/fontello.woff","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.woff2","path":"fonts/fontello.woff2","modified":0,"renderable":1},{"_id":"themes/fexo/source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/fexo/source/js/app.js","path":"js/app.js","modified":0,"renderable":1},{"_id":"themes/fexo/source/js/fastclick.js","path":"js/fastclick.js","modified":0,"renderable":1},{"_id":"themes/fexo/source/js/bundle.js","path":"js/bundle.js","modified":0,"renderable":1},{"_id":"themes/fexo/source/js/scroll-spy.js","path":"js/scroll-spy.js","modified":0,"renderable":1},{"_id":"themes/fexo/source/js/util.js","path":"js/util.js","modified":0,"renderable":1},{"_id":"themes/fexo/source/js/zenscroll.js","path":"js/zenscroll.js","modified":0,"renderable":1},{"_id":"themes/fexo/source/sass/styles.scss","path":"sass/styles.scss","modified":0,"renderable":1},{"_id":"themes/fexo/source/css/styles.css.map","path":"css/styles.css.map","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.ttf","path":"fonts/calligraffitti-regular-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff","path":"fonts/calligraffitti-regular-webfont.woff","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.svg","path":"fonts/PoiretOne-Regular.svg","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.svg","path":"fonts/calligraffitti-regular-webfont.svg","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.eot","path":"fonts/Lobster-Regular.eot","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.ttf","path":"fonts/Lobster-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.woff","path":"fonts/Lobster-Regular.woff","modified":0,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.svg","path":"fonts/Lobster-Regular.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"3747ab0acd1080f17ef134dd20c6502289f173d1","modified":1561271830000},{"_id":"themes/fexo/.gitignore","hash":"cb475326f4d34c639c3dc1abddc03a2539dafbc9","modified":1565962289000},{"_id":"themes/fexo/.csscomb.json","hash":"0bff596879c2556634b9a92abe5b1606dc77fd1c","modified":1565962289000},{"_id":"themes/fexo/LICENSE","hash":"db4cb5aef6072a96721b5428fdd999647c049d55","modified":1565962289000},{"_id":"themes/fexo/README.md","hash":"35cd346c229e17ed83609ee94b5d6493c4ab9982","modified":1565962289000},{"_id":"themes/fexo/_config.yml","hash":"6f126472d430cad6565e9385cd93f151c812b1e8","modified":1572246266928},{"_id":"themes/fexo/package.json","hash":"7e0642c0349ee1368304918d68c0a6a4f52aa435","modified":1565962289000},{"_id":"themes/fexo/gulpfile.js","hash":"dc8e67be9205210ca5d5776cc54ab8d76ead96a0","modified":1565962289000},{"_id":"source/category/index.md","hash":"7f7244fded59157de316a6b1ba4dbb6fc08a2a5c","modified":1565962538000},{"_id":"source/tag/index.md","hash":"bee4c19d66746750628e1e0ba397e6623a31d70a","modified":1565962536000},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1562509895000},{"_id":"source/_posts/1.md","hash":"63578958f40bbe7022a8b0e99c6b0daa6a5b5939","modified":1563638766000},{"_id":"source/Resume/index.html","hash":"832291f072cb74f8829bb96693c72b6f1c227431","modified":1565963331000},{"_id":"source/_posts/2.md","hash":"2fbd6a7bb96760d0954a13a5ac3ae7f719e69da1","modified":1563640162000},{"_id":"source/_posts/3.md","hash":"01a98e7b0a9af7cfa45b4f5d8b2dd07b22b1f0f8","modified":1571483464824},{"_id":"themes/fexo/.git/config","hash":"78a9f656fdfea85aaa63de99ef0857e7149d11d2","modified":1565962289000},{"_id":"themes/fexo/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1565962289000},{"_id":"themes/fexo/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1565962225000},{"_id":"themes/fexo/.git/index","hash":"4a340c9727780f354c8cb20e89c36036d244945e","modified":1572244953285},{"_id":"themes/fexo/.git/packed-refs","hash":"2b98cdc47325d01dd3eb8f53b033add892f8f2a4","modified":1565962289000},{"_id":"themes/fexo/layout/about.ejs","hash":"f1f06842f3fac2c7dd74811722431c5720e6cf8d","modified":1565962289000},{"_id":"themes/fexo/layout/archive.ejs","hash":"9c22251c328e937c444a9f5d4b324f97a78d324f","modified":1565962289000},{"_id":"themes/fexo/layout/category.ejs","hash":"e8c8209f74ac0c96c29dbdff38d0f43664417342","modified":1565962289000},{"_id":"themes/fexo/layout/index.ejs","hash":"9d33cd03e7a8adf8bbc124c248def36c15e681d0","modified":1565962289000},{"_id":"themes/fexo/layout/link.ejs","hash":"0144bdb1bc5f19763535b79b3302bf85bc0afbff","modified":1565962289000},{"_id":"themes/fexo/layout/layout.ejs","hash":"ae485be0f6c0c431245e0cac21dc109c9d0125e8","modified":1565962289000},{"_id":"themes/fexo/layout/post.ejs","hash":"8cf15be489f8f3c11ac0215c16cbce36c854555f","modified":1565962289000},{"_id":"themes/fexo/layout/search.ejs","hash":"8c6fc59bed1facf14dd6a48bdf8dd44452583f4d","modified":1565962289000},{"_id":"themes/fexo/layout/project.ejs","hash":"ea63f5ffda0d260b5dc2c2e852caddd082e37efa","modified":1565962289000},{"_id":"themes/fexo/layout/tag.ejs","hash":"ea8f39f11e6f8750edbf4130abf26168a403b1b4","modified":1565962289000},{"_id":"themes/fexo/languages/default.yml","hash":"1a6762d52295b0f7586f40c35e713c0fd33c2a2b","modified":1565962289000},{"_id":"themes/fexo/languages/en.yml","hash":"b58364c7dfac61eddd64510f74ca7516da48f0cf","modified":1565962289000},{"_id":"themes/fexo/languages/no.yml","hash":"bf11017d77f64fbafb9c99ac219d076b20d53afc","modified":1565962289000},{"_id":"themes/fexo/languages/zh-CN.yml","hash":"1a6762d52295b0f7586f40c35e713c0fd33c2a2b","modified":1565962289000},{"_id":"themes/fexo/languages/zh-TW.yml","hash":"6141b4c7a094c74bd9df7c08908d92b561c1a0c0","modified":1565962289000},{"_id":"themes/fexo/yarn.lock","hash":"553442f69dbb078881c16905ede3d7ac856a2603","modified":1565962289000},{"_id":"themes/fexo/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1565962225000},{"_id":"themes/fexo/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1565962225000},{"_id":"themes/fexo/.git/logs/HEAD","hash":"6ac1ae716aff9a721c76a21dfa33425f3eb85813","modified":1565962289000},{"_id":"themes/fexo/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1565962225000},{"_id":"themes/fexo/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1565962225000},{"_id":"themes/fexo/layout/_partial/article.ejs","hash":"78c95b932b2f6d80e1765907b70df918fd00d694","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/baidu-analytics.ejs","hash":"c19e4abec19c23840fff7f8a51f4aefbb2b7e8ca","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/baidu-push.ejs","hash":"6950255d74efac8811d5b05d0d7a263c3c96486d","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/load-script.ejs","hash":"4675c917548817118f4a3c5d84acc98d6c61a1d8","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/home.ejs","hash":"225b8a001c7aace46f2b39676e968e7cba9a4277","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/head.ejs","hash":"c711336c4f4f970b276a244f121fed6eb02ee804","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/style.ejs","hash":"b3a5bbed9dbdba4934e9805a6d98fb7ff3ed040c","modified":1565962289000},{"_id":"themes/fexo/source/css/styles.css","hash":"1c1062a8115827ce4b8ecd4e166abacf93e1e558","modified":1565962289000},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.eot","hash":"2a4ef0d00fb77d16e37c3da429698b029e7d2d2f","modified":1565962289000},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.ttf","hash":"2b186ce205301f7f3abd441f0372b72adcd2aee3","modified":1565962289000},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.woff","hash":"1cebcedde2c52261591bc322b176638798336a24","modified":1565962289000},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.eot","hash":"4c7bcece73621f648fa71d58fa13c28670fed8ca","modified":1565962289000},{"_id":"themes/fexo/source/fonts/fontello.eot","hash":"7732065eeaec4614e9548955d9bd30ccd7b149c1","modified":1565962289000},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff2","hash":"ba50c427166090361b0dab4c72136c7b451e86d4","modified":1565962289000},{"_id":"themes/fexo/source/fonts/fontello.svg","hash":"33a984f4482a5ba5e7bc67d82e8db63cda4e3ae1","modified":1565962289000},{"_id":"themes/fexo/source/fonts/fontello.ttf","hash":"e255d37ca14348e9a8532667a757ab552e58caff","modified":1565962289000},{"_id":"themes/fexo/source/fonts/fontello.woff","hash":"45737fea847f3942ef405f00ea4df940fbb6bbd9","modified":1565962289000},{"_id":"themes/fexo/source/fonts/fontello.woff2","hash":"1dfbc23328582f7cd9bcbe538224f6c762023e43","modified":1565962289000},{"_id":"themes/fexo/source/images/avatar.jpg","hash":"06b315b1cde634d2313044a83c40b1ac10961134","modified":1565962289000},{"_id":"themes/fexo/source/js/app.js","hash":"dca6a478f1ebfa27ea4bc36c0ab0692908705403","modified":1565962289000},{"_id":"themes/fexo/source/js/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1565962289000},{"_id":"themes/fexo/source/js/bundle.js","hash":"8b64dd44eec4521f554323fc0a1dbb07f61dc678","modified":1565962289000},{"_id":"themes/fexo/source/js/scroll-spy.js","hash":"cd7ba3d2982bc418d9eced6ef28bdcff83d4cb35","modified":1565962289000},{"_id":"themes/fexo/source/js/util.js","hash":"8136da2bec1faf5fe3e14fa436f501292fca8c07","modified":1565962289000},{"_id":"themes/fexo/source/js/zenscroll.js","hash":"bea2a3571555fdae64e8fc56f161f9a4f427b335","modified":1565962289000},{"_id":"themes/fexo/source/sass/_fontello.scss","hash":"f2d6b86bb63459884cf63e8c045fd10c827396eb","modified":1565962289000},{"_id":"themes/fexo/source/sass/_animate.scss","hash":"8de97c948cb4b9c9b7a87c0f7332ed534c378e26","modified":1565962289000},{"_id":"themes/fexo/source/sass/_base.scss","hash":"83f01dbe82e47ce781c6e7eb8a793d95d97e168b","modified":1565962289000},{"_id":"themes/fexo/source/sass/_fonts.scss","hash":"10e188d379782ae2ee10427544919557036d0137","modified":1565962289000},{"_id":"themes/fexo/source/sass/_highlight-js.scss","hash":"38a5c4d9f3a2943aff9bde1d624d710587e3bc05","modified":1565962289000},{"_id":"themes/fexo/source/sass/_common.scss","hash":"f1ad269b3c2902411dcae94a04cd27e710783de3","modified":1565962289000},{"_id":"themes/fexo/source/sass/_variable.scss","hash":"7b05581ef035a88bd1191914ff992103c7812bdf","modified":1565962289000},{"_id":"themes/fexo/source/sass/_type.scss","hash":"cc7a25654593030f5214d5adf85f12a954c373c5","modified":1565962289000},{"_id":"themes/fexo/source/sass/_normalize.scss","hash":"e58275a588bb631a37a2988145eea231ed23176b","modified":1565962289000},{"_id":"themes/fexo/source/sass/styles.scss","hash":"86ebe05d6a2931dd6fceef1e50c31ca996dc20be","modified":1565962289000},{"_id":"themes/fexo/source/css/styles.css.map","hash":"9672a4e5f8c6e9742095c1ca33f1c68b3145a7e3","modified":1565962289000},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.ttf","hash":"4688935c427ae40dcbf16523bc11d9fc10e359b5","modified":1565962289000},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff","hash":"1364845a3815740c572e29c83fd8d54f1c1ef5de","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_tag.scss","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/category.ejs","hash":"2429158ff177b8876de765498b54d0c91b3fc551","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/comments.ejs","hash":"db8c87adcf9426984b959a014cae149f4c872cb1","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/date.ejs","hash":"163fbd874481cb9e2b6da5282701a3fbaa4e367a","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/back-top.ejs","hash":"47f2b8306b901f0fffc6aa0cfa40db697a0c5aff","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/changyan.ejs","hash":"e87c5fa6db61713b63264e467e11d7fde229e1c0","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/category-box.ejs","hash":"f18e08e5c8718d5cd6672fc01e25ba457db0a385","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/donation.ejs","hash":"b81e911bca334074fb4b504673a14f2f184b8536","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/gentie.ejs","hash":"9b78a138fb93a71b481ab25c8dea2e082e5e9d6c","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/disqus.ejs","hash":"21de7498d235a52337335108fce7446e1a21ea1c","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/hypercomments.ejs","hash":"321339582edb1dd9c4e4ca13108fe494d08494fc","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/gitalk.ejs","hash":"8bd0101b6673550fe1bf161cc005fb591ee8496c","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/gitment.ejs","hash":"dda26e46ff84c896a96207ad33bb85a8f233f435","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/item-category-name.ejs","hash":"8ab52c9b5d5db1d3c1d343ecb405c4e15cd144ac","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/item-tag.ejs","hash":"1b4c4e090c33ccfd44b531a5de9af16eec266512","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/item-year.ejs","hash":"906a6aea44a30e83c4c4e449294c7e4d831c188e","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/modal.ejs","hash":"8edceb2fd6c770691bd5cf4a35236c1def8410fe","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/item-post.ejs","hash":"722e5dbde2d4683eea08f2af922358db45b253b1","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/page-header.ejs","hash":"14bad32082d87d7eeb45c0e9079e72f0ae65dbf4","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/pagination.ejs","hash":"ffbb548aee6e15cae924ee7f922f28b2403e8e45","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/prev-net.ejs","hash":"d1cb2e61814bcbd25ccb1628f99b18316e029892","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/tag-box.ejs","hash":"d648ea91ec9dc72bca80d70fbb66f7655bd0ea12","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/tag-list.ejs","hash":"8535c40b573744ced738b051383c0feca80eb0e9","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/title.ejs","hash":"e2fcdd904123186648513cfca4c7ad04921d2d57","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/toc.ejs","hash":"000be428e925f5595af29eeba37ba6111f7f6511","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/uyan.ejs","hash":"afe757c6f45d24640b22d90db6f2799000c6f994","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/toolbox.ejs","hash":"fcfcccc5b231c4050f1a665b70f7738f9d070541","modified":1565962289000},{"_id":"themes/fexo/layout/_partial/component/valine.ejs","hash":"28d537af94571dd962ca37358c86d529eb4efa5e","modified":1565962289000},{"_id":"themes/fexo/.git/refs/heads/master","hash":"669317634bd9100217f3e59fc28f976be60c4d8a","modified":1565962289000},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.svg","hash":"e21109783f218cb7849b12e867e0b775ce3fadda","modified":1565962289000},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.svg","hash":"76e1e4cee6f2b5d596c635631938ee5eb6ab3e67","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_archive.scss","hash":"fefd54282a42ebb68b711f1cfefa1f67abbde05b","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_index.scss","hash":"d9fe73a87585abad06a7dd77b67ec7ce6c24402c","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_about.scss","hash":"7d61e627ea5376390081e0b93db426ffc6c4dee8","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_category.scss","hash":"713242d10c0c8687c9e2f287f1beeb38de6cdbad","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_home.scss","hash":"b65bb069ed28fbf223c5bb7e760882f79d20fa46","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_post.scss","hash":"c6f694568af362f9fe1e7e2b9909e47303178116","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_link.scss","hash":"d3a249423c7ee88d1cb3a12e03f6c42a0a4d45a1","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_project.scss","hash":"cab0947fc9d7926a07badaa567803cc7a0968f10","modified":1565962289000},{"_id":"themes/fexo/source/sass/pages/_search.scss","hash":"fd28f01829628c9d21f9391d5067ddcd836dad13","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_back-top.scss","hash":"1c67da7007f4b9d8c65deea3d82c0f579e65f2c2","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_category-box.scss","hash":"a807145b74d1b98270ea19ae35edd25b4c448bfa","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_comments.scss","hash":"3e9b61bc08f38f947f54e942986a19a7f95ce723","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_donation.scss","hash":"d4d2d05e470978a38abf883be34ea2095132057a","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_index.scss","hash":"a741a0bfb47d0acdef12cdeb968c104bb002f86d","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_hint.scss","hash":"2812b4e10313168f2e082b740c60d64a151d94c8","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_item-post.scss","hash":"1fb2e9be2d2edbb538cfbce7c80d5847f88e2f05","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_item-category-name.scss","hash":"119840d160cd263b57e79e2099a81079d7eeee3d","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_item-title.scss","hash":"cdaca2858abc9428ef01103a7fbea8f095d856aa","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_item-year.scss","hash":"12c147dd4ab9587cd622083c86c2f6cf07d8e26a","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_modal.scss","hash":"2f0ed96df388ec28445b1ce5c6a61a0a697f9a68","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_page-header.scss","hash":"893d0595ef48323dce449ef0d17308ce02b36087","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_list-post.scss","hash":"43564f6443385bf34e15672d1477d1c7560f5563","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_pagination.scss","hash":"12c1880c518aee2e3ccf59661d01c308639f8a9e","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_toc.scss","hash":"3b4c083cb2ba4a88ca35b6d8259ee991c83b3406","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_table.scss","hash":"4899fb31d1be8d5c9c397fcbcfc2ff0c5b2e7f7f","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_prev-net.scss","hash":"634ef68823dda03bf9d42c740590581663c17351","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_tag-box.scss","hash":"7601951d09a75a7c39493bfa1b1da5ac989d9cda","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_toolbox-mobile.scss","hash":"f15b215b9bb103ee1773a01d8badd81bb7643710","modified":1565962289000},{"_id":"themes/fexo/source/sass/component/_toolbox.scss","hash":"964a480d4e7fad100463195cde2a3f67f9765c23","modified":1565962289000},{"_id":"themes/fexo/.git/objects/pack/pack-b895b8e55f5c74e89cf76ed77a148a8c6aff7574.idx","hash":"377436bf8c9aa051a738bd3fb68de3ddb9e39e2e","modified":1565962289000},{"_id":"themes/fexo/.git/logs/refs/heads/master","hash":"6ac1ae716aff9a721c76a21dfa33425f3eb85813","modified":1565962289000},{"_id":"themes/fexo/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1565962289000},{"_id":"themes/fexo/.git/logs/refs/remotes/origin/HEAD","hash":"6ac1ae716aff9a721c76a21dfa33425f3eb85813","modified":1565962289000},{"_id":"themes/fexo/source/fonts/Lobster-Regular.eot","hash":"4f0c85f63beb0d95610317e16f1d4acdd2962eee","modified":1565962289000},{"_id":"themes/fexo/source/fonts/Lobster-Regular.ttf","hash":"50a84291b7012bfdcf9ff5116d6c7aa3f257f37f","modified":1565962289000},{"_id":"themes/fexo/source/fonts/Lobster-Regular.woff","hash":"298b80b1c9f694e1a055d62a5d809863c89baf50","modified":1565962289000},{"_id":"themes/fexo/source/fonts/Lobster-Regular.svg","hash":"be1cab622c673942fb4d11a23c012227938b4792","modified":1565962289000},{"_id":"themes/fexo/.git/objects/pack/pack-b895b8e55f5c74e89cf76ed77a148a8c6aff7574.pack","hash":"7eac8dcb12aea91b2962aba5ca4c053e1d0d30c8","modified":1565962289000},{"_id":"public/search.xml","hash":"57cbdfff23a53a49c518147c22b38d08f573e6dd","modified":1572246288873},{"_id":"public/tag/index.html","hash":"232fa83d38dab8e8d6292b2bd7e927a03d616c0b","modified":1572246289071},{"_id":"public/category/index.html","hash":"910d1aaa427eef76d8c2ec55121bc297a391ff7e","modified":1572246289071},{"_id":"public/2019/07/21/2/index.html","hash":"e453d02195168c019eacd0b3c9a24caa6a57ff3b","modified":1572246289072},{"_id":"public/archives/index.html","hash":"88aa3a6f4db6287ff065776899c9fddd018698ab","modified":1572246289072},{"_id":"public/archives/2019/index.html","hash":"e6f5f87938a0c8b1ebce7b33ad334f74d6358b64","modified":1572246289072},{"_id":"public/archives/2019/07/index.html","hash":"64f0ad60ad1ba1e053c3e7db1b86061a4cc5cc7d","modified":1572246289072},{"_id":"public/archives/2019/10/index.html","hash":"c2c7f24f099712a80dd5b9b3c28998216befcf79","modified":1572246289072},{"_id":"public/categories/Search-Engine/index.html","hash":"f01a527757461d83ec227d31d5633bdc7de3a96a","modified":1572246289072},{"_id":"public/categories/paper/index.html","hash":"a36003266674a2b0800d7b740217c2103f13c9a9","modified":1572246289072},{"_id":"public/index.html","hash":"0998a7345f133321fccfa62f37704adf3a470e28","modified":1572246289072},{"_id":"public/tags/Java/index.html","hash":"af4a50f7cb1d285f05e11cbd40c80138843a1e42","modified":1572246289072},{"_id":"public/tags/Sprint-boot/index.html","hash":"8db3ffffc7af1ee8a5ef1d75663b581b8316cf75","modified":1572246289072},{"_id":"public/tags/Elasticsearch/index.html","hash":"4e598baf3f0e7bc09ee820c6acddabbc6a141e23","modified":1572246289072},{"_id":"public/tags/paper/index.html","hash":"20b55bdcba1c52fbe04ab1796aec9f6226b542f5","modified":1572246289072},{"_id":"public/tags/Db/index.html","hash":"d07c15ea9cf7c8a2fe54eafba7183a4bf968e1a3","modified":1572246289072},{"_id":"public/2019/10/19/3/index.html","hash":"4a642cce8e4a29fe9d8ea7a9ad104ad320d9620f","modified":1572246289073},{"_id":"public/2019/07/20/1/index.html","hash":"9fd08a3379f6da030b3b9ddfe59fd3d9472d5a92","modified":1572246289073},{"_id":"public/Resume/index.html","hash":"832291f072cb74f8829bb96693c72b6f1c227431","modified":1572246289083},{"_id":"public/fonts/PoiretOne-Regular.eot","hash":"2a4ef0d00fb77d16e37c3da429698b029e7d2d2f","modified":1572246289083},{"_id":"public/fonts/PoiretOne-Regular.ttf","hash":"2b186ce205301f7f3abd441f0372b72adcd2aee3","modified":1572246289083},{"_id":"public/fonts/PoiretOne-Regular.woff","hash":"1cebcedde2c52261591bc322b176638798336a24","modified":1572246289083},{"_id":"public/fonts/calligraffitti-regular-webfont.eot","hash":"4c7bcece73621f648fa71d58fa13c28670fed8ca","modified":1572246289083},{"_id":"public/fonts/fontello.eot","hash":"7732065eeaec4614e9548955d9bd30ccd7b149c1","modified":1572246289083},{"_id":"public/fonts/calligraffitti-regular-webfont.woff2","hash":"ba50c427166090361b0dab4c72136c7b451e86d4","modified":1572246289083},{"_id":"public/fonts/fontello.svg","hash":"33a984f4482a5ba5e7bc67d82e8db63cda4e3ae1","modified":1572246289083},{"_id":"public/fonts/fontello.ttf","hash":"e255d37ca14348e9a8532667a757ab552e58caff","modified":1572246289084},{"_id":"public/fonts/fontello.woff","hash":"45737fea847f3942ef405f00ea4df940fbb6bbd9","modified":1572246289084},{"_id":"public/fonts/fontello.woff2","hash":"1dfbc23328582f7cd9bcbe538224f6c762023e43","modified":1572246289084},{"_id":"public/images/avatar.jpg","hash":"06b315b1cde634d2313044a83c40b1ac10961134","modified":1572246289084},{"_id":"public/sass/styles.scss","hash":"86ebe05d6a2931dd6fceef1e50c31ca996dc20be","modified":1572246289084},{"_id":"public/fonts/calligraffitti-regular-webfont.woff","hash":"1364845a3815740c572e29c83fd8d54f1c1ef5de","modified":1572246289084},{"_id":"public/css/styles.css.map","hash":"9672a4e5f8c6e9742095c1ca33f1c68b3145a7e3","modified":1572246289088},{"_id":"public/fonts/calligraffitti-regular-webfont.ttf","hash":"4688935c427ae40dcbf16523bc11d9fc10e359b5","modified":1572246289088},{"_id":"public/js/app.js","hash":"dca6a478f1ebfa27ea4bc36c0ab0692908705403","modified":1572246289092},{"_id":"public/js/scroll-spy.js","hash":"cd7ba3d2982bc418d9eced6ef28bdcff83d4cb35","modified":1572246289093},{"_id":"public/js/util.js","hash":"8136da2bec1faf5fe3e14fa436f501292fca8c07","modified":1572246289093},{"_id":"public/fonts/PoiretOne-Regular.svg","hash":"e21109783f218cb7849b12e867e0b775ce3fadda","modified":1572246289093},{"_id":"public/fonts/calligraffitti-regular-webfont.svg","hash":"76e1e4cee6f2b5d596c635631938ee5eb6ab3e67","modified":1572246289093},{"_id":"public/js/bundle.js","hash":"8b64dd44eec4521f554323fc0a1dbb07f61dc678","modified":1572246289100},{"_id":"public/js/zenscroll.js","hash":"bea2a3571555fdae64e8fc56f161f9a4f427b335","modified":1572246289100},{"_id":"public/js/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1572246289105},{"_id":"public/css/styles.css","hash":"1c1062a8115827ce4b8ecd4e166abacf93e1e558","modified":1572246289108},{"_id":"public/fonts/Lobster-Regular.ttf","hash":"50a84291b7012bfdcf9ff5116d6c7aa3f257f37f","modified":1572246289112},{"_id":"public/fonts/Lobster-Regular.eot","hash":"4f0c85f63beb0d95610317e16f1d4acdd2962eee","modified":1572246289113},{"_id":"public/fonts/Lobster-Regular.woff","hash":"298b80b1c9f694e1a055d62a5d809863c89baf50","modified":1572246289113},{"_id":"public/fonts/Lobster-Regular.svg","hash":"be1cab622c673942fb4d11a23c012227938b4792","modified":1572246289116}],"Category":[{"name":"Search Engine","_id":"ck2a2ug0k0003viwqs8c1bs5b"},{"name":"paper","_id":"ck2a2ug1c000cviwq0ivvynbm"}],"Data":[],"Page":[{"title":"tag","layout":"tag","comments":0,"_content":"","source":"tag/index.md","raw":"---\ntitle: tag\nlayout: tag\ncomments: false\n---","date":"2019-10-28T06:39:03.869Z","updated":"2019-08-16T13:35:36.000Z","path":"tag/index.html","_id":"ck2a2ug080000viwq34zovd87","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"category","layout":"category","comments":0,"_content":"","source":"category/index.md","raw":"---\ntitle: category\nlayout: category\ncomments: false\n---\n","date":"2019-10-28T06:39:03.851Z","updated":"2019-08-16T13:35:38.000Z","path":"category/index.html","_id":"ck2a2ug0g0002viwq70i3kbc5","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"ES使用过程中遇到的坑","date":"2019-07-20T16:08:41.000Z","photos":["https://github.com/yangyueren/ChaggieSearchEngine/raw/master/pictures/1.png"],"descripotion":"A search engine.","_content":"这是大三暑假完成的一个基于Elasticsearch的搜索引擎的心得篇，十五天的时间遇到了太多的坑，在此做记录。\n<!-- more -->\n## 深度搜索引擎体会\n\n------\n\n```\n从7月5号到7月19号，历时十五天的课程结束了，深深的松了一口气，可以缓解一下身心的压力。\n这次的项目，是这三年中做的最认真的一次，从5号到18号，每天晚上两点多睡，八点多起床吃早饭来机房，这门课让我半年来不早起不吃早饭的人，养成了吃早饭的习惯，每天来机房时手机的电量有90%，晚上回去的时候还能够剩下65%，每天的上班的六个小时，不熬夜是不可能的，每天晚上都在熬夜补充新的功能，一点点从0到1搭建起自己的系统，用了6台服务器，部署了ES的集群，成果颇丰。\n```\n\n以上是一些偏离主题的碎碎念，以下是正文。\n\n我们此次项目做的是深度搜索引擎，爬取了小鸡词典、微博、b站等方面的数据，将数据清洗后存到Elasticsearch中，为了充分发挥ES的优势，我使用了三台服务器用来跑ES，一台服务器跑后端程序，另外还有两台图片搜索引擎的服务器，由队友负责搭建。\n\n这个项目的简介可以在此[github](https://github.com/yangyueren/ChaggieSearchEngine)仓库中找到，在此不做赘述，本文着重讲述遇到的问题。\n\n首先是Elasticsearch版本的问题，7.2的版本对java Springboot的支持太不友好了，maven里面找不到对7.2版本的ES的repository的插件，所以浪费了一天的时间在这个上面，期间我更换过到2.x的版本和5.x的版本，发现都不如人意，感谢其他组同学的支持，提供了解决思路，使用6.4的版本，最终解决问题。\n\n在ES部署过程中，我一开始就是部署成了集群的状态，对于后续的开发不利，因为我有一台阿里云服务器一直崩溃，所以集群也一直崩溃，而那台服务器又是主节点，在被折磨两天后毅然选择关掉那台服务器，找同学借了其他的服务器。这也拖累了后面的开发进度。如果我一开始就是先在单节点上部署，可以先进行后续的开发，等到最后再来调整服务器集群的问题，这样我在项目的个性化搜索推荐方面还可以做的更加出色。\n\n另一个坑是Springboot对ES的操作，Springboot在定义ES的索引的时候，没办法指定分词器，这就很尴尬。ES的默认分词器是英文的，对于中文的支持特特不友好。我输入的句子，他会拆分成一个个的字建立索引，这样的倒排索引，查一个句子的查询结果与预期的相关度相去甚远，归根结底是Spring自己建立索引时候我不会指定分词器，我最终选择学习ES的语法，首先配置好ES的index，只让Spring插入数据，不让他建索引，这样就解决了这个问题。\n\n另外就是在java中对ES进行数据的查询，repository有些鸡肋，很多想进行的查询都没办法用。我后来查到了一种方法，是加@Query注解，一定程度上缓解了这个问题。其次是sort的问题，我们想做多维的排序，但是ES对这个支持的不是很好，比如有300条数据hit，但是我加入了sort的排序方式，相关度很低的结果可能被拍到前面。于是我在ES中查询时候没有使用sort，但是限制了page size，50左右，然后对返回的一个page的内容进行手动排序，于是手写了多维排序的方法。\n\n为了java中的多维排序，我使用了最愚蠢的方法。我需要对time view like三个维度做多维排序，他们的排列组合有12种（3+6+6），于是我手写了12条下面的语句。\n\n```java\n/*按照view like time排序*/\nCollections.sort(modifyData, (a, b) -> {\n                    if (!a.getView().equals(b.getView())) {\n                        return b.getView() - a.getView();\n                    } else {\n                        if (!a.getLike().equals(b.getLike())) {\n                            return b.getLike() - a.getLike();\n                        } else {\n                            if (!a.getTime().equals(b.getTime())) {\n                                return compareTime(b.getTime(),a.getTime());\n                            }\n                        }\n                    }\n                    return 0;\n                });\n\n/*按照like time view排序*/\nCollections.sort(modifyData, (a, b) -> {\n                    if (!a.getLike().equals(b.getLike())) {\n                        return b.getLike() - a.getLike();\n                    } else {\n                        if (!a.getTime().equals(b.getTime())) {\n                            return compareTime(b.getTime(),a.getTime());\n                        } else {\n                            if (!a.getView().equals(b.getView())) {\n                                return b.getView() - a.getView();\n                            }\n                        }\n                    }\n\n                    return 0;\n                });\n```\n\n这是一个比较愚蠢的方法吧，但是确实解决了我的问题，能够解决问题的办法就是好方法！当然了，我也在一直思考如何有更加优美的写法。","source":"_posts/2.md","raw":"---\ntitle: ES使用过程中遇到的坑\ndate: 2019-07-21 00:08:41\nphotos: [https://github.com/yangyueren/ChaggieSearchEngine/raw/master/pictures/1.png]\ncategories:\n- Search Engine\ntags: \n- Java \n- Sprint boot\n- Elasticsearch\ndescripotion: A search engine.\n---\n这是大三暑假完成的一个基于Elasticsearch的搜索引擎的心得篇，十五天的时间遇到了太多的坑，在此做记录。\n<!-- more -->\n## 深度搜索引擎体会\n\n------\n\n```\n从7月5号到7月19号，历时十五天的课程结束了，深深的松了一口气，可以缓解一下身心的压力。\n这次的项目，是这三年中做的最认真的一次，从5号到18号，每天晚上两点多睡，八点多起床吃早饭来机房，这门课让我半年来不早起不吃早饭的人，养成了吃早饭的习惯，每天来机房时手机的电量有90%，晚上回去的时候还能够剩下65%，每天的上班的六个小时，不熬夜是不可能的，每天晚上都在熬夜补充新的功能，一点点从0到1搭建起自己的系统，用了6台服务器，部署了ES的集群，成果颇丰。\n```\n\n以上是一些偏离主题的碎碎念，以下是正文。\n\n我们此次项目做的是深度搜索引擎，爬取了小鸡词典、微博、b站等方面的数据，将数据清洗后存到Elasticsearch中，为了充分发挥ES的优势，我使用了三台服务器用来跑ES，一台服务器跑后端程序，另外还有两台图片搜索引擎的服务器，由队友负责搭建。\n\n这个项目的简介可以在此[github](https://github.com/yangyueren/ChaggieSearchEngine)仓库中找到，在此不做赘述，本文着重讲述遇到的问题。\n\n首先是Elasticsearch版本的问题，7.2的版本对java Springboot的支持太不友好了，maven里面找不到对7.2版本的ES的repository的插件，所以浪费了一天的时间在这个上面，期间我更换过到2.x的版本和5.x的版本，发现都不如人意，感谢其他组同学的支持，提供了解决思路，使用6.4的版本，最终解决问题。\n\n在ES部署过程中，我一开始就是部署成了集群的状态，对于后续的开发不利，因为我有一台阿里云服务器一直崩溃，所以集群也一直崩溃，而那台服务器又是主节点，在被折磨两天后毅然选择关掉那台服务器，找同学借了其他的服务器。这也拖累了后面的开发进度。如果我一开始就是先在单节点上部署，可以先进行后续的开发，等到最后再来调整服务器集群的问题，这样我在项目的个性化搜索推荐方面还可以做的更加出色。\n\n另一个坑是Springboot对ES的操作，Springboot在定义ES的索引的时候，没办法指定分词器，这就很尴尬。ES的默认分词器是英文的，对于中文的支持特特不友好。我输入的句子，他会拆分成一个个的字建立索引，这样的倒排索引，查一个句子的查询结果与预期的相关度相去甚远，归根结底是Spring自己建立索引时候我不会指定分词器，我最终选择学习ES的语法，首先配置好ES的index，只让Spring插入数据，不让他建索引，这样就解决了这个问题。\n\n另外就是在java中对ES进行数据的查询，repository有些鸡肋，很多想进行的查询都没办法用。我后来查到了一种方法，是加@Query注解，一定程度上缓解了这个问题。其次是sort的问题，我们想做多维的排序，但是ES对这个支持的不是很好，比如有300条数据hit，但是我加入了sort的排序方式，相关度很低的结果可能被拍到前面。于是我在ES中查询时候没有使用sort，但是限制了page size，50左右，然后对返回的一个page的内容进行手动排序，于是手写了多维排序的方法。\n\n为了java中的多维排序，我使用了最愚蠢的方法。我需要对time view like三个维度做多维排序，他们的排列组合有12种（3+6+6），于是我手写了12条下面的语句。\n\n```java\n/*按照view like time排序*/\nCollections.sort(modifyData, (a, b) -> {\n                    if (!a.getView().equals(b.getView())) {\n                        return b.getView() - a.getView();\n                    } else {\n                        if (!a.getLike().equals(b.getLike())) {\n                            return b.getLike() - a.getLike();\n                        } else {\n                            if (!a.getTime().equals(b.getTime())) {\n                                return compareTime(b.getTime(),a.getTime());\n                            }\n                        }\n                    }\n                    return 0;\n                });\n\n/*按照like time view排序*/\nCollections.sort(modifyData, (a, b) -> {\n                    if (!a.getLike().equals(b.getLike())) {\n                        return b.getLike() - a.getLike();\n                    } else {\n                        if (!a.getTime().equals(b.getTime())) {\n                            return compareTime(b.getTime(),a.getTime());\n                        } else {\n                            if (!a.getView().equals(b.getView())) {\n                                return b.getView() - a.getView();\n                            }\n                        }\n                    }\n\n                    return 0;\n                });\n```\n\n这是一个比较愚蠢的方法吧，但是确实解决了我的问题，能够解决问题的办法就是好方法！当然了，我也在一直思考如何有更加优美的写法。","slug":"2","published":1,"updated":"2019-07-20T16:29:22.000Z","comments":1,"layout":"post","link":"","_id":"ck2a2ug0a0001viwqfyyax6ai","content":"<p>这是大三暑假完成的一个基于Elasticsearch的搜索引擎的心得篇，十五天的时间遇到了太多的坑，在此做记录。<br><a id=\"more\"></a></p>\n<h2 id=\"深度搜索引擎体会\"><a href=\"#深度搜索引擎体会\" class=\"headerlink\" title=\"深度搜索引擎体会\"></a>深度搜索引擎体会</h2><hr>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">从7月5号到7月19号，历时十五天的课程结束了，深深的松了一口气，可以缓解一下身心的压力。</span><br><span class=\"line\">这次的项目，是这三年中做的最认真的一次，从5号到18号，每天晚上两点多睡，八点多起床吃早饭来机房，这门课让我半年来不早起不吃早饭的人，养成了吃早饭的习惯，每天来机房时手机的电量有90%，晚上回去的时候还能够剩下65%，每天的上班的六个小时，不熬夜是不可能的，每天晚上都在熬夜补充新的功能，一点点从0到1搭建起自己的系统，用了6台服务器，部署了ES的集群，成果颇丰。</span><br></pre></td></tr></table></figure>\n<p>以上是一些偏离主题的碎碎念，以下是正文。</p>\n<p>我们此次项目做的是深度搜索引擎，爬取了小鸡词典、微博、b站等方面的数据，将数据清洗后存到Elasticsearch中，为了充分发挥ES的优势，我使用了三台服务器用来跑ES，一台服务器跑后端程序，另外还有两台图片搜索引擎的服务器，由队友负责搭建。</p>\n<p>这个项目的简介可以在此<a href=\"https://github.com/yangyueren/ChaggieSearchEngine\" target=\"_blank\" rel=\"noopener\">github</a>仓库中找到，在此不做赘述，本文着重讲述遇到的问题。</p>\n<p>首先是Elasticsearch版本的问题，7.2的版本对java Springboot的支持太不友好了，maven里面找不到对7.2版本的ES的repository的插件，所以浪费了一天的时间在这个上面，期间我更换过到2.x的版本和5.x的版本，发现都不如人意，感谢其他组同学的支持，提供了解决思路，使用6.4的版本，最终解决问题。</p>\n<p>在ES部署过程中，我一开始就是部署成了集群的状态，对于后续的开发不利，因为我有一台阿里云服务器一直崩溃，所以集群也一直崩溃，而那台服务器又是主节点，在被折磨两天后毅然选择关掉那台服务器，找同学借了其他的服务器。这也拖累了后面的开发进度。如果我一开始就是先在单节点上部署，可以先进行后续的开发，等到最后再来调整服务器集群的问题，这样我在项目的个性化搜索推荐方面还可以做的更加出色。</p>\n<p>另一个坑是Springboot对ES的操作，Springboot在定义ES的索引的时候，没办法指定分词器，这就很尴尬。ES的默认分词器是英文的，对于中文的支持特特不友好。我输入的句子，他会拆分成一个个的字建立索引，这样的倒排索引，查一个句子的查询结果与预期的相关度相去甚远，归根结底是Spring自己建立索引时候我不会指定分词器，我最终选择学习ES的语法，首先配置好ES的index，只让Spring插入数据，不让他建索引，这样就解决了这个问题。</p>\n<p>另外就是在java中对ES进行数据的查询，repository有些鸡肋，很多想进行的查询都没办法用。我后来查到了一种方法，是加@Query注解，一定程度上缓解了这个问题。其次是sort的问题，我们想做多维的排序，但是ES对这个支持的不是很好，比如有300条数据hit，但是我加入了sort的排序方式，相关度很低的结果可能被拍到前面。于是我在ES中查询时候没有使用sort，但是限制了page size，50左右，然后对返回的一个page的内容进行手动排序，于是手写了多维排序的方法。</p>\n<p>为了java中的多维排序，我使用了最愚蠢的方法。我需要对time view like三个维度做多维排序，他们的排列组合有12种（3+6+6），于是我手写了12条下面的语句。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*按照view like time排序*/</span></span><br><span class=\"line\">Collections.sort(modifyData, (a, b) -&gt; &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (!a.getView().equals(b.getView())) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">return</span> b.getView() - a.getView();</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (!a.getLike().equals(b.getLike())) &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">return</span> b.getLike() - a.getLike();</span><br><span class=\"line\">                        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">if</span> (!a.getTime().equals(b.getTime())) &#123;</span><br><span class=\"line\">                                <span class=\"keyword\">return</span> compareTime(b.getTime(),a.getTime());</span><br><span class=\"line\">                            &#125;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">                &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*按照like time view排序*/</span></span><br><span class=\"line\">Collections.sort(modifyData, (a, b) -&gt; &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (!a.getLike().equals(b.getLike())) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">return</span> b.getLike() - a.getLike();</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (!a.getTime().equals(b.getTime())) &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">return</span> compareTime(b.getTime(),a.getTime());</span><br><span class=\"line\">                        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">if</span> (!a.getView().equals(b.getView())) &#123;</span><br><span class=\"line\">                                <span class=\"keyword\">return</span> b.getView() - a.getView();</span><br><span class=\"line\">                            &#125;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">                &#125;);</span><br></pre></td></tr></table></figure>\n<p>这是一个比较愚蠢的方法吧，但是确实解决了我的问题，能够解决问题的办法就是好方法！当然了，我也在一直思考如何有更加优美的写法。</p>\n","site":{"data":{}},"excerpt":"<p>这是大三暑假完成的一个基于Elasticsearch的搜索引擎的心得篇，十五天的时间遇到了太多的坑，在此做记录。<br>","more":"</p>\n<h2 id=\"深度搜索引擎体会\"><a href=\"#深度搜索引擎体会\" class=\"headerlink\" title=\"深度搜索引擎体会\"></a>深度搜索引擎体会</h2><hr>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">从7月5号到7月19号，历时十五天的课程结束了，深深的松了一口气，可以缓解一下身心的压力。</span><br><span class=\"line\">这次的项目，是这三年中做的最认真的一次，从5号到18号，每天晚上两点多睡，八点多起床吃早饭来机房，这门课让我半年来不早起不吃早饭的人，养成了吃早饭的习惯，每天来机房时手机的电量有90%，晚上回去的时候还能够剩下65%，每天的上班的六个小时，不熬夜是不可能的，每天晚上都在熬夜补充新的功能，一点点从0到1搭建起自己的系统，用了6台服务器，部署了ES的集群，成果颇丰。</span><br></pre></td></tr></table></figure>\n<p>以上是一些偏离主题的碎碎念，以下是正文。</p>\n<p>我们此次项目做的是深度搜索引擎，爬取了小鸡词典、微博、b站等方面的数据，将数据清洗后存到Elasticsearch中，为了充分发挥ES的优势，我使用了三台服务器用来跑ES，一台服务器跑后端程序，另外还有两台图片搜索引擎的服务器，由队友负责搭建。</p>\n<p>这个项目的简介可以在此<a href=\"https://github.com/yangyueren/ChaggieSearchEngine\" target=\"_blank\" rel=\"noopener\">github</a>仓库中找到，在此不做赘述，本文着重讲述遇到的问题。</p>\n<p>首先是Elasticsearch版本的问题，7.2的版本对java Springboot的支持太不友好了，maven里面找不到对7.2版本的ES的repository的插件，所以浪费了一天的时间在这个上面，期间我更换过到2.x的版本和5.x的版本，发现都不如人意，感谢其他组同学的支持，提供了解决思路，使用6.4的版本，最终解决问题。</p>\n<p>在ES部署过程中，我一开始就是部署成了集群的状态，对于后续的开发不利，因为我有一台阿里云服务器一直崩溃，所以集群也一直崩溃，而那台服务器又是主节点，在被折磨两天后毅然选择关掉那台服务器，找同学借了其他的服务器。这也拖累了后面的开发进度。如果我一开始就是先在单节点上部署，可以先进行后续的开发，等到最后再来调整服务器集群的问题，这样我在项目的个性化搜索推荐方面还可以做的更加出色。</p>\n<p>另一个坑是Springboot对ES的操作，Springboot在定义ES的索引的时候，没办法指定分词器，这就很尴尬。ES的默认分词器是英文的，对于中文的支持特特不友好。我输入的句子，他会拆分成一个个的字建立索引，这样的倒排索引，查一个句子的查询结果与预期的相关度相去甚远，归根结底是Spring自己建立索引时候我不会指定分词器，我最终选择学习ES的语法，首先配置好ES的index，只让Spring插入数据，不让他建索引，这样就解决了这个问题。</p>\n<p>另外就是在java中对ES进行数据的查询，repository有些鸡肋，很多想进行的查询都没办法用。我后来查到了一种方法，是加@Query注解，一定程度上缓解了这个问题。其次是sort的问题，我们想做多维的排序，但是ES对这个支持的不是很好，比如有300条数据hit，但是我加入了sort的排序方式，相关度很低的结果可能被拍到前面。于是我在ES中查询时候没有使用sort，但是限制了page size，50左右，然后对返回的一个page的内容进行手动排序，于是手写了多维排序的方法。</p>\n<p>为了java中的多维排序，我使用了最愚蠢的方法。我需要对time view like三个维度做多维排序，他们的排列组合有12种（3+6+6），于是我手写了12条下面的语句。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*按照view like time排序*/</span></span><br><span class=\"line\">Collections.sort(modifyData, (a, b) -&gt; &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (!a.getView().equals(b.getView())) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">return</span> b.getView() - a.getView();</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (!a.getLike().equals(b.getLike())) &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">return</span> b.getLike() - a.getLike();</span><br><span class=\"line\">                        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">if</span> (!a.getTime().equals(b.getTime())) &#123;</span><br><span class=\"line\">                                <span class=\"keyword\">return</span> compareTime(b.getTime(),a.getTime());</span><br><span class=\"line\">                            &#125;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">                &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*按照like time view排序*/</span></span><br><span class=\"line\">Collections.sort(modifyData, (a, b) -&gt; &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (!a.getLike().equals(b.getLike())) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">return</span> b.getLike() - a.getLike();</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (!a.getTime().equals(b.getTime())) &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">return</span> compareTime(b.getTime(),a.getTime());</span><br><span class=\"line\">                        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">if</span> (!a.getView().equals(b.getView())) &#123;</span><br><span class=\"line\">                                <span class=\"keyword\">return</span> b.getView() - a.getView();</span><br><span class=\"line\">                            &#125;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">                &#125;);</span><br></pre></td></tr></table></figure>\n<p>这是一个比较愚蠢的方法吧，但是确实解决了我的问题，能够解决问题的办法就是好方法！当然了，我也在一直思考如何有更加优美的写法。</p>"},{"title":"Clue-based Spatio-textual Query 论文笔记","date":"2019-10-19T09:08:41.000Z","photos":["https://github.com/yangyueren/ChaggieSearchEngine/raw/master/pictures/1.png"],"descripotion":"Clue-based Spatio-textual Query.","_content":"\n<!-- more -->\n\n<!-- ## Clue-based Spatio-textual Query 论文笔记\n\n基于线索的时空文本查询 -->\n\n### 1. 背景介绍\n\nPOI数据库存储了空间中各个地点的位置信息，包括地点的名称，类别，地址，地理坐标等，可以提供查询服务。\n\n这篇文章研究了如下的问题：用户想查询一个地点，但是记不清这个地点准确的信息，只能提供一些关于这个POI的线索，所以算法需要通过这些线索信息推测出这个地点。比如：用户想查询多年前去过的一个位于杭州西湖区的咖啡馆，但是他忘记了咖啡馆的名字和准确地址，只记得离这个咖啡馆200米远有一个餐馆，餐馆的左侧500米远处有一家蛋糕店。请你帮忙查出来这个咖啡馆的位置。\n\n这篇文章主要做了两方面的工作，第一是提出衡量两组POIs的相似度提高准确率，第二是提出了RSR-tree提高查询效率，最后还提出了Ensemble Method提高准确率。\n\n我们将拿到两组POI，第一组是querying POIs：$Q_R(q,N,E)$，$q$是要查的POI，$N$是clue POIs的集合(包含q自身)，$N$ = {$q,q_1,q_2.....$q_n}, $E$是clue POIs之间的连接关系。第二组是$D$：$D$是我们的POI数据库。\n\n我们需要输出与$D_R$中与$q$时空文本上下文最相似的POI $o$，也就是在$D_R$中找到与$Q_R(q,N,E)$最相匹配的一组实例 $I$, $I$ = {$o, o_1, o2 ...... o_n$} ，其中$q$与$o$匹配，$q_i$与$o_i$匹配($1<= i <= n$)，$o$即为我们所求\n\n如下图，在$Q$和region $R$中，分别标出来了每个POI的category，POI之间的距离以及方向（文章中用relative direction代替absolute direction）。\n\n<img src = \"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-141911@2x.png?raw=true\" style=\"zoom:68%\"/>\n\n\n\n以及我们需要用到的一些notations：\n\n<img src = \"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-145935@2x.png?raw=true\" style=\"zoom:60%\"/>\n\n\n\n\n\n### 2. 算法简介\n\n在本篇文章的POI查询中，我们只需关心POI的三类信息，POI的category，distance，direction。\n\n我们该如何在$R$中找到符合$Q$的一组实例呢？\n\n我会先想到暴力的方法，暴力枚举所有category相符合的实例$I$，然后衡量他们direction、distance与querying POIs的相似度，相似度最大的即为所求解：$q$对应cafe，$q_1$对应restaurant，$q_2$对应bus stop，$q_3$对应bakery。相应的，在$D_R$中我们可以按category对各个POI分类，比如cafe包括{$o, o_7, o_8, o_{16}$}，restaurant包括{$o_1,o_6,o_9, o_{15},o_{17}$}，我们可以让$q_i$分别对应$D_R(q_i.cid)$ 中的每个$o_i$，对每一种情况计算$SCsim(q, o, N, I)$ (选定与$q$对应的$o$以及与$q_i$对应的$o_i$ ($1<=i<=n$)的实例$I$，计算$N$与$I$的相似度)，选取最大的相似度的那组$I$和$o$，即为我们的解。\n\n但是相似度该如何计算，如何衡量才更有效？\n\n数据库本身的质量存在问题，甚至可能要查的$o$并不在数据库中；用户提供的clue POIs也存在质量问题。\n\n所以作者给出了一套相似度计算方法，能够显著提高查询的准确率。\n\n\n\n#### 2.1 Spatio-textual Context similarity\n\n首先作者提供了一个先验知识：Minimum Matching Requriment\n\n> Given a clue-based spatio-textual query $Q_R (q, N, E)$, if a POI $o ∈ D_R (q.cid)$ truly matches the querying POI $q$, the minimum matching requirement is that at least one clue POI $q^m ∈ N \\backslash \\lbrace q\\rbrace $has truly matching POI $o^m$ with the same category as $q^m$ in $D_R \\backslash\\lbrace o \\rbrace$.\n\n下图提供了一个例子，令$o$对应$q$，$o_1$对应$q_1$（作为$q^m$），让$o$与$q$重合，$o_1$与$q_1$重合，其他所有的点$q_i$跟着旋转，他们的distance也进行放缩，放缩因子$γ = S(|d_ E (q^m , q) − d_ E (o^m , o)|).$\n\n<img src= \"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-152406@2x.png?raw=true\" style=\"zoom:60%\"/>\n\n$d_ E (q^m , q)$是综合考虑distance和relative direction的一个距离函数，$S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $为激活函数，他们的图像如下：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-153421@2x.png?raw=true\" style=\"zoom: 60%\"/>\n\n\n\n当$q$与$o$完全重合，选出的$q^m$与$o^m$完全重合，剩余的点$q_i$再通过暴力的方法，找出符合category条件的所有Instance，计算每个Instance的$SCsim(N, I)$，最大值即为$SCsim(q, o, q^m , o^m )$的值。\n\n以下为两组POIs相似度的计算公式：\n\n> $SCsim(q, o, q^ m , o^ m ) := γ \\max\\limits _{I \\subseteq  \\phi} SCsim(N, I).$\n>\n> where $Φ$ is the set of all possible matching instances of $N$ in $D_R$ .​\n>\n> $SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i )).$\n>\n> $γ = S(|d _E (q ^m , q) − d _E (o ^m , o)|).$\n>\n> $S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $\n\n$d_E (o_i , q_i )$ is the Euclidean distance between POI $o_i$ and POI $q _i $,\n\n$τ_i$ is the number of edges linked with POI $q_ i$ in the clue,\n\n$S(d)$ is a sigmoid function to normalize distance d, and $γ$ is the scale factor of $Q$ transformation,\n\nIn particular, $d_E (q_i , o_i )$ characterises the difference between $q_i$ and $o_i$ in terms of their distances to $q$ as well as their relative directions against edge $(q, q^m )$.\n\n\n\n#### 2.2 Query Processing Algorithm\n\nAlgorithm 1:\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160246@2x.png?raw=true\" alt=7 style=\"zoom: 60%;\"/>\n\n\n\nAlgorithm 2: Algorithm 1中的matching instance非常多，所以作者改进了$SCsim(q,o,q^m,o^m)$计算算法，提出了更加有效率的Algorithm 2。\n\n算法描述：\n\n- line 3: 把$D_R(q_i.cid)$中离$q_i$最近的$o_i$放到$\\Lambda$集合中；\n- line 5: 如果$\\Lambda$集合中元素均互斥，$\\Lambda$集合即为相似度最大的Instance；\n- line 6: 返回相似度最大的Instance的value;\n- line 7:如果$\\Lambda$集合中元素不互斥，则需要对$\\Lambda$集合中的每类category，运用AugPath算法，计算出该类category下$\\Sigma _{q_i ∈T 3,o_i ∈T 4} τ i ∗ S(d_E (q_i , o_i ))$的最大值，其中 $T3 = N(cid) \\backslash \\lbrace q, q^m \\rbrace $ and $ T4 = D_R (cid) \\backslash \\lbrace o, o^m \\rbrace $ .   \n\nAugPath算法作用：make sure one to one match for this category .\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160410@2x.png?raw=true\" alt=0 style=\"zoom: 60%;\"/>\n\n\n\n\n\n### 3. 时空文本上下文索引：Roll-out-star R-tree\n\n引进RSR-tree是为了提高查询效率。\n\n以下将先介绍Roll-out-star，其次介绍在Roll-out-star下两组POIs的相似度的衡量，最后介绍使用RSR-tree进行查询的过程。\n\n#### 3.1 Roll-out-star\n\nRSR是针对一个POI $o$ , 其他的POIs都以他作为参照，用角度 $\\theta$ 和 距离 $dis$ 表示，类似于极坐标。横轴代表 $direction$， 纵轴代表 $distance$ ，如下图：\n\n注：\n\n每个POI，都有一个RSR-tree，用$o.RS$ 表示。\n\n$0度$到$360度$ 和 $360度$到$720度$ 是相同的图像，是为了计算方便，才会扩展到$720度$。\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-201140@2x.png?raw=true\" alt=\"7\" style=\"zoom:60%;\" />\n\n\n\n在RSR-tree中，使用grid cell划分区域，每个grid cell只记录落在其中的category的类别；\n\n两个RSR-tree的叠加：相应位置的grid cell中的category取并集。\n\n图例如下：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-203603@2x.png?raw=true\" style=\"zoom:70%\" />\n\n\n\n\n\n#### 3.2 Similarity Estimation\n\n\n\n对于$q$和每个$o$，我们可以构建出他们的Roll-out-star，如下图：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-220129@2x.png?raw=true\" alt=\"8\" style=\"zoom:70%;\" />\n\nUsing o.RS, the spatio-textual context similarity between q and o is estimated as follows.\n\n> $SCsim ^∗ (q, o) = \\max \\limits _{q^ m∈N \\backslash {q}, gc(q^m)∈o.RS} SCsim^∗ (q, o, gr(q^m ), gc(q^m )).$\n>\n> where\n>\n> $SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $\n>\n> $γ^∗= S(min(T5, T6)).$\n>\n> $T5 = |gr(q^m ).dist_{max} − gc(o^m ).dist_{min} |.$\n>\n> $T6 = |gr(q^m ).dist_{min} − gc(o^m ).dist_{max} |.$\n>\n> \n\n上述式子即为计算$q$与$o$的相似度。解释如下：\n\n根据Minimum Matching Requriment准则，我们需要选定一个$q^m$ , 移动$q.RS$，将$gr(q^m)$与一个grid cell $gc(q^m)$完全重合。这里可以理解为，$q.RS$是基于$q$的，我们再让$q.RS$在$o.RS$上移动使$gr(q^m)$与$gc(q^m)$完全重合，意味着选定了$q$与$o$对应，$gr(q^m)$与$gc(q^m)$对应，符合上述准则。\n\n然后在此基础上，我们对每个$gr(q_i)$在$o.RS$中找到在原始空间中离它最近的$gc(q_i)$，重命名为$gc_{imax}$，并添加到$\\Lambda_G$集合中。\n\n计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $的时候，$d_E(a_i, b_i)$是在original space 中的距离。\n\n\n\nDistance in original space is as follows.\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-230359@2x.png?raw=true\" alt=\"10\" style=\"zoom:70%;\" />\n\n\n\n\n\n#### 3.3 Roll-out-star R-Tree and Query Processing\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235400@2x.png?raw=true\" style=\"zoom:50%;\" />\n\nRSR-tree是R-tree的扩展，如上图所示。与R-tree相比，RSR-tree的节点存储中增加了$ptr$指针。在非叶节点之中 $ptr$ 指针指向 superimposed RSR-tree of all POIs under this entry（RSR的叠加详见section 3.1），并且是按category存的RSR-tree。在叶节点中，$ptr$ 指向当前POI $o$ 的Roll-out-star。\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235420@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n基于RSR-tree的查询过程解释如下：\n\n$H$是一个堆，初始化为空。\n\n1. 从根开始访问，如果$etr$ 覆盖 $R$ 区域并且 $etr.cids$ 包含 $q.cid$，计算 $etr.credit$  = $SCsim^*(q, o_{etr})$ ，并把$etr$插入到堆$H$中。\n\n2. 取出$H$中$credit$最大到$etr$，如果 $etr$是非叶节点，依次访问其$ChildNode$，重复上述过程1。如果$etr$是叶节点，赋值为$o$，并且删掉$H$中$credit$比他低的 $etr'$ .\n3. 重复2过程，直到$H$为空。\n\n\n\n\n\n\n\n###4. Ensemble Method\n\n概念：对于一个$Q_R(q,N,E)$ ，我们可以令$N \\backslash \\lbrace q \\rbrace$中的每个$q_i$分别作为querying POI (即 $q_i$代替$q$作为querying POI，$q$成为了clue POI)，所以现在一共有N个$Q_R(q,N,E)$，对于每个$Q_R(q,N,E)$，可以选取出 $\\zeta$ 个matching instance，记为$l_i$，在$l_i$中对$I_i$进行降序排名。$I$最终得分为 $Score(I) = \\Sigma _{l_i \\in L}pos(I, l_i)$\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-004012@2x.png?raw=true\" style=\"zoom:60%;\" />\n\n使用Ensemble Method有两个目的：\n\n1. 交叉验证提高准确率；\n2. 如果由于数据质量问题，truly matching POI of $q$ 不在数据库中，根据querying POIs中的时空文本关系，使用Ensemble Method仍可以找到相应的区域。\n\n\n\n\n\n### 5. 一些实验\n\n#### 5.1 数据集描述\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212049@2x.png?raw=true\" alt=\"12\" style=\"zoom:50%;\" />\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212341@2x.png?raw=true\" alt=\"13\" style=\"zoom:50%;\" />\n\n数据集取自北京地区，2005、2007、2009、2013年数据质量依次变好。\n\n实验中，使用2013年的数据，选择了100条querying POIs，每条querying POI有4个clue POIs。\n\n\n\n#### 5.2 Accuracy\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212955@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n实验中比较了Baseline 1，Baseline 2， Alg，En四种算法。\n\nBaseline 1:计算相似度时只考虑距离，不考虑方向，衡量方向的作用。 $SCsim_{bl1} (q, o) = \\Sigma _{q_i \\in N}S(d_E (q_i , o_i )).$\n\nBaseline 2:计算相似度考虑距离和方向，但是不使用sigmoid function，衡量sigmoid function的作用。\n\n$SCsim_{bl2}(q, o) = \\min \\limits _{q^m \\in N,o^m \\in D_R(q^m.cid)} SCsim_{bl2} (q, o, q^m , o^m ) $\n\n$SCsim_{bl2} (q, o, q^m , o^m ) = \\Upsilon \\min \\limits _{I \\subseteq N, o_i \\in I} \\tau_i * d_E(q_i, o_i) $\n\nAlg：上述的算法。\n\nEn：Ensemble Method。\n\n\n\nsigmoid  function where the parameter β decides the slope of curve：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214700@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214751@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n\n\n#### 5.3 Efﬁciency and RSR-tree\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214932@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n\n\nIn Fig. 15, When the number of clue POIs in a query (excluding the querying POI) increases from 1 to 10, the processing time with RSR-tree dramatically reduced by up to 10 times.\n\n\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-215049@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n\n\nIn Fig. 16(a) , from < 100, 45 > to < 5, 10 >, the number of grid cells increases by more than 800 times and the size of ﬁle maintaining the roll-outstars increase much slower as shown in Fig. 16 (a).\n\nIn Fig. 16(b) , the RSR-tree with ﬁner grid setting has better ﬁltering capability because the spatio-textual similarity estimation tends to be closer to the actual spatio-textual similarity.\n\nIn Fig. 17(a), the storage required for maintaining roll-out-stars at different settings of ξ is presented.\n\nGiven a query $Q_R (q, N, E)$, if a user believes that the distance between the querying POI $q$ and a clue POI $q_i$ is greater than ξ (the maximum value in distance dimension of roll-out-star), the query cannot be solved using the RSR-tree. In this situation, Algorithm 1 will be used.\n\n\n\n### 6. 论文贡献\n\n1. 提出了可以容忍数据质量的时空文本上下文相似度的衡量方法，一是综合考虑distance和direction，二是使用了激活函数，效果更好；\n2. 提出RSR-tree，提高了查询速度；\n3. 提出Ensemble Method，交叉验证提高准确率，即使truly matching of queyring POI不在D中，也可以找到用户想查询区域。\n4. 此问题的研究具有实际价值，并且可以扩展到三维空间和涉及到空间物体分布的研究领域。\n\n\n\n### 7. 一些证明\n\n待补充。\n\n\n\n\n\n\n\n\n\n### 8. 遗留问题\n\n\n\n#### 8.1 max的问题\n\n$Clue-based\\quad Spatio-textual\\quad Query$ 这篇文章的 $p535$  $section6 .2$ 中，计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\max \\limits_{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $ 的式子中，我觉得这个$max$函数有问题，应该是$sum$函数。\n\n理由如下：\n\n在$lemma 2$ 证明过程中，文中比较了$d_{min} (gr(q_i ), gc(q_i )) $和 $ d_E (q_i , o_i )$ [该式子在 $p533$ $SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i ))$ 中]，以及“$γ^∗$ is not less than $γ$ ”，并没有指出$sum$函数和$max$函数的引起的不同，所以我认为 $p535$ 页的式子中应该是 $sum$ 函数，这样前后就一致了。\n\n\n\n\n\n\n","source":"_posts/3.md","raw":"---\ntitle: Clue-based Spatio-textual Query 论文笔记\ndate: 2019-10-19 17:08:41\nphotos: [https://github.com/yangyueren/ChaggieSearchEngine/raw/master/pictures/1.png]\ncategories:\n- paper\ntags: \n- paper\n- Db\ndescripotion: Clue-based Spatio-textual Query.\n---\n\n<!-- more -->\n\n<!-- ## Clue-based Spatio-textual Query 论文笔记\n\n基于线索的时空文本查询 -->\n\n### 1. 背景介绍\n\nPOI数据库存储了空间中各个地点的位置信息，包括地点的名称，类别，地址，地理坐标等，可以提供查询服务。\n\n这篇文章研究了如下的问题：用户想查询一个地点，但是记不清这个地点准确的信息，只能提供一些关于这个POI的线索，所以算法需要通过这些线索信息推测出这个地点。比如：用户想查询多年前去过的一个位于杭州西湖区的咖啡馆，但是他忘记了咖啡馆的名字和准确地址，只记得离这个咖啡馆200米远有一个餐馆，餐馆的左侧500米远处有一家蛋糕店。请你帮忙查出来这个咖啡馆的位置。\n\n这篇文章主要做了两方面的工作，第一是提出衡量两组POIs的相似度提高准确率，第二是提出了RSR-tree提高查询效率，最后还提出了Ensemble Method提高准确率。\n\n我们将拿到两组POI，第一组是querying POIs：$Q_R(q,N,E)$，$q$是要查的POI，$N$是clue POIs的集合(包含q自身)，$N$ = {$q,q_1,q_2.....$q_n}, $E$是clue POIs之间的连接关系。第二组是$D$：$D$是我们的POI数据库。\n\n我们需要输出与$D_R$中与$q$时空文本上下文最相似的POI $o$，也就是在$D_R$中找到与$Q_R(q,N,E)$最相匹配的一组实例 $I$, $I$ = {$o, o_1, o2 ...... o_n$} ，其中$q$与$o$匹配，$q_i$与$o_i$匹配($1<= i <= n$)，$o$即为我们所求\n\n如下图，在$Q$和region $R$中，分别标出来了每个POI的category，POI之间的距离以及方向（文章中用relative direction代替absolute direction）。\n\n<img src = \"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-141911@2x.png?raw=true\" style=\"zoom:68%\"/>\n\n\n\n以及我们需要用到的一些notations：\n\n<img src = \"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-145935@2x.png?raw=true\" style=\"zoom:60%\"/>\n\n\n\n\n\n### 2. 算法简介\n\n在本篇文章的POI查询中，我们只需关心POI的三类信息，POI的category，distance，direction。\n\n我们该如何在$R$中找到符合$Q$的一组实例呢？\n\n我会先想到暴力的方法，暴力枚举所有category相符合的实例$I$，然后衡量他们direction、distance与querying POIs的相似度，相似度最大的即为所求解：$q$对应cafe，$q_1$对应restaurant，$q_2$对应bus stop，$q_3$对应bakery。相应的，在$D_R$中我们可以按category对各个POI分类，比如cafe包括{$o, o_7, o_8, o_{16}$}，restaurant包括{$o_1,o_6,o_9, o_{15},o_{17}$}，我们可以让$q_i$分别对应$D_R(q_i.cid)$ 中的每个$o_i$，对每一种情况计算$SCsim(q, o, N, I)$ (选定与$q$对应的$o$以及与$q_i$对应的$o_i$ ($1<=i<=n$)的实例$I$，计算$N$与$I$的相似度)，选取最大的相似度的那组$I$和$o$，即为我们的解。\n\n但是相似度该如何计算，如何衡量才更有效？\n\n数据库本身的质量存在问题，甚至可能要查的$o$并不在数据库中；用户提供的clue POIs也存在质量问题。\n\n所以作者给出了一套相似度计算方法，能够显著提高查询的准确率。\n\n\n\n#### 2.1 Spatio-textual Context similarity\n\n首先作者提供了一个先验知识：Minimum Matching Requriment\n\n> Given a clue-based spatio-textual query $Q_R (q, N, E)$, if a POI $o ∈ D_R (q.cid)$ truly matches the querying POI $q$, the minimum matching requirement is that at least one clue POI $q^m ∈ N \\backslash \\lbrace q\\rbrace $has truly matching POI $o^m$ with the same category as $q^m$ in $D_R \\backslash\\lbrace o \\rbrace$.\n\n下图提供了一个例子，令$o$对应$q$，$o_1$对应$q_1$（作为$q^m$），让$o$与$q$重合，$o_1$与$q_1$重合，其他所有的点$q_i$跟着旋转，他们的distance也进行放缩，放缩因子$γ = S(|d_ E (q^m , q) − d_ E (o^m , o)|).$\n\n<img src= \"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-152406@2x.png?raw=true\" style=\"zoom:60%\"/>\n\n$d_ E (q^m , q)$是综合考虑distance和relative direction的一个距离函数，$S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $为激活函数，他们的图像如下：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-153421@2x.png?raw=true\" style=\"zoom: 60%\"/>\n\n\n\n当$q$与$o$完全重合，选出的$q^m$与$o^m$完全重合，剩余的点$q_i$再通过暴力的方法，找出符合category条件的所有Instance，计算每个Instance的$SCsim(N, I)$，最大值即为$SCsim(q, o, q^m , o^m )$的值。\n\n以下为两组POIs相似度的计算公式：\n\n> $SCsim(q, o, q^ m , o^ m ) := γ \\max\\limits _{I \\subseteq  \\phi} SCsim(N, I).$\n>\n> where $Φ$ is the set of all possible matching instances of $N$ in $D_R$ .​\n>\n> $SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i )).$\n>\n> $γ = S(|d _E (q ^m , q) − d _E (o ^m , o)|).$\n>\n> $S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $\n\n$d_E (o_i , q_i )$ is the Euclidean distance between POI $o_i$ and POI $q _i $,\n\n$τ_i$ is the number of edges linked with POI $q_ i$ in the clue,\n\n$S(d)$ is a sigmoid function to normalize distance d, and $γ$ is the scale factor of $Q$ transformation,\n\nIn particular, $d_E (q_i , o_i )$ characterises the difference between $q_i$ and $o_i$ in terms of their distances to $q$ as well as their relative directions against edge $(q, q^m )$.\n\n\n\n#### 2.2 Query Processing Algorithm\n\nAlgorithm 1:\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160246@2x.png?raw=true\" alt=7 style=\"zoom: 60%;\"/>\n\n\n\nAlgorithm 2: Algorithm 1中的matching instance非常多，所以作者改进了$SCsim(q,o,q^m,o^m)$计算算法，提出了更加有效率的Algorithm 2。\n\n算法描述：\n\n- line 3: 把$D_R(q_i.cid)$中离$q_i$最近的$o_i$放到$\\Lambda$集合中；\n- line 5: 如果$\\Lambda$集合中元素均互斥，$\\Lambda$集合即为相似度最大的Instance；\n- line 6: 返回相似度最大的Instance的value;\n- line 7:如果$\\Lambda$集合中元素不互斥，则需要对$\\Lambda$集合中的每类category，运用AugPath算法，计算出该类category下$\\Sigma _{q_i ∈T 3,o_i ∈T 4} τ i ∗ S(d_E (q_i , o_i ))$的最大值，其中 $T3 = N(cid) \\backslash \\lbrace q, q^m \\rbrace $ and $ T4 = D_R (cid) \\backslash \\lbrace o, o^m \\rbrace $ .   \n\nAugPath算法作用：make sure one to one match for this category .\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160410@2x.png?raw=true\" alt=0 style=\"zoom: 60%;\"/>\n\n\n\n\n\n### 3. 时空文本上下文索引：Roll-out-star R-tree\n\n引进RSR-tree是为了提高查询效率。\n\n以下将先介绍Roll-out-star，其次介绍在Roll-out-star下两组POIs的相似度的衡量，最后介绍使用RSR-tree进行查询的过程。\n\n#### 3.1 Roll-out-star\n\nRSR是针对一个POI $o$ , 其他的POIs都以他作为参照，用角度 $\\theta$ 和 距离 $dis$ 表示，类似于极坐标。横轴代表 $direction$， 纵轴代表 $distance$ ，如下图：\n\n注：\n\n每个POI，都有一个RSR-tree，用$o.RS$ 表示。\n\n$0度$到$360度$ 和 $360度$到$720度$ 是相同的图像，是为了计算方便，才会扩展到$720度$。\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-201140@2x.png?raw=true\" alt=\"7\" style=\"zoom:60%;\" />\n\n\n\n在RSR-tree中，使用grid cell划分区域，每个grid cell只记录落在其中的category的类别；\n\n两个RSR-tree的叠加：相应位置的grid cell中的category取并集。\n\n图例如下：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-203603@2x.png?raw=true\" style=\"zoom:70%\" />\n\n\n\n\n\n#### 3.2 Similarity Estimation\n\n\n\n对于$q$和每个$o$，我们可以构建出他们的Roll-out-star，如下图：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-220129@2x.png?raw=true\" alt=\"8\" style=\"zoom:70%;\" />\n\nUsing o.RS, the spatio-textual context similarity between q and o is estimated as follows.\n\n> $SCsim ^∗ (q, o) = \\max \\limits _{q^ m∈N \\backslash {q}, gc(q^m)∈o.RS} SCsim^∗ (q, o, gr(q^m ), gc(q^m )).$\n>\n> where\n>\n> $SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $\n>\n> $γ^∗= S(min(T5, T6)).$\n>\n> $T5 = |gr(q^m ).dist_{max} − gc(o^m ).dist_{min} |.$\n>\n> $T6 = |gr(q^m ).dist_{min} − gc(o^m ).dist_{max} |.$\n>\n> \n\n上述式子即为计算$q$与$o$的相似度。解释如下：\n\n根据Minimum Matching Requriment准则，我们需要选定一个$q^m$ , 移动$q.RS$，将$gr(q^m)$与一个grid cell $gc(q^m)$完全重合。这里可以理解为，$q.RS$是基于$q$的，我们再让$q.RS$在$o.RS$上移动使$gr(q^m)$与$gc(q^m)$完全重合，意味着选定了$q$与$o$对应，$gr(q^m)$与$gc(q^m)$对应，符合上述准则。\n\n然后在此基础上，我们对每个$gr(q_i)$在$o.RS$中找到在原始空间中离它最近的$gc(q_i)$，重命名为$gc_{imax}$，并添加到$\\Lambda_G$集合中。\n\n计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $的时候，$d_E(a_i, b_i)$是在original space 中的距离。\n\n\n\nDistance in original space is as follows.\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-230359@2x.png?raw=true\" alt=\"10\" style=\"zoom:70%;\" />\n\n\n\n\n\n#### 3.3 Roll-out-star R-Tree and Query Processing\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235400@2x.png?raw=true\" style=\"zoom:50%;\" />\n\nRSR-tree是R-tree的扩展，如上图所示。与R-tree相比，RSR-tree的节点存储中增加了$ptr$指针。在非叶节点之中 $ptr$ 指针指向 superimposed RSR-tree of all POIs under this entry（RSR的叠加详见section 3.1），并且是按category存的RSR-tree。在叶节点中，$ptr$ 指向当前POI $o$ 的Roll-out-star。\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235420@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n基于RSR-tree的查询过程解释如下：\n\n$H$是一个堆，初始化为空。\n\n1. 从根开始访问，如果$etr$ 覆盖 $R$ 区域并且 $etr.cids$ 包含 $q.cid$，计算 $etr.credit$  = $SCsim^*(q, o_{etr})$ ，并把$etr$插入到堆$H$中。\n\n2. 取出$H$中$credit$最大到$etr$，如果 $etr$是非叶节点，依次访问其$ChildNode$，重复上述过程1。如果$etr$是叶节点，赋值为$o$，并且删掉$H$中$credit$比他低的 $etr'$ .\n3. 重复2过程，直到$H$为空。\n\n\n\n\n\n\n\n###4. Ensemble Method\n\n概念：对于一个$Q_R(q,N,E)$ ，我们可以令$N \\backslash \\lbrace q \\rbrace$中的每个$q_i$分别作为querying POI (即 $q_i$代替$q$作为querying POI，$q$成为了clue POI)，所以现在一共有N个$Q_R(q,N,E)$，对于每个$Q_R(q,N,E)$，可以选取出 $\\zeta$ 个matching instance，记为$l_i$，在$l_i$中对$I_i$进行降序排名。$I$最终得分为 $Score(I) = \\Sigma _{l_i \\in L}pos(I, l_i)$\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-004012@2x.png?raw=true\" style=\"zoom:60%;\" />\n\n使用Ensemble Method有两个目的：\n\n1. 交叉验证提高准确率；\n2. 如果由于数据质量问题，truly matching POI of $q$ 不在数据库中，根据querying POIs中的时空文本关系，使用Ensemble Method仍可以找到相应的区域。\n\n\n\n\n\n### 5. 一些实验\n\n#### 5.1 数据集描述\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212049@2x.png?raw=true\" alt=\"12\" style=\"zoom:50%;\" />\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212341@2x.png?raw=true\" alt=\"13\" style=\"zoom:50%;\" />\n\n数据集取自北京地区，2005、2007、2009、2013年数据质量依次变好。\n\n实验中，使用2013年的数据，选择了100条querying POIs，每条querying POI有4个clue POIs。\n\n\n\n#### 5.2 Accuracy\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212955@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n实验中比较了Baseline 1，Baseline 2， Alg，En四种算法。\n\nBaseline 1:计算相似度时只考虑距离，不考虑方向，衡量方向的作用。 $SCsim_{bl1} (q, o) = \\Sigma _{q_i \\in N}S(d_E (q_i , o_i )).$\n\nBaseline 2:计算相似度考虑距离和方向，但是不使用sigmoid function，衡量sigmoid function的作用。\n\n$SCsim_{bl2}(q, o) = \\min \\limits _{q^m \\in N,o^m \\in D_R(q^m.cid)} SCsim_{bl2} (q, o, q^m , o^m ) $\n\n$SCsim_{bl2} (q, o, q^m , o^m ) = \\Upsilon \\min \\limits _{I \\subseteq N, o_i \\in I} \\tau_i * d_E(q_i, o_i) $\n\nAlg：上述的算法。\n\nEn：Ensemble Method。\n\n\n\nsigmoid  function where the parameter β decides the slope of curve：\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214700@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214751@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n\n\n#### 5.3 Efﬁciency and RSR-tree\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214932@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n\n\nIn Fig. 15, When the number of clue POIs in a query (excluding the querying POI) increases from 1 to 10, the processing time with RSR-tree dramatically reduced by up to 10 times.\n\n\n\n\n\n<img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-215049@2x.png?raw=true\" style=\"zoom:50%;\" />\n\n\n\nIn Fig. 16(a) , from < 100, 45 > to < 5, 10 >, the number of grid cells increases by more than 800 times and the size of ﬁle maintaining the roll-outstars increase much slower as shown in Fig. 16 (a).\n\nIn Fig. 16(b) , the RSR-tree with ﬁner grid setting has better ﬁltering capability because the spatio-textual similarity estimation tends to be closer to the actual spatio-textual similarity.\n\nIn Fig. 17(a), the storage required for maintaining roll-out-stars at different settings of ξ is presented.\n\nGiven a query $Q_R (q, N, E)$, if a user believes that the distance between the querying POI $q$ and a clue POI $q_i$ is greater than ξ (the maximum value in distance dimension of roll-out-star), the query cannot be solved using the RSR-tree. In this situation, Algorithm 1 will be used.\n\n\n\n### 6. 论文贡献\n\n1. 提出了可以容忍数据质量的时空文本上下文相似度的衡量方法，一是综合考虑distance和direction，二是使用了激活函数，效果更好；\n2. 提出RSR-tree，提高了查询速度；\n3. 提出Ensemble Method，交叉验证提高准确率，即使truly matching of queyring POI不在D中，也可以找到用户想查询区域。\n4. 此问题的研究具有实际价值，并且可以扩展到三维空间和涉及到空间物体分布的研究领域。\n\n\n\n### 7. 一些证明\n\n待补充。\n\n\n\n\n\n\n\n\n\n### 8. 遗留问题\n\n\n\n#### 8.1 max的问题\n\n$Clue-based\\quad Spatio-textual\\quad Query$ 这篇文章的 $p535$  $section6 .2$ 中，计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\max \\limits_{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $ 的式子中，我觉得这个$max$函数有问题，应该是$sum$函数。\n\n理由如下：\n\n在$lemma 2$ 证明过程中，文中比较了$d_{min} (gr(q_i ), gc(q_i )) $和 $ d_E (q_i , o_i )$ [该式子在 $p533$ $SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i ))$ 中]，以及“$γ^∗$ is not less than $γ$ ”，并没有指出$sum$函数和$max$函数的引起的不同，所以我认为 $p535$ 页的式子中应该是 $sum$ 函数，这样前后就一致了。\n\n\n\n\n\n\n","slug":"3","published":1,"updated":"2019-10-19T11:11:04.824Z","comments":1,"layout":"post","link":"","_id":"ck2a2ug1a000bviwqq2i4qded","content":"<a id=\"more\"></a>\n<!-- ## Clue-based Spatio-textual Query 论文笔记\n\n基于线索的时空文本查询 -->\n<h3 id=\"1-背景介绍\"><a href=\"#1-背景介绍\" class=\"headerlink\" title=\"1. 背景介绍\"></a>1. 背景介绍</h3><p>POI数据库存储了空间中各个地点的位置信息，包括地点的名称，类别，地址，地理坐标等，可以提供查询服务。</p>\n<p>这篇文章研究了如下的问题：用户想查询一个地点，但是记不清这个地点准确的信息，只能提供一些关于这个POI的线索，所以算法需要通过这些线索信息推测出这个地点。比如：用户想查询多年前去过的一个位于杭州西湖区的咖啡馆，但是他忘记了咖啡馆的名字和准确地址，只记得离这个咖啡馆200米远有一个餐馆，餐馆的左侧500米远处有一家蛋糕店。请你帮忙查出来这个咖啡馆的位置。</p>\n<p>这篇文章主要做了两方面的工作，第一是提出衡量两组POIs的相似度提高准确率，第二是提出了RSR-tree提高查询效率，最后还提出了Ensemble Method提高准确率。</p>\n<p>我们将拿到两组POI，第一组是querying POIs：$Q_R(q,N,E)$，$q$是要查的POI，$N$是clue POIs的集合(包含q自身)，$N$ = {$q,q_1,q_2…..$q_n}, $E$是clue POIs之间的连接关系。第二组是$D$：$D$是我们的POI数据库。</p>\n<p>我们需要输出与$D_R$中与$q$时空文本上下文最相似的POI $o$，也就是在$D_R$中找到与$Q_R(q,N,E)$最相匹配的一组实例 $I$, $I$ = {$o, o_1, o2 …… o_n$} ，其中$q$与$o$匹配，$q_i$与$o_i$匹配($1&lt;= i &lt;= n$)，$o$即为我们所求</p>\n<p>如下图，在$Q$和region $R$中，分别标出来了每个POI的category，POI之间的距离以及方向（文章中用relative direction代替absolute direction）。</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-141911@2x.png?raw=true\" style=\"zoom:68%\"></p>\n<p>以及我们需要用到的一些notations：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-145935@2x.png?raw=true\" style=\"zoom:60%\"></p>\n<h3 id=\"2-算法简介\"><a href=\"#2-算法简介\" class=\"headerlink\" title=\"2. 算法简介\"></a>2. 算法简介</h3><p>在本篇文章的POI查询中，我们只需关心POI的三类信息，POI的category，distance，direction。</p>\n<p>我们该如何在$R$中找到符合$Q$的一组实例呢？</p>\n<p>我会先想到暴力的方法，暴力枚举所有category相符合的实例$I$，然后衡量他们direction、distance与querying POIs的相似度，相似度最大的即为所求解：$q$对应cafe，$q_1$对应restaurant，$q_2$对应bus stop，$q_3$对应bakery。相应的，在$D_R$中我们可以按category对各个POI分类，比如cafe包括{$o, o_7, o_8, o_{16}$}，restaurant包括{$o_1,o_6,o_9, o_{15},o_{17}$}，我们可以让$q_i$分别对应$D_R(q_i.cid)$ 中的每个$o_i$，对每一种情况计算$SCsim(q, o, N, I)$ (选定与$q$对应的$o$以及与$q_i$对应的$o_i$ ($1&lt;=i&lt;=n$)的实例$I$，计算$N$与$I$的相似度)，选取最大的相似度的那组$I$和$o$，即为我们的解。</p>\n<p>但是相似度该如何计算，如何衡量才更有效？</p>\n<p>数据库本身的质量存在问题，甚至可能要查的$o$并不在数据库中；用户提供的clue POIs也存在质量问题。</p>\n<p>所以作者给出了一套相似度计算方法，能够显著提高查询的准确率。</p>\n<h4 id=\"2-1-Spatio-textual-Context-similarity\"><a href=\"#2-1-Spatio-textual-Context-similarity\" class=\"headerlink\" title=\"2.1 Spatio-textual Context similarity\"></a>2.1 Spatio-textual Context similarity</h4><p>首先作者提供了一个先验知识：Minimum Matching Requriment</p>\n<blockquote>\n<p>Given a clue-based spatio-textual query $Q_R (q, N, E)$, if a POI $o ∈ D_R (q.cid)$ truly matches the querying POI $q$, the minimum matching requirement is that at least one clue POI $q^m ∈ N \\backslash \\lbrace q\\rbrace $has truly matching POI $o^m$ with the same category as $q^m$ in $D_R \\backslash\\lbrace o \\rbrace$.</p>\n</blockquote>\n<p>下图提供了一个例子，令$o$对应$q$，$o_1$对应$q_1$（作为$q^m$），让$o$与$q$重合，$o_1$与$q_1$重合，其他所有的点$q_i$跟着旋转，他们的distance也进行放缩，放缩因子$γ = S(|d_ E (q^m , q) − d_ E (o^m , o)|).$</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-152406@2x.png?raw=true\" style=\"zoom:60%\"></p>\n<p>$d_ E (q^m , q)$是综合考虑distance和relative direction的一个距离函数，$S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $为激活函数，他们的图像如下：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-153421@2x.png?raw=true\" style=\"zoom: 60%\"></p>\n<p>当$q$与$o$完全重合，选出的$q^m$与$o^m$完全重合，剩余的点$q_i$再通过暴力的方法，找出符合category条件的所有Instance，计算每个Instance的$SCsim(N, I)$，最大值即为$SCsim(q, o, q^m , o^m )$的值。</p>\n<p>以下为两组POIs相似度的计算公式：</p>\n<blockquote>\n<p>$SCsim(q, o, q^ m , o^ m ) := γ \\max\\limits _{I \\subseteq  \\phi} SCsim(N, I).$</p>\n<p>where $Φ$ is the set of all possible matching instances of $N$ in $D_R$ .​</p>\n<p>$SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i )).$</p>\n<p>$γ = S(|d _E (q ^m , q) − d _E (o ^m , o)|).$</p>\n<p>$S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $</p>\n</blockquote>\n<p>$d_E (o_i , q_i )$ is the Euclidean distance between POI $o_i$ and POI $q _i $,</p>\n<p>$τ<em>i$ is the number of edges linked with POI $q</em> i$ in the clue,</p>\n<p>$S(d)$ is a sigmoid function to normalize distance d, and $γ$ is the scale factor of $Q$ transformation,</p>\n<p>In particular, $d_E (q_i , o_i )$ characterises the difference between $q_i$ and $o_i$ in terms of their distances to $q$ as well as their relative directions against edge $(q, q^m )$.</p>\n<h4 id=\"2-2-Query-Processing-Algorithm\"><a href=\"#2-2-Query-Processing-Algorithm\" class=\"headerlink\" title=\"2.2 Query Processing Algorithm\"></a>2.2 Query Processing Algorithm</h4><p>Algorithm 1:</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160246@2x.png?raw=true\" alt=\"7\" style=\"zoom: 60%;\"></p>\n<p>Algorithm 2: Algorithm 1中的matching instance非常多，所以作者改进了$SCsim(q,o,q^m,o^m)$计算算法，提出了更加有效率的Algorithm 2。</p>\n<p>算法描述：</p>\n<ul>\n<li>line 3: 把$D_R(q_i.cid)$中离$q_i$最近的$o_i$放到$\\Lambda$集合中；</li>\n<li>line 5: 如果$\\Lambda$集合中元素均互斥，$\\Lambda$集合即为相似度最大的Instance；</li>\n<li>line 6: 返回相似度最大的Instance的value;</li>\n<li>line 7:如果$\\Lambda$集合中元素不互斥，则需要对$\\Lambda$集合中的每类category，运用AugPath算法，计算出该类category下$\\Sigma _{q_i ∈T 3,o_i ∈T 4} τ i ∗ S(d_E (q_i , o_i ))$的最大值，其中 $T3 = N(cid) \\backslash \\lbrace q, q^m \\rbrace $ and $ T4 = D_R (cid) \\backslash \\lbrace o, o^m \\rbrace $ .   </li>\n</ul>\n<p>AugPath算法作用：make sure one to one match for this category .</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160410@2x.png?raw=true\" alt=\"0\" style=\"zoom: 60%;\"></p>\n<h3 id=\"3-时空文本上下文索引：Roll-out-star-R-tree\"><a href=\"#3-时空文本上下文索引：Roll-out-star-R-tree\" class=\"headerlink\" title=\"3. 时空文本上下文索引：Roll-out-star R-tree\"></a>3. 时空文本上下文索引：Roll-out-star R-tree</h3><p>引进RSR-tree是为了提高查询效率。</p>\n<p>以下将先介绍Roll-out-star，其次介绍在Roll-out-star下两组POIs的相似度的衡量，最后介绍使用RSR-tree进行查询的过程。</p>\n<h4 id=\"3-1-Roll-out-star\"><a href=\"#3-1-Roll-out-star\" class=\"headerlink\" title=\"3.1 Roll-out-star\"></a>3.1 Roll-out-star</h4><p>RSR是针对一个POI $o$ , 其他的POIs都以他作为参照，用角度 $\\theta$ 和 距离 $dis$ 表示，类似于极坐标。横轴代表 $direction$， 纵轴代表 $distance$ ，如下图：</p>\n<p>注：</p>\n<p>每个POI，都有一个RSR-tree，用$o.RS$ 表示。</p>\n<p>$0度$到$360度$ 和 $360度$到$720度$ 是相同的图像，是为了计算方便，才会扩展到$720度$。</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-201140@2x.png?raw=true\" alt=\"7\" style=\"zoom:60%;\"></p>\n<p>在RSR-tree中，使用grid cell划分区域，每个grid cell只记录落在其中的category的类别；</p>\n<p>两个RSR-tree的叠加：相应位置的grid cell中的category取并集。</p>\n<p>图例如下：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-203603@2x.png?raw=true\" style=\"zoom:70%\"></p>\n<h4 id=\"3-2-Similarity-Estimation\"><a href=\"#3-2-Similarity-Estimation\" class=\"headerlink\" title=\"3.2 Similarity Estimation\"></a>3.2 Similarity Estimation</h4><p>对于$q$和每个$o$，我们可以构建出他们的Roll-out-star，如下图：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-220129@2x.png?raw=true\" alt=\"8\" style=\"zoom:70%;\"></p>\n<p>Using o.RS, the spatio-textual context similarity between q and o is estimated as follows.</p>\n<blockquote>\n<p>$SCsim ^∗ (q, o) = \\max \\limits _{q^ m∈N \\backslash {q}, gc(q^m)∈o.RS} SCsim^∗ (q, o, gr(q^m ), gc(q^m )).$</p>\n<p>where</p>\n<p>$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $</p>\n<p>$γ^∗= S(min(T5, T6)).$</p>\n<p>$T5 = |gr(q^m ).dist_{max} − gc(o^m ).dist_{min} |.$</p>\n<p>$T6 = |gr(q^m ).dist_{min} − gc(o^m ).dist_{max} |.$</p>\n</blockquote>\n<p>上述式子即为计算$q$与$o$的相似度。解释如下：</p>\n<p>根据Minimum Matching Requriment准则，我们需要选定一个$q^m$ , 移动$q.RS$，将$gr(q^m)$与一个grid cell $gc(q^m)$完全重合。这里可以理解为，$q.RS$是基于$q$的，我们再让$q.RS$在$o.RS$上移动使$gr(q^m)$与$gc(q^m)$完全重合，意味着选定了$q$与$o$对应，$gr(q^m)$与$gc(q^m)$对应，符合上述准则。</p>\n<p>然后在此基础上，我们对每个$gr(q_i)$在$o.RS$中找到在原始空间中离它最近的$gc(q_i)$，重命名为$gc_{imax}$，并添加到$\\Lambda_G$集合中。</p>\n<p>计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $的时候，$d_E(a_i, b_i)$是在original space 中的距离。</p>\n<p>Distance in original space is as follows.</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-230359@2x.png?raw=true\" alt=\"10\" style=\"zoom:70%;\"></p>\n<h4 id=\"3-3-Roll-out-star-R-Tree-and-Query-Processing\"><a href=\"#3-3-Roll-out-star-R-Tree-and-Query-Processing\" class=\"headerlink\" title=\"3.3 Roll-out-star R-Tree and Query Processing\"></a>3.3 Roll-out-star R-Tree and Query Processing</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235400@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>RSR-tree是R-tree的扩展，如上图所示。与R-tree相比，RSR-tree的节点存储中增加了$ptr$指针。在非叶节点之中 $ptr$ 指针指向 superimposed RSR-tree of all POIs under this entry（RSR的叠加详见section 3.1），并且是按category存的RSR-tree。在叶节点中，$ptr$ 指向当前POI $o$ 的Roll-out-star。</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235420@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>基于RSR-tree的查询过程解释如下：</p>\n<p>$H$是一个堆，初始化为空。</p>\n<ol>\n<li><p>从根开始访问，如果$etr$ 覆盖 $R$ 区域并且 $etr.cids$ 包含 $q.cid$，计算 $etr.credit$  = $SCsim^*(q, o_{etr})$ ，并把$etr$插入到堆$H$中。</p>\n</li>\n<li><p>取出$H$中$credit$最大到$etr$，如果 $etr$是非叶节点，依次访问其$ChildNode$，重复上述过程1。如果$etr$是叶节点，赋值为$o$，并且删掉$H$中$credit$比他低的 $etr’$ .</p>\n</li>\n<li>重复2过程，直到$H$为空。</li>\n</ol>\n<p>###4. Ensemble Method</p>\n<p>概念：对于一个$Q_R(q,N,E)$ ，我们可以令$N \\backslash \\lbrace q \\rbrace$中的每个$q_i$分别作为querying POI (即 $q_i$代替$q$作为querying POI，$q$成为了clue POI)，所以现在一共有N个$Q_R(q,N,E)$，对于每个$Q_R(q,N,E)$，可以选取出 $\\zeta$ 个matching instance，记为$l_i$，在$l_i$中对$I_i$进行降序排名。$I$最终得分为 $Score(I) = \\Sigma _{l_i \\in L}pos(I, l_i)$</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-004012@2x.png?raw=true\" style=\"zoom:60%;\"></p>\n<p>使用Ensemble Method有两个目的：</p>\n<ol>\n<li>交叉验证提高准确率；</li>\n<li>如果由于数据质量问题，truly matching POI of $q$ 不在数据库中，根据querying POIs中的时空文本关系，使用Ensemble Method仍可以找到相应的区域。</li>\n</ol>\n<h3 id=\"5-一些实验\"><a href=\"#5-一些实验\" class=\"headerlink\" title=\"5. 一些实验\"></a>5. 一些实验</h3><h4 id=\"5-1-数据集描述\"><a href=\"#5-1-数据集描述\" class=\"headerlink\" title=\"5.1 数据集描述\"></a>5.1 数据集描述</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212049@2x.png?raw=true\" alt=\"12\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212341@2x.png?raw=true\" alt=\"13\" style=\"zoom:50%;\"></p>\n<p>数据集取自北京地区，2005、2007、2009、2013年数据质量依次变好。</p>\n<p>实验中，使用2013年的数据，选择了100条querying POIs，每条querying POI有4个clue POIs。</p>\n<h4 id=\"5-2-Accuracy\"><a href=\"#5-2-Accuracy\" class=\"headerlink\" title=\"5.2 Accuracy\"></a>5.2 Accuracy</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212955@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>实验中比较了Baseline 1，Baseline 2， Alg，En四种算法。</p>\n<p>Baseline 1:计算相似度时只考虑距离，不考虑方向，衡量方向的作用。 $SCsim_{bl1} (q, o) = \\Sigma _{q_i \\in N}S(d_E (q_i , o_i )).$</p>\n<p>Baseline 2:计算相似度考虑距离和方向，但是不使用sigmoid function，衡量sigmoid function的作用。</p>\n<p>$SCsim_{bl2}(q, o) = \\min \\limits _{q^m \\in N,o^m \\in D_R(q^m.cid)} SCsim_{bl2} (q, o, q^m , o^m ) $</p>\n<p>$SCsim_{bl2} (q, o, q^m , o^m ) = \\Upsilon \\min \\limits _{I \\subseteq N, o_i \\in I} \\tau_i * d_E(q_i, o_i) $</p>\n<p>Alg：上述的算法。</p>\n<p>En：Ensemble Method。</p>\n<p>sigmoid  function where the parameter β decides the slope of curve：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214700@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214751@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<h4 id=\"5-3-Efﬁciency-and-RSR-tree\"><a href=\"#5-3-Efﬁciency-and-RSR-tree\" class=\"headerlink\" title=\"5.3 Efﬁciency and RSR-tree\"></a>5.3 Efﬁciency and RSR-tree</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214932@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>In Fig. 15, When the number of clue POIs in a query (excluding the querying POI) increases from 1 to 10, the processing time with RSR-tree dramatically reduced by up to 10 times.</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-215049@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>In Fig. 16(a) , from &lt; 100, 45 &gt; to &lt; 5, 10 &gt;, the number of grid cells increases by more than 800 times and the size of ﬁle maintaining the roll-outstars increase much slower as shown in Fig. 16 (a).</p>\n<p>In Fig. 16(b) , the RSR-tree with ﬁner grid setting has better ﬁltering capability because the spatio-textual similarity estimation tends to be closer to the actual spatio-textual similarity.</p>\n<p>In Fig. 17(a), the storage required for maintaining roll-out-stars at different settings of ξ is presented.</p>\n<p>Given a query $Q_R (q, N, E)$, if a user believes that the distance between the querying POI $q$ and a clue POI $q_i$ is greater than ξ (the maximum value in distance dimension of roll-out-star), the query cannot be solved using the RSR-tree. In this situation, Algorithm 1 will be used.</p>\n<h3 id=\"6-论文贡献\"><a href=\"#6-论文贡献\" class=\"headerlink\" title=\"6. 论文贡献\"></a>6. 论文贡献</h3><ol>\n<li>提出了可以容忍数据质量的时空文本上下文相似度的衡量方法，一是综合考虑distance和direction，二是使用了激活函数，效果更好；</li>\n<li>提出RSR-tree，提高了查询速度；</li>\n<li>提出Ensemble Method，交叉验证提高准确率，即使truly matching of queyring POI不在D中，也可以找到用户想查询区域。</li>\n<li>此问题的研究具有实际价值，并且可以扩展到三维空间和涉及到空间物体分布的研究领域。</li>\n</ol>\n<h3 id=\"7-一些证明\"><a href=\"#7-一些证明\" class=\"headerlink\" title=\"7. 一些证明\"></a>7. 一些证明</h3><p>待补充。</p>\n<h3 id=\"8-遗留问题\"><a href=\"#8-遗留问题\" class=\"headerlink\" title=\"8. 遗留问题\"></a>8. 遗留问题</h3><h4 id=\"8-1-max的问题\"><a href=\"#8-1-max的问题\" class=\"headerlink\" title=\"8.1 max的问题\"></a>8.1 max的问题</h4><p>$Clue-based\\quad Spatio-textual\\quad Query$ 这篇文章的 $p535$  $section6 .2$ 中，计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\max \\limits_{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $ 的式子中，我觉得这个$max$函数有问题，应该是$sum$函数。</p>\n<p>理由如下：</p>\n<p>在$lemma 2$ 证明过程中，文中比较了$d_{min} (gr(q_i ), gc(q_i )) $和 $ d_E (q_i , o_i )$ [该式子在 $p533$ $SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i ))$ 中]，以及“$γ^∗$ is not less than $γ$ ”，并没有指出$sum$函数和$max$函数的引起的不同，所以我认为 $p535$ 页的式子中应该是 $sum$ 函数，这样前后就一致了。</p>\n","site":{"data":{}},"excerpt":"","more":"<!-- ## Clue-based Spatio-textual Query 论文笔记\n\n基于线索的时空文本查询 -->\n<h3 id=\"1-背景介绍\"><a href=\"#1-背景介绍\" class=\"headerlink\" title=\"1. 背景介绍\"></a>1. 背景介绍</h3><p>POI数据库存储了空间中各个地点的位置信息，包括地点的名称，类别，地址，地理坐标等，可以提供查询服务。</p>\n<p>这篇文章研究了如下的问题：用户想查询一个地点，但是记不清这个地点准确的信息，只能提供一些关于这个POI的线索，所以算法需要通过这些线索信息推测出这个地点。比如：用户想查询多年前去过的一个位于杭州西湖区的咖啡馆，但是他忘记了咖啡馆的名字和准确地址，只记得离这个咖啡馆200米远有一个餐馆，餐馆的左侧500米远处有一家蛋糕店。请你帮忙查出来这个咖啡馆的位置。</p>\n<p>这篇文章主要做了两方面的工作，第一是提出衡量两组POIs的相似度提高准确率，第二是提出了RSR-tree提高查询效率，最后还提出了Ensemble Method提高准确率。</p>\n<p>我们将拿到两组POI，第一组是querying POIs：$Q_R(q,N,E)$，$q$是要查的POI，$N$是clue POIs的集合(包含q自身)，$N$ = {$q,q_1,q_2…..$q_n}, $E$是clue POIs之间的连接关系。第二组是$D$：$D$是我们的POI数据库。</p>\n<p>我们需要输出与$D_R$中与$q$时空文本上下文最相似的POI $o$，也就是在$D_R$中找到与$Q_R(q,N,E)$最相匹配的一组实例 $I$, $I$ = {$o, o_1, o2 …… o_n$} ，其中$q$与$o$匹配，$q_i$与$o_i$匹配($1&lt;= i &lt;= n$)，$o$即为我们所求</p>\n<p>如下图，在$Q$和region $R$中，分别标出来了每个POI的category，POI之间的距离以及方向（文章中用relative direction代替absolute direction）。</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-141911@2x.png?raw=true\" style=\"zoom:68%\"></p>\n<p>以及我们需要用到的一些notations：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-145935@2x.png?raw=true\" style=\"zoom:60%\"></p>\n<h3 id=\"2-算法简介\"><a href=\"#2-算法简介\" class=\"headerlink\" title=\"2. 算法简介\"></a>2. 算法简介</h3><p>在本篇文章的POI查询中，我们只需关心POI的三类信息，POI的category，distance，direction。</p>\n<p>我们该如何在$R$中找到符合$Q$的一组实例呢？</p>\n<p>我会先想到暴力的方法，暴力枚举所有category相符合的实例$I$，然后衡量他们direction、distance与querying POIs的相似度，相似度最大的即为所求解：$q$对应cafe，$q_1$对应restaurant，$q_2$对应bus stop，$q_3$对应bakery。相应的，在$D_R$中我们可以按category对各个POI分类，比如cafe包括{$o, o_7, o_8, o_{16}$}，restaurant包括{$o_1,o_6,o_9, o_{15},o_{17}$}，我们可以让$q_i$分别对应$D_R(q_i.cid)$ 中的每个$o_i$，对每一种情况计算$SCsim(q, o, N, I)$ (选定与$q$对应的$o$以及与$q_i$对应的$o_i$ ($1&lt;=i&lt;=n$)的实例$I$，计算$N$与$I$的相似度)，选取最大的相似度的那组$I$和$o$，即为我们的解。</p>\n<p>但是相似度该如何计算，如何衡量才更有效？</p>\n<p>数据库本身的质量存在问题，甚至可能要查的$o$并不在数据库中；用户提供的clue POIs也存在质量问题。</p>\n<p>所以作者给出了一套相似度计算方法，能够显著提高查询的准确率。</p>\n<h4 id=\"2-1-Spatio-textual-Context-similarity\"><a href=\"#2-1-Spatio-textual-Context-similarity\" class=\"headerlink\" title=\"2.1 Spatio-textual Context similarity\"></a>2.1 Spatio-textual Context similarity</h4><p>首先作者提供了一个先验知识：Minimum Matching Requriment</p>\n<blockquote>\n<p>Given a clue-based spatio-textual query $Q_R (q, N, E)$, if a POI $o ∈ D_R (q.cid)$ truly matches the querying POI $q$, the minimum matching requirement is that at least one clue POI $q^m ∈ N \\backslash \\lbrace q\\rbrace $has truly matching POI $o^m$ with the same category as $q^m$ in $D_R \\backslash\\lbrace o \\rbrace$.</p>\n</blockquote>\n<p>下图提供了一个例子，令$o$对应$q$，$o_1$对应$q_1$（作为$q^m$），让$o$与$q$重合，$o_1$与$q_1$重合，其他所有的点$q_i$跟着旋转，他们的distance也进行放缩，放缩因子$γ = S(|d_ E (q^m , q) − d_ E (o^m , o)|).$</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-152406@2x.png?raw=true\" style=\"zoom:60%\"></p>\n<p>$d_ E (q^m , q)$是综合考虑distance和relative direction的一个距离函数，$S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $为激活函数，他们的图像如下：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-153421@2x.png?raw=true\" style=\"zoom: 60%\"></p>\n<p>当$q$与$o$完全重合，选出的$q^m$与$o^m$完全重合，剩余的点$q_i$再通过暴力的方法，找出符合category条件的所有Instance，计算每个Instance的$SCsim(N, I)$，最大值即为$SCsim(q, o, q^m , o^m )$的值。</p>\n<p>以下为两组POIs相似度的计算公式：</p>\n<blockquote>\n<p>$SCsim(q, o, q^ m , o^ m ) := γ \\max\\limits _{I \\subseteq  \\phi} SCsim(N, I).$</p>\n<p>where $Φ$ is the set of all possible matching instances of $N$ in $D_R$ .​</p>\n<p>$SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i )).$</p>\n<p>$γ = S(|d _E (q ^m , q) − d _E (o ^m , o)|).$</p>\n<p>$S(d) = 2 − 2 ∗ \\cfrac{1}{1 + e^{−dβ}} $</p>\n</blockquote>\n<p>$d_E (o_i , q_i )$ is the Euclidean distance between POI $o_i$ and POI $q _i $,</p>\n<p>$τ<em>i$ is the number of edges linked with POI $q</em> i$ in the clue,</p>\n<p>$S(d)$ is a sigmoid function to normalize distance d, and $γ$ is the scale factor of $Q$ transformation,</p>\n<p>In particular, $d_E (q_i , o_i )$ characterises the difference between $q_i$ and $o_i$ in terms of their distances to $q$ as well as their relative directions against edge $(q, q^m )$.</p>\n<h4 id=\"2-2-Query-Processing-Algorithm\"><a href=\"#2-2-Query-Processing-Algorithm\" class=\"headerlink\" title=\"2.2 Query Processing Algorithm\"></a>2.2 Query Processing Algorithm</h4><p>Algorithm 1:</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160246@2x.png?raw=true\" alt=\"7\" style=\"zoom: 60%;\"></p>\n<p>Algorithm 2: Algorithm 1中的matching instance非常多，所以作者改进了$SCsim(q,o,q^m,o^m)$计算算法，提出了更加有效率的Algorithm 2。</p>\n<p>算法描述：</p>\n<ul>\n<li>line 3: 把$D_R(q_i.cid)$中离$q_i$最近的$o_i$放到$\\Lambda$集合中；</li>\n<li>line 5: 如果$\\Lambda$集合中元素均互斥，$\\Lambda$集合即为相似度最大的Instance；</li>\n<li>line 6: 返回相似度最大的Instance的value;</li>\n<li>line 7:如果$\\Lambda$集合中元素不互斥，则需要对$\\Lambda$集合中的每类category，运用AugPath算法，计算出该类category下$\\Sigma _{q_i ∈T 3,o_i ∈T 4} τ i ∗ S(d_E (q_i , o_i ))$的最大值，其中 $T3 = N(cid) \\backslash \\lbrace q, q^m \\rbrace $ and $ T4 = D_R (cid) \\backslash \\lbrace o, o^m \\rbrace $ .   </li>\n</ul>\n<p>AugPath算法作用：make sure one to one match for this category .</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-160410@2x.png?raw=true\" alt=\"0\" style=\"zoom: 60%;\"></p>\n<h3 id=\"3-时空文本上下文索引：Roll-out-star-R-tree\"><a href=\"#3-时空文本上下文索引：Roll-out-star-R-tree\" class=\"headerlink\" title=\"3. 时空文本上下文索引：Roll-out-star R-tree\"></a>3. 时空文本上下文索引：Roll-out-star R-tree</h3><p>引进RSR-tree是为了提高查询效率。</p>\n<p>以下将先介绍Roll-out-star，其次介绍在Roll-out-star下两组POIs的相似度的衡量，最后介绍使用RSR-tree进行查询的过程。</p>\n<h4 id=\"3-1-Roll-out-star\"><a href=\"#3-1-Roll-out-star\" class=\"headerlink\" title=\"3.1 Roll-out-star\"></a>3.1 Roll-out-star</h4><p>RSR是针对一个POI $o$ , 其他的POIs都以他作为参照，用角度 $\\theta$ 和 距离 $dis$ 表示，类似于极坐标。横轴代表 $direction$， 纵轴代表 $distance$ ，如下图：</p>\n<p>注：</p>\n<p>每个POI，都有一个RSR-tree，用$o.RS$ 表示。</p>\n<p>$0度$到$360度$ 和 $360度$到$720度$ 是相同的图像，是为了计算方便，才会扩展到$720度$。</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-201140@2x.png?raw=true\" alt=\"7\" style=\"zoom:60%;\"></p>\n<p>在RSR-tree中，使用grid cell划分区域，每个grid cell只记录落在其中的category的类别；</p>\n<p>两个RSR-tree的叠加：相应位置的grid cell中的category取并集。</p>\n<p>图例如下：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-203603@2x.png?raw=true\" style=\"zoom:70%\"></p>\n<h4 id=\"3-2-Similarity-Estimation\"><a href=\"#3-2-Similarity-Estimation\" class=\"headerlink\" title=\"3.2 Similarity Estimation\"></a>3.2 Similarity Estimation</h4><p>对于$q$和每个$o$，我们可以构建出他们的Roll-out-star，如下图：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-220129@2x.png?raw=true\" alt=\"8\" style=\"zoom:70%;\"></p>\n<p>Using o.RS, the spatio-textual context similarity between q and o is estimated as follows.</p>\n<blockquote>\n<p>$SCsim ^∗ (q, o) = \\max \\limits _{q^ m∈N \\backslash {q}, gc(q^m)∈o.RS} SCsim^∗ (q, o, gr(q^m ), gc(q^m )).$</p>\n<p>where</p>\n<p>$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $</p>\n<p>$γ^∗= S(min(T5, T6)).$</p>\n<p>$T5 = |gr(q^m ).dist_{max} − gc(o^m ).dist_{min} |.$</p>\n<p>$T6 = |gr(q^m ).dist_{min} − gc(o^m ).dist_{max} |.$</p>\n</blockquote>\n<p>上述式子即为计算$q$与$o$的相似度。解释如下：</p>\n<p>根据Minimum Matching Requriment准则，我们需要选定一个$q^m$ , 移动$q.RS$，将$gr(q^m)$与一个grid cell $gc(q^m)$完全重合。这里可以理解为，$q.RS$是基于$q$的，我们再让$q.RS$在$o.RS$上移动使$gr(q^m)$与$gc(q^m)$完全重合，意味着选定了$q$与$o$对应，$gr(q^m)$与$gc(q^m)$对应，符合上述准则。</p>\n<p>然后在此基础上，我们对每个$gr(q_i)$在$o.RS$中找到在原始空间中离它最近的$gc(q_i)$，重命名为$gc_{imax}$，并添加到$\\Lambda_G$集合中。</p>\n<p>计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\Sigma _{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $的时候，$d_E(a_i, b_i)$是在original space 中的距离。</p>\n<p>Distance in original space is as follows.</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-230359@2x.png?raw=true\" alt=\"10\" style=\"zoom:70%;\"></p>\n<h4 id=\"3-3-Roll-out-star-R-Tree-and-Query-Processing\"><a href=\"#3-3-Roll-out-star-R-Tree-and-Query-Processing\" class=\"headerlink\" title=\"3.3 Roll-out-star R-Tree and Query Processing\"></a>3.3 Roll-out-star R-Tree and Query Processing</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235400@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>RSR-tree是R-tree的扩展，如上图所示。与R-tree相比，RSR-tree的节点存储中增加了$ptr$指针。在非叶节点之中 $ptr$ 指针指向 superimposed RSR-tree of all POIs under this entry（RSR的叠加详见section 3.1），并且是按category存的RSR-tree。在叶节点中，$ptr$ 指向当前POI $o$ 的Roll-out-star。</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191017-235420@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>基于RSR-tree的查询过程解释如下：</p>\n<p>$H$是一个堆，初始化为空。</p>\n<ol>\n<li><p>从根开始访问，如果$etr$ 覆盖 $R$ 区域并且 $etr.cids$ 包含 $q.cid$，计算 $etr.credit$  = $SCsim^*(q, o_{etr})$ ，并把$etr$插入到堆$H$中。</p>\n</li>\n<li><p>取出$H$中$credit$最大到$etr$，如果 $etr$是非叶节点，依次访问其$ChildNode$，重复上述过程1。如果$etr$是叶节点，赋值为$o$，并且删掉$H$中$credit$比他低的 $etr’$ .</p>\n</li>\n<li>重复2过程，直到$H$为空。</li>\n</ol>\n<p>###4. Ensemble Method</p>\n<p>概念：对于一个$Q_R(q,N,E)$ ，我们可以令$N \\backslash \\lbrace q \\rbrace$中的每个$q_i$分别作为querying POI (即 $q_i$代替$q$作为querying POI，$q$成为了clue POI)，所以现在一共有N个$Q_R(q,N,E)$，对于每个$Q_R(q,N,E)$，可以选取出 $\\zeta$ 个matching instance，记为$l_i$，在$l_i$中对$I_i$进行降序排名。$I$最终得分为 $Score(I) = \\Sigma _{l_i \\in L}pos(I, l_i)$</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-004012@2x.png?raw=true\" style=\"zoom:60%;\"></p>\n<p>使用Ensemble Method有两个目的：</p>\n<ol>\n<li>交叉验证提高准确率；</li>\n<li>如果由于数据质量问题，truly matching POI of $q$ 不在数据库中，根据querying POIs中的时空文本关系，使用Ensemble Method仍可以找到相应的区域。</li>\n</ol>\n<h3 id=\"5-一些实验\"><a href=\"#5-一些实验\" class=\"headerlink\" title=\"5. 一些实验\"></a>5. 一些实验</h3><h4 id=\"5-1-数据集描述\"><a href=\"#5-1-数据集描述\" class=\"headerlink\" title=\"5.1 数据集描述\"></a>5.1 数据集描述</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212049@2x.png?raw=true\" alt=\"12\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212341@2x.png?raw=true\" alt=\"13\" style=\"zoom:50%;\"></p>\n<p>数据集取自北京地区，2005、2007、2009、2013年数据质量依次变好。</p>\n<p>实验中，使用2013年的数据，选择了100条querying POIs，每条querying POI有4个clue POIs。</p>\n<h4 id=\"5-2-Accuracy\"><a href=\"#5-2-Accuracy\" class=\"headerlink\" title=\"5.2 Accuracy\"></a>5.2 Accuracy</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-212955@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>实验中比较了Baseline 1，Baseline 2， Alg，En四种算法。</p>\n<p>Baseline 1:计算相似度时只考虑距离，不考虑方向，衡量方向的作用。 $SCsim_{bl1} (q, o) = \\Sigma _{q_i \\in N}S(d_E (q_i , o_i )).$</p>\n<p>Baseline 2:计算相似度考虑距离和方向，但是不使用sigmoid function，衡量sigmoid function的作用。</p>\n<p>$SCsim_{bl2}(q, o) = \\min \\limits _{q^m \\in N,o^m \\in D_R(q^m.cid)} SCsim_{bl2} (q, o, q^m , o^m ) $</p>\n<p>$SCsim_{bl2} (q, o, q^m , o^m ) = \\Upsilon \\min \\limits _{I \\subseteq N, o_i \\in I} \\tau_i * d_E(q_i, o_i) $</p>\n<p>Alg：上述的算法。</p>\n<p>En：Ensemble Method。</p>\n<p>sigmoid  function where the parameter β decides the slope of curve：</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214700@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214751@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<h4 id=\"5-3-Efﬁciency-and-RSR-tree\"><a href=\"#5-3-Efﬁciency-and-RSR-tree\" class=\"headerlink\" title=\"5.3 Efﬁciency and RSR-tree\"></a>5.3 Efﬁciency and RSR-tree</h4><p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-214932@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>In Fig. 15, When the number of clue POIs in a query (excluding the querying POI) increases from 1 to 10, the processing time with RSR-tree dramatically reduced by up to 10 times.</p>\n<p><img src=\"https://github.com/yangyueren/Pictures/blob/master/clue_based_query/WX20191018-215049@2x.png?raw=true\" style=\"zoom:50%;\"></p>\n<p>In Fig. 16(a) , from &lt; 100, 45 &gt; to &lt; 5, 10 &gt;, the number of grid cells increases by more than 800 times and the size of ﬁle maintaining the roll-outstars increase much slower as shown in Fig. 16 (a).</p>\n<p>In Fig. 16(b) , the RSR-tree with ﬁner grid setting has better ﬁltering capability because the spatio-textual similarity estimation tends to be closer to the actual spatio-textual similarity.</p>\n<p>In Fig. 17(a), the storage required for maintaining roll-out-stars at different settings of ξ is presented.</p>\n<p>Given a query $Q_R (q, N, E)$, if a user believes that the distance between the querying POI $q$ and a clue POI $q_i$ is greater than ξ (the maximum value in distance dimension of roll-out-star), the query cannot be solved using the RSR-tree. In this situation, Algorithm 1 will be used.</p>\n<h3 id=\"6-论文贡献\"><a href=\"#6-论文贡献\" class=\"headerlink\" title=\"6. 论文贡献\"></a>6. 论文贡献</h3><ol>\n<li>提出了可以容忍数据质量的时空文本上下文相似度的衡量方法，一是综合考虑distance和direction，二是使用了激活函数，效果更好；</li>\n<li>提出RSR-tree，提高了查询速度；</li>\n<li>提出Ensemble Method，交叉验证提高准确率，即使truly matching of queyring POI不在D中，也可以找到用户想查询区域。</li>\n<li>此问题的研究具有实际价值，并且可以扩展到三维空间和涉及到空间物体分布的研究领域。</li>\n</ol>\n<h3 id=\"7-一些证明\"><a href=\"#7-一些证明\" class=\"headerlink\" title=\"7. 一些证明\"></a>7. 一些证明</h3><p>待补充。</p>\n<h3 id=\"8-遗留问题\"><a href=\"#8-遗留问题\" class=\"headerlink\" title=\"8. 遗留问题\"></a>8. 遗留问题</h3><h4 id=\"8-1-max的问题\"><a href=\"#8-1-max的问题\" class=\"headerlink\" title=\"8.1 max的问题\"></a>8.1 max的问题</h4><p>$Clue-based\\quad Spatio-textual\\quad Query$ 这篇文章的 $p535$  $section6 .2$ 中，计算$SCsim ∗ (q, o, gr(q^m ),gc(q^m )) = γ^ ∗ \\max \\limits_{a_i ∈N_G ,b_i ∈Λ_G} τ_i ∗ S(d_E (a_i , b_i )) $ 的式子中，我觉得这个$max$函数有问题，应该是$sum$函数。</p>\n<p>理由如下：</p>\n<p>在$lemma 2$ 证明过程中，文中比较了$d_{min} (gr(q_i ), gc(q_i )) $和 $ d_E (q_i , o_i )$ [该式子在 $p533$ $SCsim(N, I) := \\Sigma _{q_i∈N,o_i∈I} τ_i ∗ S(d_E (q i , o i ))$ 中]，以及“$γ^∗$ is not less than $γ$ ”，并没有指出$sum$函数和$max$函数的引起的不同，所以我认为 $p535$ 页的式子中应该是 $sum$ 函数，这样前后就一致了。</p>"},{"title":"Chaggie Search Engine","date":"2019-07-20T15:58:32.000Z","photos":["https://github.com/yangyueren/ChaggieSearchEngine/raw/master/pictures/1.png"],"descripotion":"A search engine","_content":"这是大三暑假完成的一个基于Elasticsearch的搜索引擎，后端及ES部分由我用Spring boot完成，前端和爬虫由队友完成。\n<!-- more -->\n## 基于Elasticsearch集群的数据查询优化\n\nElasticsearch是一个基于Lucene的分布式全文搜索引擎，能够横向扩展数以百计的服务器，存储PB级的数据，而且对每个字段都可以建立索引并且检索，并且可以在极短的时间内存储、搜索和分析大量的数据，程序员最爱的网站Github的搜索就是基于ES构建的，GitHub大约有30TB的索引文件数据，由此可见Elasticsearch（下文简称ES）强大的搜索功能。\n\n在此次的深度搜索引擎项目之中，虽然Elasticsearch也可以在一个节点上使用，该节点可以同时担任master node和data node，但是为了发挥Elasticsearch的分布式搜索的优势，在我们的深度搜索引擎中我们使用了三台服务器提供Elasticsearch的服务。下文将详细介绍从集群部署到优化查询的一些要点。\n\n### 一、Elasticsearch的集群部署\n\n#### 1. ES概念简介\n\nElasticsearch中有几个比较重要的概念，集群是指连接在一起的若干台服务器，不同的服务器承担不同的角色，一起提供服务。集群中有主节点、数据节点和客户端节点等。主节点负责管理整个集群，当群集的拓扑结构改变时把索引分片分派到相应的节点上，主节点是从可以担任主节点的节点中选举出来的。数据节点只负责存储数据，客户端节点在选举主节点过程中起作用。ES的分片是把索引信息分散到多个节点上，相当于一桶水用多个杯子装。副本是指索引信息的拷贝。\n\n在进行ES的配置时，首先要考虑节点数和分片数。通过实验，多节点的ES集群中的节点数至少为3，分片数为一倍的节点数量到两倍的节点数量。\n\n节点数和分片数相等时，每个节点负责一个分片的检索，ES集群的性能可以达到最优。对于一个3节点集群，为每个节点分配一个分片，总共3个分片。但是由于ES的不可变性的限制，系统无法对分片进行重新拆分分配，除非重新索引这个文件集合。但是我在三个节点的集群中再加入一个节点，这时候分片数量小于了节点数，在搜索上效率会降低，所以为了支持水平扩展，可以为集群分配比节点数更多的分片数，也就是说每个节点有多个分片。但是每个节点有多个分片时，需要考虑性能的问题，每个节点最好不要超过两个分片，\n\n我采用了官方给默认配置中分片数目为5，这样既可以拓展到5个节点，也可以保证性能。\n\n我的集群的其余配置如下图：\n\n```json\n#节点集群名称和节点类型\ncluster.name: yang-es-clusters\nnode.name: node-3\nnode.master: true\nnode.data: true\n#同个集群其他节点的信息，ES通过广播的方式寻找同一集群的其他节点\ndiscovery.zen.ping.unicast.hosts: [ \"0.0.0.0\", \"106.14.191.xxx\", \"120.79.191.xxx\"]\n#选举主节点时需要由至少2个节点参与投票\ndiscovery.zen.minimum_master_nodes: 2\ngateway.recover_after_nodes: 1\n#配置本节点的ip，默认开发9300端口用于节点间TCP通信\nnetwork.host: 0.0.0.0\nnetwork.publish_host: 106.14.227.30\nnetwork.bind_host: 0.0.0.0\n\n```\n\n\n\n#### 2. Elsaticsearch集群至少需要有三个节点\n\n上文写到我们组搭建的ES集群使用了三台服务器，这也是搭建ES集群所需的最少节点数，是因为需要防止ES集群发生脑裂。ES中维护索引状态最重要的节点是主节点，主节点是被投票选举出来的。\n\n##### 三个和尚投票\n\n当主节点出现问题，从节点不能与主节点通信时，从节点会发起选举任命新的主节点，同时新的主节点会接管旧的主节点的所有工作，如果旧的主节点重新恢复并加入到集群中，新的主节点会将原来旧的主节点降级为从节点，这样就不会有冲突发生。所有这个过程都由ES自己处理，使用者无需任何参与。\n\n##### 两个和尚投票\n\n但是，当只有两个节点的时候，一主（master）一从（slave），如果主从直接的通信出现问题时，从节点slave会自我提升为master，但是当恢复通信时，我们就会同时有两个master。因为此时，对于原来的主节点角度考虑，它认为是原来的从节点出现问题，现在仍然需要作为slave重新加入。这样，两个节点的时候，我们就出现了集群不知道将哪个节点选举为主节点的情况，也就是我们通常说的“分脑”。\n\n为了防止这种情况的发生，第三个节点的出现会打破平衡，解决冲突问题。\n\n##### 三个和尚仍然存在问题\n\n分脑的问题同样会出现在具有三或三个以上节点的集群中，为了降低发生的概率，ElasticSearch提供了一个配置 `discovery.zen.minimum_master_nodes`它规定了在选举新的master时，一个集群下最少需要的节点数。例如，一个3节点集群，这个数字为2，2个节点可以防止单个节点在脱离集群时，将其自己选举成master，相反，它会等待直到重新加入到集群中。这个数值可以通过一个公式确定：\n\n这里的配置是指当主节点宕掉掉时候至少同时需要几个节点才重新进行投票选举新的主节点，官方建议将此数目配置为`N / 2 + 1`，可以有效的防止脑裂。\n\n```json\ndiscovery.zen.minimum_master_nodes: 2\n```\n\n\n\n从图中分析可以得知，如果只有两个节点，当这两个节点通讯故障的时候，会各自选举自己为主节点，而当通讯恢复正常时候会发生冲突，这与区块链的思想不谋而合，只有控制了51%以上的节点，才可以掌控整个集群。\n\n我在配置ES的时候，主节点所在的服务器由于网络问题，经常会发生断网的现象，此时集群的状态会由绿色（正常）转变为红色（预警）状态，而当非主节点宕机的时候，集群状态会变为黄色（所有的主分片可用，但是副本分片不可用）。这个问题的解决方案只有一种，设置容易宕机的节点为数据节点，禁止其被选举为主节点。\n\n\n\n### 二、Elasticsearch的查询参数优化\n\n\n\n#### 1. Lucene的打分模型\n\n![lucene-tf-idf](http://www.biaodianfu.com/wp-content/uploads/2016/09/lucene-tf-idf.png)\n\n\n\n由于ES是基于Lucene，所以ES也是使用的打分机制。通过上面的公式，一篇文档的分数实际上是由查询语句q和文档d作为变量的一个函数值。打分公式中有两部分不直接依赖于查询词，它们是coord和queryNorm。公式的值是这样计算的，coord和queryNorm两大部分直接乘以查询语句中每个查询词计算值的总和。另一方面，这个总和也是由每个查询词的词频(tf)，逆文档频率(idf)，查询词的权重，还有norm，也就是前面说的length norm相乘而得的结果。\n\n从中可以得出以下几条规则：\n\n- 匹配到的关键词越稀有，文档的得分就越高。\n- 文档的域越小(包含比较少的Term)，文档的得分就越高。\n- 设置的权重(索引和搜索时设置的都可以)越大，文档得分越高。\n\n随着Lucene的发展，打分模型也引入了新的相似度模型，并且可以在ES中指定，现在比较流行的是Okapi BM25，Divergence from randomness和Information based。\n\nBM25是基于概率模型的相似度模型，适合处理短文本，关键词的重复次数对整个文档得分影响比较大。DFR和IB比较类似，基于同名概率模型，适用于自然语言类的文本。我们的搜索引擎要搜索的字段比较少，内容也是以短文本为主，并且倾向于能够对名字和标签进行准确匹配，如果关键词在内容中多次重复，明显词条是用户所查询的结果，所以BM25更加适合我们的搜索引擎。\n\n\n\n#### 2. 分词器的选择\n\nES是基于词的搜索引擎，其能够快速的通过搜索词检索出对应的文章归功于倒排索引，使用不同的分词器对于检索效果也有重大影响。\n\nES的默认分词器对英文句子的切割效果比较好，但用于中文句子的分割时，只会将句子分割成孤立的一个个的字，所以需要指定建立索引时的分词器和搜索分词器。我们使用的是IKAnalyzer，是目前比较流行的中文分词器之一,设置比较简单,稳定。\n\n在Sprint Boot中建立索引时候，对ES的支持度不如直接在ES里面自己建立索引可操作性高，以下是我建立索引的代码。\n\n```json\ncurl -XPOST http://106.14.227.30:9200/chageng/EntryDb/_mapping -H 'Content-Type:application/json' -d' { \"EntryDb\": { \"properties\": {\n    \"content\": {\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"search_analyzer\": \"ik_smart\",\n        \"fields\": {\n            \"keyword\": {\n                \"type\": \"text\",\n                \"analyzer\": \"ik_max_word\",\n                \"search_analyzer\": \"ik_smart\"\n            }\n        }\n    },\n    \"imageList\": {\n        \"type\": \"text\",\n        \"fields\": {\n            \"keyword\": {\n                \"type\": \"keyword\",\n                \"ignore_above\": 256\n            }\n        }\n    },\n    \"like\": {\n        \"type\": \"long\"\n    },\n    \"name\": {\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"search_analyzer\": \"ik_smart\",\n        \"fields\": {\n            \"keyword\": {\n                \"type\": \"text\",\n                \"analyzer\": \"ik_max_word\",\n                \"search_analyzer\": \"ik_smart\"\n            }\n        }\n    }\n}'\n```\n\n\n\n#### 3. 查询语句的优化\n\n##### 3.1 term、match与multi_match\n\nES中的term是代表完全匹配，也就是精确查询，搜索前不会再对搜索词进行分词，所以我们的搜索词必须是文档分词集合中的一个。以下代码将会在name中精确匹配为“小鸡快跑”的词条。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n  \"query\":{\n    \"term\":{\n        \"name\":\"小鸡快跑\"\n    }\n  }\n}'\n```\n\n\n\nES的match搜索会先对搜索词进行分词，对于最基本的match搜索来说，只要搜索词的分词集合中的一个或多个存在于文档中即可，例如，当我们搜索`小鸡快跑`，搜索词会先分词为`小鸡`和`快跑`,只要文档中包含`小鸡`和`快跑`任意一个词，都会被搜索到。\n\n如果文档1中有`小鸡`，文档2中有`快跑`，那么这两个文档都会被检索到，而如果文档3中有`小鸡`和`快跑`两个词，文档3也将被返回，并且文档3将被排在首位。所有被返回的文档将依靠_score的分数进行排序，得分的算法参考上文。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n    \"query\": {\n        \"match\": {\n            \"content\": \"小鸡快跑\"\n        }\n    }\n}'\n```\n\n\n\nES的multi_match是对多个字段进行匹配，其中一个字段包含分词，该文档即可被搜索到并且返回。在实际使用中用的比较多。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n\"query\": {\n\"bool\": {\n    \"must\": {\n        \"match\": {\n            \"tagList\": \"社交\"\n        }\n    },\n    \"should\": {\n        \"multi_match\": {\n            \"query\": \"吓得我瓜子都掉了\",\n            \"type\": \"best_fields\",\n            \"fields\": [\n                \"name^2\",\n                \"content\"\n            ],\n\t          \"fuzziness\": \"AUTO\",\n            \"tie_breaker\": 0.4,\n            \"minimum_should_match\": \"30%\"\n        }\n    }\n}\n}\n}\n'\n```\n\n\n\n##### 3.2 组合过滤器bool\n\n `bool` 过滤器通过 `and` 、 `or` 和 `not` 逻辑组合将多个过滤器进行组合。`bool` 查询可以接受 `must` 、 `must_not` 和 `should` 参数下的多个查询语句，对查询结果进行筛选，分别对应`AND NOT OR`。`bool` 查询会为每个文档计算相关度评分 `_score` ， 再将所有匹配的 `must` 和 `should` 语句的分数 `_score` 求和，最后除以 `must` 和 `should` 语句的总数。\n\n`must_not` 语句不会影响评分； 它的作用只是将不相关的文档排除。\n\n`should`过滤的数量是由`minimum_should_match`参数来进行控制，该参数可以是百分比，也可以是一个数字，我在多次实验后发现40%的效果最好。\n\n以下是bool的基本用法。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n\"query\": {\n\"bool\": {\n    \"must\": {\n        \"match\": {\n            \"tagList\": \"游戏\"\n        }\n    },\n    \"should\": {\n        \"multi_match\": {\n            \"query\": \"秦王\",\n            \"type\": \"best_fields\",\n            \"fields\": [\n                \"name^5\",\n              \t\"tagList^2\",\n                \"content^1\"\n            ],\n            \"tie_breaker\": 0.4,\n            \"minimum_should_match\": \"40%\"\n        }\n    },\n    \"filter\": {\n        \"range\": {\n            \"time\": {\n                \"gte\": \"2012-09-09\",\n                \"lt\": \"2019-09-09\"\n            }\n        }\n    }\n}\n}\n}'\n```\n\n\n\n##### 3.3 boost权重控制\n\n在多字段匹配中，我在name tagList 和 content字段中对内容进行查询，但是想让name字段拥有有更高的权重，可以通过指定 `boost` 来控制任何查询语句的相对的权重， `boost` 的默认值为 `1` ，大于 `1` 会提升一个语句的相对权重。基本使用见上条ES语句。\n\n基于 TF/IDF 的评分模型中，如果使用了`boost`改变权重，新的评分 `_score` 会在应用权重提升之后进行归一化处理 ，并不是线性的变化。\n\n\n\n\n\n##### 3.4 模糊匹配\n\n模糊查询的工作原理是给定原始词项及构造一个编辑自动机— 像表示所有原始字符串指定编辑距离的字符串的一个大图表。然后模糊查询使用这个自动机依次高效遍历词典中的所有词项以确定是否匹配。 一旦收集了词典中存在的所有匹配项，就可以计算匹配文档列表。在搜索巨大文档时候，模糊匹配的效率很低，故可以用以下两个参数限制对性能的影响，prefix_length为不能被 “模糊化” 的初始字符数，建议设置为了3，max_expansions限制产生的模糊选项的总数量。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n    \"query\": {\n        \"multi_match\": {\n            \"query\": \"吓得我瓜子都掉了\",\n            \"type\": \"best_fields\",\n            \"fields\": [\n                \"name^2\",\n                \"content\"\n            ],\n            \"fuzziness\": \"AUTO\",\n            \"tie_breaker\": 0.4,\n            \"minimum_should_match\": \"40%\"\n        }\n    }\n}'\n```\n\n\n\n\n\n##### 3.5 随机评分\n\n我们的搜索词条结果集中有很多点赞数一样的词条，在指定按点赞数排序这种方式后，有相同评分 `_score` 的文档会每次都以相同次序出现，为了提高展现率，可以引入一些随机性，保证有相同评分的文档都能有均等相似的展现机率。\n\n每个用户看到不同的随机次序，但也同时希望如果是同一用户翻页浏览时，结果的相对次序能始终保持一致。这种行为被称为 一致随机（consistently random） 。\n\n引用：https://www.elastic.co/guide/cn/elasticsearch/guide/current/random-scoring.html\n\n以下是样例：\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n  \"query\": {\n    \"function_score\": {\n      \"filter\": {\n        \"match\": { \"name\": \"小鸡快跑\" }\n      },\n      \"functions\": [\n        {\n          \"filter\": { \"term\": { \"tagList\": \"小鸡\" }},\n          \"weight\": 1\n        },\n        {\n          \"filter\": { \"term\": { \"tagList\": \"游戏\" }},\n          \"weight\": 2\n        },\n        {\n          \"random_score\": { \n            \"seed\":  \"the users session id\" \n          }\n        }\n      ],\n      \"score_mode\": \"sum\"\n    }\n  }\n}\n```\n\n\n\n### 三、Elasticsearch性能问题\n\n#### 1. 数据预热:\n\nES可以在查询前进行预热，将查询中十分依赖的字段的数据加载出来，可以使用Elasticsearch为类型和索引定义预热查询。\n\n定义一个新的预热查询，和普通查询没什么区别，只是它存储在Elasticsearch一个特殊的名为_warmer的索引中，以下是我的预热查询。\n\n```json\ncurl -XPUT '106.14.227.30: 9200/chageng/_warmer?pretty' -H 'Content-Type: application/json' -d '\n{\n    \"query\": {\n        \"match_all\": {}\n    },\n    \"facets\": {\n        \"warming_facet\": {\n            \"terms\": {\n                \"field\": \"name\"\n            }\n        }\n    }\n}'\n```\n\n\n\n\n\n#### 2. 优化索引\n\n我建立的索引，每个词条都包含较多的内容，不仅包括了该词条的基本信息（name，tag，content，view，like），还包括了从微博、B站、谷歌等地方爬取到的相关信息，每个词条中包含的数据比较多，对完整的词条建立索引，每次的查询速度与在mongodb里面检索持平，在做自动补全时能够有肉眼可见的延迟。\n\n出现查询速度过慢的情况有两方面的原因。第一是建立的索引包含的内容过多，比如微博、B站的数据大约是该词条的基本信息的25倍以上，而这些微博、B站的信息我们在做检索的时候并不需要对这些字段进行检索，这些无效的信息拖累了检索速度。第二是网络传输延迟，因为我们的ES集群和我们的搜索引擎服务并不在同一个机器上面，他们之间是通过网络进行通信，由于每条词条包含数据比较大，所以如果查询结果中有上百条的数据被命中，返回这些数据时需要比较多的时间。\n\n我们的解决方案是建立两个索引，第一个索引存储词条的基本信息，第二个索引存储词条的所有信息，但使用检索功能的时候，我们只需要在第一个索引中检索，将词条的基本信息返回呈现给用户，这样可以大大加快速度。为了将速度优化到极致，在不影响用户正常使用的情况下，我们又对搜索结果的数量进行了限制，每次只返回当前页面要展现的搜索条目，最快的呈现给用户结果，其余的搜索结果用异步的方式加载。当用户进入词条详细页面时，我们可以通过该词条的id，到ES中的第二个索引中查找该id词条的所有信息进行返回，这样的检索速度能够提升到28倍。\n\n#### 3. 优化存储\n\n上文提到索引可以存储到ES中，这样的查询效率最高，那具体的数据可以存储到MySQL、MongoDb，ES三种数据库中，考虑到我们的数据类型以json文件为主，MySQL需要建立多张表来实现关系间的映射，故不做考虑。\n\n我对MongoDb存储词条的所有信息，与直接用ES存储所有的信息进行检索做了一个对比，发现两者在检索10000条数据运行时间上并没有太大差异，所以直接使用ES进行存储了所有的数据。","source":"_posts/1.md","raw":"---\ntitle: Chaggie Search Engine\ndate: 2019-07-20 23:58:32\nphotos: [https://github.com/yangyueren/ChaggieSearchEngine/raw/master/pictures/1.png]\ncategories:\n- Search Engine\ntags: \n- Java \n- Sprint boot\n- Elasticsearch\ndescripotion: A search engine\n---\n这是大三暑假完成的一个基于Elasticsearch的搜索引擎，后端及ES部分由我用Spring boot完成，前端和爬虫由队友完成。\n<!-- more -->\n## 基于Elasticsearch集群的数据查询优化\n\nElasticsearch是一个基于Lucene的分布式全文搜索引擎，能够横向扩展数以百计的服务器，存储PB级的数据，而且对每个字段都可以建立索引并且检索，并且可以在极短的时间内存储、搜索和分析大量的数据，程序员最爱的网站Github的搜索就是基于ES构建的，GitHub大约有30TB的索引文件数据，由此可见Elasticsearch（下文简称ES）强大的搜索功能。\n\n在此次的深度搜索引擎项目之中，虽然Elasticsearch也可以在一个节点上使用，该节点可以同时担任master node和data node，但是为了发挥Elasticsearch的分布式搜索的优势，在我们的深度搜索引擎中我们使用了三台服务器提供Elasticsearch的服务。下文将详细介绍从集群部署到优化查询的一些要点。\n\n### 一、Elasticsearch的集群部署\n\n#### 1. ES概念简介\n\nElasticsearch中有几个比较重要的概念，集群是指连接在一起的若干台服务器，不同的服务器承担不同的角色，一起提供服务。集群中有主节点、数据节点和客户端节点等。主节点负责管理整个集群，当群集的拓扑结构改变时把索引分片分派到相应的节点上，主节点是从可以担任主节点的节点中选举出来的。数据节点只负责存储数据，客户端节点在选举主节点过程中起作用。ES的分片是把索引信息分散到多个节点上，相当于一桶水用多个杯子装。副本是指索引信息的拷贝。\n\n在进行ES的配置时，首先要考虑节点数和分片数。通过实验，多节点的ES集群中的节点数至少为3，分片数为一倍的节点数量到两倍的节点数量。\n\n节点数和分片数相等时，每个节点负责一个分片的检索，ES集群的性能可以达到最优。对于一个3节点集群，为每个节点分配一个分片，总共3个分片。但是由于ES的不可变性的限制，系统无法对分片进行重新拆分分配，除非重新索引这个文件集合。但是我在三个节点的集群中再加入一个节点，这时候分片数量小于了节点数，在搜索上效率会降低，所以为了支持水平扩展，可以为集群分配比节点数更多的分片数，也就是说每个节点有多个分片。但是每个节点有多个分片时，需要考虑性能的问题，每个节点最好不要超过两个分片，\n\n我采用了官方给默认配置中分片数目为5，这样既可以拓展到5个节点，也可以保证性能。\n\n我的集群的其余配置如下图：\n\n```json\n#节点集群名称和节点类型\ncluster.name: yang-es-clusters\nnode.name: node-3\nnode.master: true\nnode.data: true\n#同个集群其他节点的信息，ES通过广播的方式寻找同一集群的其他节点\ndiscovery.zen.ping.unicast.hosts: [ \"0.0.0.0\", \"106.14.191.xxx\", \"120.79.191.xxx\"]\n#选举主节点时需要由至少2个节点参与投票\ndiscovery.zen.minimum_master_nodes: 2\ngateway.recover_after_nodes: 1\n#配置本节点的ip，默认开发9300端口用于节点间TCP通信\nnetwork.host: 0.0.0.0\nnetwork.publish_host: 106.14.227.30\nnetwork.bind_host: 0.0.0.0\n\n```\n\n\n\n#### 2. Elsaticsearch集群至少需要有三个节点\n\n上文写到我们组搭建的ES集群使用了三台服务器，这也是搭建ES集群所需的最少节点数，是因为需要防止ES集群发生脑裂。ES中维护索引状态最重要的节点是主节点，主节点是被投票选举出来的。\n\n##### 三个和尚投票\n\n当主节点出现问题，从节点不能与主节点通信时，从节点会发起选举任命新的主节点，同时新的主节点会接管旧的主节点的所有工作，如果旧的主节点重新恢复并加入到集群中，新的主节点会将原来旧的主节点降级为从节点，这样就不会有冲突发生。所有这个过程都由ES自己处理，使用者无需任何参与。\n\n##### 两个和尚投票\n\n但是，当只有两个节点的时候，一主（master）一从（slave），如果主从直接的通信出现问题时，从节点slave会自我提升为master，但是当恢复通信时，我们就会同时有两个master。因为此时，对于原来的主节点角度考虑，它认为是原来的从节点出现问题，现在仍然需要作为slave重新加入。这样，两个节点的时候，我们就出现了集群不知道将哪个节点选举为主节点的情况，也就是我们通常说的“分脑”。\n\n为了防止这种情况的发生，第三个节点的出现会打破平衡，解决冲突问题。\n\n##### 三个和尚仍然存在问题\n\n分脑的问题同样会出现在具有三或三个以上节点的集群中，为了降低发生的概率，ElasticSearch提供了一个配置 `discovery.zen.minimum_master_nodes`它规定了在选举新的master时，一个集群下最少需要的节点数。例如，一个3节点集群，这个数字为2，2个节点可以防止单个节点在脱离集群时，将其自己选举成master，相反，它会等待直到重新加入到集群中。这个数值可以通过一个公式确定：\n\n这里的配置是指当主节点宕掉掉时候至少同时需要几个节点才重新进行投票选举新的主节点，官方建议将此数目配置为`N / 2 + 1`，可以有效的防止脑裂。\n\n```json\ndiscovery.zen.minimum_master_nodes: 2\n```\n\n\n\n从图中分析可以得知，如果只有两个节点，当这两个节点通讯故障的时候，会各自选举自己为主节点，而当通讯恢复正常时候会发生冲突，这与区块链的思想不谋而合，只有控制了51%以上的节点，才可以掌控整个集群。\n\n我在配置ES的时候，主节点所在的服务器由于网络问题，经常会发生断网的现象，此时集群的状态会由绿色（正常）转变为红色（预警）状态，而当非主节点宕机的时候，集群状态会变为黄色（所有的主分片可用，但是副本分片不可用）。这个问题的解决方案只有一种，设置容易宕机的节点为数据节点，禁止其被选举为主节点。\n\n\n\n### 二、Elasticsearch的查询参数优化\n\n\n\n#### 1. Lucene的打分模型\n\n![lucene-tf-idf](http://www.biaodianfu.com/wp-content/uploads/2016/09/lucene-tf-idf.png)\n\n\n\n由于ES是基于Lucene，所以ES也是使用的打分机制。通过上面的公式，一篇文档的分数实际上是由查询语句q和文档d作为变量的一个函数值。打分公式中有两部分不直接依赖于查询词，它们是coord和queryNorm。公式的值是这样计算的，coord和queryNorm两大部分直接乘以查询语句中每个查询词计算值的总和。另一方面，这个总和也是由每个查询词的词频(tf)，逆文档频率(idf)，查询词的权重，还有norm，也就是前面说的length norm相乘而得的结果。\n\n从中可以得出以下几条规则：\n\n- 匹配到的关键词越稀有，文档的得分就越高。\n- 文档的域越小(包含比较少的Term)，文档的得分就越高。\n- 设置的权重(索引和搜索时设置的都可以)越大，文档得分越高。\n\n随着Lucene的发展，打分模型也引入了新的相似度模型，并且可以在ES中指定，现在比较流行的是Okapi BM25，Divergence from randomness和Information based。\n\nBM25是基于概率模型的相似度模型，适合处理短文本，关键词的重复次数对整个文档得分影响比较大。DFR和IB比较类似，基于同名概率模型，适用于自然语言类的文本。我们的搜索引擎要搜索的字段比较少，内容也是以短文本为主，并且倾向于能够对名字和标签进行准确匹配，如果关键词在内容中多次重复，明显词条是用户所查询的结果，所以BM25更加适合我们的搜索引擎。\n\n\n\n#### 2. 分词器的选择\n\nES是基于词的搜索引擎，其能够快速的通过搜索词检索出对应的文章归功于倒排索引，使用不同的分词器对于检索效果也有重大影响。\n\nES的默认分词器对英文句子的切割效果比较好，但用于中文句子的分割时，只会将句子分割成孤立的一个个的字，所以需要指定建立索引时的分词器和搜索分词器。我们使用的是IKAnalyzer，是目前比较流行的中文分词器之一,设置比较简单,稳定。\n\n在Sprint Boot中建立索引时候，对ES的支持度不如直接在ES里面自己建立索引可操作性高，以下是我建立索引的代码。\n\n```json\ncurl -XPOST http://106.14.227.30:9200/chageng/EntryDb/_mapping -H 'Content-Type:application/json' -d' { \"EntryDb\": { \"properties\": {\n    \"content\": {\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"search_analyzer\": \"ik_smart\",\n        \"fields\": {\n            \"keyword\": {\n                \"type\": \"text\",\n                \"analyzer\": \"ik_max_word\",\n                \"search_analyzer\": \"ik_smart\"\n            }\n        }\n    },\n    \"imageList\": {\n        \"type\": \"text\",\n        \"fields\": {\n            \"keyword\": {\n                \"type\": \"keyword\",\n                \"ignore_above\": 256\n            }\n        }\n    },\n    \"like\": {\n        \"type\": \"long\"\n    },\n    \"name\": {\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"search_analyzer\": \"ik_smart\",\n        \"fields\": {\n            \"keyword\": {\n                \"type\": \"text\",\n                \"analyzer\": \"ik_max_word\",\n                \"search_analyzer\": \"ik_smart\"\n            }\n        }\n    }\n}'\n```\n\n\n\n#### 3. 查询语句的优化\n\n##### 3.1 term、match与multi_match\n\nES中的term是代表完全匹配，也就是精确查询，搜索前不会再对搜索词进行分词，所以我们的搜索词必须是文档分词集合中的一个。以下代码将会在name中精确匹配为“小鸡快跑”的词条。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n  \"query\":{\n    \"term\":{\n        \"name\":\"小鸡快跑\"\n    }\n  }\n}'\n```\n\n\n\nES的match搜索会先对搜索词进行分词，对于最基本的match搜索来说，只要搜索词的分词集合中的一个或多个存在于文档中即可，例如，当我们搜索`小鸡快跑`，搜索词会先分词为`小鸡`和`快跑`,只要文档中包含`小鸡`和`快跑`任意一个词，都会被搜索到。\n\n如果文档1中有`小鸡`，文档2中有`快跑`，那么这两个文档都会被检索到，而如果文档3中有`小鸡`和`快跑`两个词，文档3也将被返回，并且文档3将被排在首位。所有被返回的文档将依靠_score的分数进行排序，得分的算法参考上文。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n    \"query\": {\n        \"match\": {\n            \"content\": \"小鸡快跑\"\n        }\n    }\n}'\n```\n\n\n\nES的multi_match是对多个字段进行匹配，其中一个字段包含分词，该文档即可被搜索到并且返回。在实际使用中用的比较多。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n\"query\": {\n\"bool\": {\n    \"must\": {\n        \"match\": {\n            \"tagList\": \"社交\"\n        }\n    },\n    \"should\": {\n        \"multi_match\": {\n            \"query\": \"吓得我瓜子都掉了\",\n            \"type\": \"best_fields\",\n            \"fields\": [\n                \"name^2\",\n                \"content\"\n            ],\n\t          \"fuzziness\": \"AUTO\",\n            \"tie_breaker\": 0.4,\n            \"minimum_should_match\": \"30%\"\n        }\n    }\n}\n}\n}\n'\n```\n\n\n\n##### 3.2 组合过滤器bool\n\n `bool` 过滤器通过 `and` 、 `or` 和 `not` 逻辑组合将多个过滤器进行组合。`bool` 查询可以接受 `must` 、 `must_not` 和 `should` 参数下的多个查询语句，对查询结果进行筛选，分别对应`AND NOT OR`。`bool` 查询会为每个文档计算相关度评分 `_score` ， 再将所有匹配的 `must` 和 `should` 语句的分数 `_score` 求和，最后除以 `must` 和 `should` 语句的总数。\n\n`must_not` 语句不会影响评分； 它的作用只是将不相关的文档排除。\n\n`should`过滤的数量是由`minimum_should_match`参数来进行控制，该参数可以是百分比，也可以是一个数字，我在多次实验后发现40%的效果最好。\n\n以下是bool的基本用法。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n\"query\": {\n\"bool\": {\n    \"must\": {\n        \"match\": {\n            \"tagList\": \"游戏\"\n        }\n    },\n    \"should\": {\n        \"multi_match\": {\n            \"query\": \"秦王\",\n            \"type\": \"best_fields\",\n            \"fields\": [\n                \"name^5\",\n              \t\"tagList^2\",\n                \"content^1\"\n            ],\n            \"tie_breaker\": 0.4,\n            \"minimum_should_match\": \"40%\"\n        }\n    },\n    \"filter\": {\n        \"range\": {\n            \"time\": {\n                \"gte\": \"2012-09-09\",\n                \"lt\": \"2019-09-09\"\n            }\n        }\n    }\n}\n}\n}'\n```\n\n\n\n##### 3.3 boost权重控制\n\n在多字段匹配中，我在name tagList 和 content字段中对内容进行查询，但是想让name字段拥有有更高的权重，可以通过指定 `boost` 来控制任何查询语句的相对的权重， `boost` 的默认值为 `1` ，大于 `1` 会提升一个语句的相对权重。基本使用见上条ES语句。\n\n基于 TF/IDF 的评分模型中，如果使用了`boost`改变权重，新的评分 `_score` 会在应用权重提升之后进行归一化处理 ，并不是线性的变化。\n\n\n\n\n\n##### 3.4 模糊匹配\n\n模糊查询的工作原理是给定原始词项及构造一个编辑自动机— 像表示所有原始字符串指定编辑距离的字符串的一个大图表。然后模糊查询使用这个自动机依次高效遍历词典中的所有词项以确定是否匹配。 一旦收集了词典中存在的所有匹配项，就可以计算匹配文档列表。在搜索巨大文档时候，模糊匹配的效率很低，故可以用以下两个参数限制对性能的影响，prefix_length为不能被 “模糊化” 的初始字符数，建议设置为了3，max_expansions限制产生的模糊选项的总数量。\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n    \"query\": {\n        \"multi_match\": {\n            \"query\": \"吓得我瓜子都掉了\",\n            \"type\": \"best_fields\",\n            \"fields\": [\n                \"name^2\",\n                \"content\"\n            ],\n            \"fuzziness\": \"AUTO\",\n            \"tie_breaker\": 0.4,\n            \"minimum_should_match\": \"40%\"\n        }\n    }\n}'\n```\n\n\n\n\n\n##### 3.5 随机评分\n\n我们的搜索词条结果集中有很多点赞数一样的词条，在指定按点赞数排序这种方式后，有相同评分 `_score` 的文档会每次都以相同次序出现，为了提高展现率，可以引入一些随机性，保证有相同评分的文档都能有均等相似的展现机率。\n\n每个用户看到不同的随机次序，但也同时希望如果是同一用户翻页浏览时，结果的相对次序能始终保持一致。这种行为被称为 一致随机（consistently random） 。\n\n引用：https://www.elastic.co/guide/cn/elasticsearch/guide/current/random-scoring.html\n\n以下是样例：\n\n```json\ncurl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '\n{\n  \"query\": {\n    \"function_score\": {\n      \"filter\": {\n        \"match\": { \"name\": \"小鸡快跑\" }\n      },\n      \"functions\": [\n        {\n          \"filter\": { \"term\": { \"tagList\": \"小鸡\" }},\n          \"weight\": 1\n        },\n        {\n          \"filter\": { \"term\": { \"tagList\": \"游戏\" }},\n          \"weight\": 2\n        },\n        {\n          \"random_score\": { \n            \"seed\":  \"the users session id\" \n          }\n        }\n      ],\n      \"score_mode\": \"sum\"\n    }\n  }\n}\n```\n\n\n\n### 三、Elasticsearch性能问题\n\n#### 1. 数据预热:\n\nES可以在查询前进行预热，将查询中十分依赖的字段的数据加载出来，可以使用Elasticsearch为类型和索引定义预热查询。\n\n定义一个新的预热查询，和普通查询没什么区别，只是它存储在Elasticsearch一个特殊的名为_warmer的索引中，以下是我的预热查询。\n\n```json\ncurl -XPUT '106.14.227.30: 9200/chageng/_warmer?pretty' -H 'Content-Type: application/json' -d '\n{\n    \"query\": {\n        \"match_all\": {}\n    },\n    \"facets\": {\n        \"warming_facet\": {\n            \"terms\": {\n                \"field\": \"name\"\n            }\n        }\n    }\n}'\n```\n\n\n\n\n\n#### 2. 优化索引\n\n我建立的索引，每个词条都包含较多的内容，不仅包括了该词条的基本信息（name，tag，content，view，like），还包括了从微博、B站、谷歌等地方爬取到的相关信息，每个词条中包含的数据比较多，对完整的词条建立索引，每次的查询速度与在mongodb里面检索持平，在做自动补全时能够有肉眼可见的延迟。\n\n出现查询速度过慢的情况有两方面的原因。第一是建立的索引包含的内容过多，比如微博、B站的数据大约是该词条的基本信息的25倍以上，而这些微博、B站的信息我们在做检索的时候并不需要对这些字段进行检索，这些无效的信息拖累了检索速度。第二是网络传输延迟，因为我们的ES集群和我们的搜索引擎服务并不在同一个机器上面，他们之间是通过网络进行通信，由于每条词条包含数据比较大，所以如果查询结果中有上百条的数据被命中，返回这些数据时需要比较多的时间。\n\n我们的解决方案是建立两个索引，第一个索引存储词条的基本信息，第二个索引存储词条的所有信息，但使用检索功能的时候，我们只需要在第一个索引中检索，将词条的基本信息返回呈现给用户，这样可以大大加快速度。为了将速度优化到极致，在不影响用户正常使用的情况下，我们又对搜索结果的数量进行了限制，每次只返回当前页面要展现的搜索条目，最快的呈现给用户结果，其余的搜索结果用异步的方式加载。当用户进入词条详细页面时，我们可以通过该词条的id，到ES中的第二个索引中查找该id词条的所有信息进行返回，这样的检索速度能够提升到28倍。\n\n#### 3. 优化存储\n\n上文提到索引可以存储到ES中，这样的查询效率最高，那具体的数据可以存储到MySQL、MongoDb，ES三种数据库中，考虑到我们的数据类型以json文件为主，MySQL需要建立多张表来实现关系间的映射，故不做考虑。\n\n我对MongoDb存储词条的所有信息，与直接用ES存储所有的信息进行检索做了一个对比，发现两者在检索10000条数据运行时间上并没有太大差异，所以直接使用ES进行存储了所有的数据。","slug":"1","published":1,"updated":"2019-07-20T16:06:06.000Z","comments":1,"layout":"post","link":"","_id":"ck2a2ug2a000iviwq952gugjz","content":"<p>这是大三暑假完成的一个基于Elasticsearch的搜索引擎，后端及ES部分由我用Spring boot完成，前端和爬虫由队友完成。<br><a id=\"more\"></a></p>\n<h2 id=\"基于Elasticsearch集群的数据查询优化\"><a href=\"#基于Elasticsearch集群的数据查询优化\" class=\"headerlink\" title=\"基于Elasticsearch集群的数据查询优化\"></a>基于Elasticsearch集群的数据查询优化</h2><p>Elasticsearch是一个基于Lucene的分布式全文搜索引擎，能够横向扩展数以百计的服务器，存储PB级的数据，而且对每个字段都可以建立索引并且检索，并且可以在极短的时间内存储、搜索和分析大量的数据，程序员最爱的网站Github的搜索就是基于ES构建的，GitHub大约有30TB的索引文件数据，由此可见Elasticsearch（下文简称ES）强大的搜索功能。</p>\n<p>在此次的深度搜索引擎项目之中，虽然Elasticsearch也可以在一个节点上使用，该节点可以同时担任master node和data node，但是为了发挥Elasticsearch的分布式搜索的优势，在我们的深度搜索引擎中我们使用了三台服务器提供Elasticsearch的服务。下文将详细介绍从集群部署到优化查询的一些要点。</p>\n<h3 id=\"一、Elasticsearch的集群部署\"><a href=\"#一、Elasticsearch的集群部署\" class=\"headerlink\" title=\"一、Elasticsearch的集群部署\"></a>一、Elasticsearch的集群部署</h3><h4 id=\"1-ES概念简介\"><a href=\"#1-ES概念简介\" class=\"headerlink\" title=\"1. ES概念简介\"></a>1. ES概念简介</h4><p>Elasticsearch中有几个比较重要的概念，集群是指连接在一起的若干台服务器，不同的服务器承担不同的角色，一起提供服务。集群中有主节点、数据节点和客户端节点等。主节点负责管理整个集群，当群集的拓扑结构改变时把索引分片分派到相应的节点上，主节点是从可以担任主节点的节点中选举出来的。数据节点只负责存储数据，客户端节点在选举主节点过程中起作用。ES的分片是把索引信息分散到多个节点上，相当于一桶水用多个杯子装。副本是指索引信息的拷贝。</p>\n<p>在进行ES的配置时，首先要考虑节点数和分片数。通过实验，多节点的ES集群中的节点数至少为3，分片数为一倍的节点数量到两倍的节点数量。</p>\n<p>节点数和分片数相等时，每个节点负责一个分片的检索，ES集群的性能可以达到最优。对于一个3节点集群，为每个节点分配一个分片，总共3个分片。但是由于ES的不可变性的限制，系统无法对分片进行重新拆分分配，除非重新索引这个文件集合。但是我在三个节点的集群中再加入一个节点，这时候分片数量小于了节点数，在搜索上效率会降低，所以为了支持水平扩展，可以为集群分配比节点数更多的分片数，也就是说每个节点有多个分片。但是每个节点有多个分片时，需要考虑性能的问题，每个节点最好不要超过两个分片，</p>\n<p>我采用了官方给默认配置中分片数目为5，这样既可以拓展到5个节点，也可以保证性能。</p>\n<p>我的集群的其余配置如下图：</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">#节点集群名称和节点类型</span><br><span class=\"line\">cluster.name: yang-es-clusters</span><br><span class=\"line\">node.name: node-3</span><br><span class=\"line\">node.master: true</span><br><span class=\"line\">node.data: true</span><br><span class=\"line\">#同个集群其他节点的信息，ES通过广播的方式寻找同一集群的其他节点</span><br><span class=\"line\">discovery.zen.ping.unicast.hosts: [ \"0.0.0.0\", \"106.14.191.xxx\", \"120.79.191.xxx\"]</span><br><span class=\"line\">#选举主节点时需要由至少2个节点参与投票</span><br><span class=\"line\">discovery.zen.minimum_master_nodes: 2</span><br><span class=\"line\">gateway.recover_after_nodes: 1</span><br><span class=\"line\">#配置本节点的ip，默认开发9300端口用于节点间TCP通信</span><br><span class=\"line\">network.host: 0.0.0.0</span><br><span class=\"line\">network.publish_host: 106.14.227.30</span><br><span class=\"line\">network.bind_host: 0.0.0.0</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-Elsaticsearch集群至少需要有三个节点\"><a href=\"#2-Elsaticsearch集群至少需要有三个节点\" class=\"headerlink\" title=\"2. Elsaticsearch集群至少需要有三个节点\"></a>2. Elsaticsearch集群至少需要有三个节点</h4><p>上文写到我们组搭建的ES集群使用了三台服务器，这也是搭建ES集群所需的最少节点数，是因为需要防止ES集群发生脑裂。ES中维护索引状态最重要的节点是主节点，主节点是被投票选举出来的。</p>\n<h5 id=\"三个和尚投票\"><a href=\"#三个和尚投票\" class=\"headerlink\" title=\"三个和尚投票\"></a>三个和尚投票</h5><p>当主节点出现问题，从节点不能与主节点通信时，从节点会发起选举任命新的主节点，同时新的主节点会接管旧的主节点的所有工作，如果旧的主节点重新恢复并加入到集群中，新的主节点会将原来旧的主节点降级为从节点，这样就不会有冲突发生。所有这个过程都由ES自己处理，使用者无需任何参与。</p>\n<h5 id=\"两个和尚投票\"><a href=\"#两个和尚投票\" class=\"headerlink\" title=\"两个和尚投票\"></a>两个和尚投票</h5><p>但是，当只有两个节点的时候，一主（master）一从（slave），如果主从直接的通信出现问题时，从节点slave会自我提升为master，但是当恢复通信时，我们就会同时有两个master。因为此时，对于原来的主节点角度考虑，它认为是原来的从节点出现问题，现在仍然需要作为slave重新加入。这样，两个节点的时候，我们就出现了集群不知道将哪个节点选举为主节点的情况，也就是我们通常说的“分脑”。</p>\n<p>为了防止这种情况的发生，第三个节点的出现会打破平衡，解决冲突问题。</p>\n<h5 id=\"三个和尚仍然存在问题\"><a href=\"#三个和尚仍然存在问题\" class=\"headerlink\" title=\"三个和尚仍然存在问题\"></a>三个和尚仍然存在问题</h5><p>分脑的问题同样会出现在具有三或三个以上节点的集群中，为了降低发生的概率，ElasticSearch提供了一个配置 <code>discovery.zen.minimum_master_nodes</code>它规定了在选举新的master时，一个集群下最少需要的节点数。例如，一个3节点集群，这个数字为2，2个节点可以防止单个节点在脱离集群时，将其自己选举成master，相反，它会等待直到重新加入到集群中。这个数值可以通过一个公式确定：</p>\n<p>这里的配置是指当主节点宕掉掉时候至少同时需要几个节点才重新进行投票选举新的主节点，官方建议将此数目配置为<code>N / 2 + 1</code>，可以有效的防止脑裂。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure>\n<p>从图中分析可以得知，如果只有两个节点，当这两个节点通讯故障的时候，会各自选举自己为主节点，而当通讯恢复正常时候会发生冲突，这与区块链的思想不谋而合，只有控制了51%以上的节点，才可以掌控整个集群。</p>\n<p>我在配置ES的时候，主节点所在的服务器由于网络问题，经常会发生断网的现象，此时集群的状态会由绿色（正常）转变为红色（预警）状态，而当非主节点宕机的时候，集群状态会变为黄色（所有的主分片可用，但是副本分片不可用）。这个问题的解决方案只有一种，设置容易宕机的节点为数据节点，禁止其被选举为主节点。</p>\n<h3 id=\"二、Elasticsearch的查询参数优化\"><a href=\"#二、Elasticsearch的查询参数优化\" class=\"headerlink\" title=\"二、Elasticsearch的查询参数优化\"></a>二、Elasticsearch的查询参数优化</h3><h4 id=\"1-Lucene的打分模型\"><a href=\"#1-Lucene的打分模型\" class=\"headerlink\" title=\"1. Lucene的打分模型\"></a>1. Lucene的打分模型</h4><p><img src=\"http://www.biaodianfu.com/wp-content/uploads/2016/09/lucene-tf-idf.png\" alt=\"lucene-tf-idf\"></p>\n<p>由于ES是基于Lucene，所以ES也是使用的打分机制。通过上面的公式，一篇文档的分数实际上是由查询语句q和文档d作为变量的一个函数值。打分公式中有两部分不直接依赖于查询词，它们是coord和queryNorm。公式的值是这样计算的，coord和queryNorm两大部分直接乘以查询语句中每个查询词计算值的总和。另一方面，这个总和也是由每个查询词的词频(tf)，逆文档频率(idf)，查询词的权重，还有norm，也就是前面说的length norm相乘而得的结果。</p>\n<p>从中可以得出以下几条规则：</p>\n<ul>\n<li>匹配到的关键词越稀有，文档的得分就越高。</li>\n<li>文档的域越小(包含比较少的Term)，文档的得分就越高。</li>\n<li>设置的权重(索引和搜索时设置的都可以)越大，文档得分越高。</li>\n</ul>\n<p>随着Lucene的发展，打分模型也引入了新的相似度模型，并且可以在ES中指定，现在比较流行的是Okapi BM25，Divergence from randomness和Information based。</p>\n<p>BM25是基于概率模型的相似度模型，适合处理短文本，关键词的重复次数对整个文档得分影响比较大。DFR和IB比较类似，基于同名概率模型，适用于自然语言类的文本。我们的搜索引擎要搜索的字段比较少，内容也是以短文本为主，并且倾向于能够对名字和标签进行准确匹配，如果关键词在内容中多次重复，明显词条是用户所查询的结果，所以BM25更加适合我们的搜索引擎。</p>\n<h4 id=\"2-分词器的选择\"><a href=\"#2-分词器的选择\" class=\"headerlink\" title=\"2. 分词器的选择\"></a>2. 分词器的选择</h4><p>ES是基于词的搜索引擎，其能够快速的通过搜索词检索出对应的文章归功于倒排索引，使用不同的分词器对于检索效果也有重大影响。</p>\n<p>ES的默认分词器对英文句子的切割效果比较好，但用于中文句子的分割时，只会将句子分割成孤立的一个个的字，所以需要指定建立索引时的分词器和搜索分词器。我们使用的是IKAnalyzer，是目前比较流行的中文分词器之一,设置比较简单,稳定。</p>\n<p>在Sprint Boot中建立索引时候，对ES的支持度不如直接在ES里面自己建立索引可操作性高，以下是我建立索引的代码。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST http://106.14.227.30:9200/chageng/EntryDb/_mapping -H 'Content-Type:application/json' -d' &#123; \"EntryDb\": &#123; \"properties\": &#123;</span><br><span class=\"line\">    \"content\": &#123;</span><br><span class=\"line\">        \"type\": \"text\",</span><br><span class=\"line\">        \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">        \"search_analyzer\": \"ik_smart\",</span><br><span class=\"line\">        \"fields\": &#123;</span><br><span class=\"line\">            \"keyword\": &#123;</span><br><span class=\"line\">                \"type\": \"text\",</span><br><span class=\"line\">                \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">                \"search_analyzer\": \"ik_smart\"</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    \"imageList\": &#123;</span><br><span class=\"line\">        \"type\": \"text\",</span><br><span class=\"line\">        \"fields\": &#123;</span><br><span class=\"line\">            \"keyword\": &#123;</span><br><span class=\"line\">                \"type\": \"keyword\",</span><br><span class=\"line\">                \"ignore_above\": 256</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    \"like\": &#123;</span><br><span class=\"line\">        \"type\": \"long\"</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    \"name\": &#123;</span><br><span class=\"line\">        \"type\": \"text\",</span><br><span class=\"line\">        \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">        \"search_analyzer\": \"ik_smart\",</span><br><span class=\"line\">        \"fields\": &#123;</span><br><span class=\"line\">            \"keyword\": &#123;</span><br><span class=\"line\">                \"type\": \"text\",</span><br><span class=\"line\">                \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">                \"search_analyzer\": \"ik_smart\"</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-查询语句的优化\"><a href=\"#3-查询语句的优化\" class=\"headerlink\" title=\"3. 查询语句的优化\"></a>3. 查询语句的优化</h4><h5 id=\"3-1-term、match与multi-match\"><a href=\"#3-1-term、match与multi-match\" class=\"headerlink\" title=\"3.1 term、match与multi_match\"></a>3.1 term、match与multi_match</h5><p>ES中的term是代表完全匹配，也就是精确查询，搜索前不会再对搜索词进行分词，所以我们的搜索词必须是文档分词集合中的一个。以下代码将会在name中精确匹配为“小鸡快跑”的词条。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"query\"</span>:&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"term\"</span>:&#123;</span><br><span class=\"line\">        <span class=\"attr\">\"name\"</span>:<span class=\"string\">\"小鸡快跑\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<p>ES的match搜索会先对搜索词进行分词，对于最基本的match搜索来说，只要搜索词的分词集合中的一个或多个存在于文档中即可，例如，当我们搜索<code>小鸡快跑</code>，搜索词会先分词为<code>小鸡</code>和<code>快跑</code>,只要文档中包含<code>小鸡</code>和<code>快跑</code>任意一个词，都会被搜索到。</p>\n<p>如果文档1中有<code>小鸡</code>，文档2中有<code>快跑</code>，那么这两个文档都会被检索到，而如果文档3中有<code>小鸡</code>和<code>快跑</code>两个词，文档3也将被返回，并且文档3将被排在首位。所有被返回的文档将依靠_score的分数进行排序，得分的算法参考上文。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"content\"</span>: <span class=\"string\">\"小鸡快跑\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<p>ES的multi_match是对多个字段进行匹配，其中一个字段包含分词，该文档即可被搜索到并且返回。在实际使用中用的比较多。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\"><span class=\"attr\">\"bool\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"must\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"社交\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"should\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"multi_match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"query\"</span>: <span class=\"string\">\"吓得我瓜子都掉了\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"best_fields\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">                <span class=\"string\">\"name^2\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"content\"</span></span><br><span class=\"line\">            ],</span><br><span class=\"line\">\t          <span class=\"attr\">\"fuzziness\"</span>: <span class=\"string\">\"AUTO\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"tie_breaker\"</span>: <span class=\"number\">0.4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"minimum_should_match\"</span>: <span class=\"string\">\"30%\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">'</span><br></pre></td></tr></table></figure>\n<h5 id=\"3-2-组合过滤器bool\"><a href=\"#3-2-组合过滤器bool\" class=\"headerlink\" title=\"3.2 组合过滤器bool\"></a>3.2 组合过滤器bool</h5><p> <code>bool</code> 过滤器通过 <code>and</code> 、 <code>or</code> 和 <code>not</code> 逻辑组合将多个过滤器进行组合。<code>bool</code> 查询可以接受 <code>must</code> 、 <code>must_not</code> 和 <code>should</code> 参数下的多个查询语句，对查询结果进行筛选，分别对应<code>AND NOT OR</code>。<code>bool</code> 查询会为每个文档计算相关度评分 <code>_score</code> ， 再将所有匹配的 <code>must</code> 和 <code>should</code> 语句的分数 <code>_score</code> 求和，最后除以 <code>must</code> 和 <code>should</code> 语句的总数。</p>\n<p><code>must_not</code> 语句不会影响评分； 它的作用只是将不相关的文档排除。</p>\n<p><code>should</code>过滤的数量是由<code>minimum_should_match</code>参数来进行控制，该参数可以是百分比，也可以是一个数字，我在多次实验后发现40%的效果最好。</p>\n<p>以下是bool的基本用法。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\"><span class=\"attr\">\"bool\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"must\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"游戏\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"should\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"multi_match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"query\"</span>: <span class=\"string\">\"秦王\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"best_fields\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">                <span class=\"string\">\"name^5\"</span>,</span><br><span class=\"line\">              \t<span class=\"string\">\"tagList^2\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"content^1\"</span></span><br><span class=\"line\">            ],</span><br><span class=\"line\">            <span class=\"attr\">\"tie_breaker\"</span>: <span class=\"number\">0.4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"minimum_should_match\"</span>: <span class=\"string\">\"40%\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"filter\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"range\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"time\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"gte\"</span>: <span class=\"string\">\"2012-09-09\"</span>,</span><br><span class=\"line\">                <span class=\"attr\">\"lt\"</span>: <span class=\"string\">\"2019-09-09\"</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h5 id=\"3-3-boost权重控制\"><a href=\"#3-3-boost权重控制\" class=\"headerlink\" title=\"3.3 boost权重控制\"></a>3.3 boost权重控制</h5><p>在多字段匹配中，我在name tagList 和 content字段中对内容进行查询，但是想让name字段拥有有更高的权重，可以通过指定 <code>boost</code> 来控制任何查询语句的相对的权重， <code>boost</code> 的默认值为 <code>1</code> ，大于 <code>1</code> 会提升一个语句的相对权重。基本使用见上条ES语句。</p>\n<p>基于 TF/IDF 的评分模型中，如果使用了<code>boost</code>改变权重，新的评分 <code>_score</code> 会在应用权重提升之后进行归一化处理 ，并不是线性的变化。</p>\n<h5 id=\"3-4-模糊匹配\"><a href=\"#3-4-模糊匹配\" class=\"headerlink\" title=\"3.4 模糊匹配\"></a>3.4 模糊匹配</h5><p>模糊查询的工作原理是给定原始词项及构造一个编辑自动机— 像表示所有原始字符串指定编辑距离的字符串的一个大图表。然后模糊查询使用这个自动机依次高效遍历词典中的所有词项以确定是否匹配。 一旦收集了词典中存在的所有匹配项，就可以计算匹配文档列表。在搜索巨大文档时候，模糊匹配的效率很低，故可以用以下两个参数限制对性能的影响，prefix_length为不能被 “模糊化” 的初始字符数，建议设置为了3，max_expansions限制产生的模糊选项的总数量。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"multi_match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"query\"</span>: <span class=\"string\">\"吓得我瓜子都掉了\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"best_fields\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">                <span class=\"string\">\"name^2\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"content\"</span></span><br><span class=\"line\">            ],</span><br><span class=\"line\">            <span class=\"attr\">\"fuzziness\"</span>: <span class=\"string\">\"AUTO\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"tie_breaker\"</span>: <span class=\"number\">0.4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"minimum_should_match\"</span>: <span class=\"string\">\"40%\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h5 id=\"3-5-随机评分\"><a href=\"#3-5-随机评分\" class=\"headerlink\" title=\"3.5 随机评分\"></a>3.5 随机评分</h5><p>我们的搜索词条结果集中有很多点赞数一样的词条，在指定按点赞数排序这种方式后，有相同评分 <code>_score</code> 的文档会每次都以相同次序出现，为了提高展现率，可以引入一些随机性，保证有相同评分的文档都能有均等相似的展现机率。</p>\n<p>每个用户看到不同的随机次序，但也同时希望如果是同一用户翻页浏览时，结果的相对次序能始终保持一致。这种行为被称为 一致随机（consistently random） 。</p>\n<p>引用：<a href=\"https://www.elastic.co/guide/cn/elasticsearch/guide/current/random-scoring.html\" target=\"_blank\" rel=\"noopener\">https://www.elastic.co/guide/cn/elasticsearch/guide/current/random-scoring.html</a></p>\n<p>以下是样例：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"function_score\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"filter\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123; <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"小鸡快跑\"</span> &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"functions\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"filter\"</span>: &#123; <span class=\"attr\">\"term\"</span>: &#123; <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"小鸡\"</span> &#125;&#125;,</span><br><span class=\"line\">          <span class=\"attr\">\"weight\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"filter\"</span>: &#123; <span class=\"attr\">\"term\"</span>: &#123; <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"游戏\"</span> &#125;&#125;,</span><br><span class=\"line\">          <span class=\"attr\">\"weight\"</span>: <span class=\"number\">2</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"random_score\"</span>: &#123; </span><br><span class=\"line\">            <span class=\"attr\">\"seed\"</span>:  <span class=\"string\">\"the users session id\"</span> </span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"score_mode\"</span>: <span class=\"string\">\"sum\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"三、Elasticsearch性能问题\"><a href=\"#三、Elasticsearch性能问题\" class=\"headerlink\" title=\"三、Elasticsearch性能问题\"></a>三、Elasticsearch性能问题</h3><h4 id=\"1-数据预热\"><a href=\"#1-数据预热\" class=\"headerlink\" title=\"1. 数据预热:\"></a>1. 数据预热:</h4><p>ES可以在查询前进行预热，将查询中十分依赖的字段的数据加载出来，可以使用Elasticsearch为类型和索引定义预热查询。</p>\n<p>定义一个新的预热查询，和普通查询没什么区别，只是它存储在Elasticsearch一个特殊的名为_warmer的索引中，以下是我的预热查询。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPUT '106.14.227.30: 9200/chageng/_warmer?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match_all\"</span>: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"facets\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"warming_facet\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"terms\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"field\"</span>: <span class=\"string\">\"name\"</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-优化索引\"><a href=\"#2-优化索引\" class=\"headerlink\" title=\"2. 优化索引\"></a>2. 优化索引</h4><p>我建立的索引，每个词条都包含较多的内容，不仅包括了该词条的基本信息（name，tag，content，view，like），还包括了从微博、B站、谷歌等地方爬取到的相关信息，每个词条中包含的数据比较多，对完整的词条建立索引，每次的查询速度与在mongodb里面检索持平，在做自动补全时能够有肉眼可见的延迟。</p>\n<p>出现查询速度过慢的情况有两方面的原因。第一是建立的索引包含的内容过多，比如微博、B站的数据大约是该词条的基本信息的25倍以上，而这些微博、B站的信息我们在做检索的时候并不需要对这些字段进行检索，这些无效的信息拖累了检索速度。第二是网络传输延迟，因为我们的ES集群和我们的搜索引擎服务并不在同一个机器上面，他们之间是通过网络进行通信，由于每条词条包含数据比较大，所以如果查询结果中有上百条的数据被命中，返回这些数据时需要比较多的时间。</p>\n<p>我们的解决方案是建立两个索引，第一个索引存储词条的基本信息，第二个索引存储词条的所有信息，但使用检索功能的时候，我们只需要在第一个索引中检索，将词条的基本信息返回呈现给用户，这样可以大大加快速度。为了将速度优化到极致，在不影响用户正常使用的情况下，我们又对搜索结果的数量进行了限制，每次只返回当前页面要展现的搜索条目，最快的呈现给用户结果，其余的搜索结果用异步的方式加载。当用户进入词条详细页面时，我们可以通过该词条的id，到ES中的第二个索引中查找该id词条的所有信息进行返回，这样的检索速度能够提升到28倍。</p>\n<h4 id=\"3-优化存储\"><a href=\"#3-优化存储\" class=\"headerlink\" title=\"3. 优化存储\"></a>3. 优化存储</h4><p>上文提到索引可以存储到ES中，这样的查询效率最高，那具体的数据可以存储到MySQL、MongoDb，ES三种数据库中，考虑到我们的数据类型以json文件为主，MySQL需要建立多张表来实现关系间的映射，故不做考虑。</p>\n<p>我对MongoDb存储词条的所有信息，与直接用ES存储所有的信息进行检索做了一个对比，发现两者在检索10000条数据运行时间上并没有太大差异，所以直接使用ES进行存储了所有的数据。</p>\n","site":{"data":{}},"excerpt":"<p>这是大三暑假完成的一个基于Elasticsearch的搜索引擎，后端及ES部分由我用Spring boot完成，前端和爬虫由队友完成。<br>","more":"</p>\n<h2 id=\"基于Elasticsearch集群的数据查询优化\"><a href=\"#基于Elasticsearch集群的数据查询优化\" class=\"headerlink\" title=\"基于Elasticsearch集群的数据查询优化\"></a>基于Elasticsearch集群的数据查询优化</h2><p>Elasticsearch是一个基于Lucene的分布式全文搜索引擎，能够横向扩展数以百计的服务器，存储PB级的数据，而且对每个字段都可以建立索引并且检索，并且可以在极短的时间内存储、搜索和分析大量的数据，程序员最爱的网站Github的搜索就是基于ES构建的，GitHub大约有30TB的索引文件数据，由此可见Elasticsearch（下文简称ES）强大的搜索功能。</p>\n<p>在此次的深度搜索引擎项目之中，虽然Elasticsearch也可以在一个节点上使用，该节点可以同时担任master node和data node，但是为了发挥Elasticsearch的分布式搜索的优势，在我们的深度搜索引擎中我们使用了三台服务器提供Elasticsearch的服务。下文将详细介绍从集群部署到优化查询的一些要点。</p>\n<h3 id=\"一、Elasticsearch的集群部署\"><a href=\"#一、Elasticsearch的集群部署\" class=\"headerlink\" title=\"一、Elasticsearch的集群部署\"></a>一、Elasticsearch的集群部署</h3><h4 id=\"1-ES概念简介\"><a href=\"#1-ES概念简介\" class=\"headerlink\" title=\"1. ES概念简介\"></a>1. ES概念简介</h4><p>Elasticsearch中有几个比较重要的概念，集群是指连接在一起的若干台服务器，不同的服务器承担不同的角色，一起提供服务。集群中有主节点、数据节点和客户端节点等。主节点负责管理整个集群，当群集的拓扑结构改变时把索引分片分派到相应的节点上，主节点是从可以担任主节点的节点中选举出来的。数据节点只负责存储数据，客户端节点在选举主节点过程中起作用。ES的分片是把索引信息分散到多个节点上，相当于一桶水用多个杯子装。副本是指索引信息的拷贝。</p>\n<p>在进行ES的配置时，首先要考虑节点数和分片数。通过实验，多节点的ES集群中的节点数至少为3，分片数为一倍的节点数量到两倍的节点数量。</p>\n<p>节点数和分片数相等时，每个节点负责一个分片的检索，ES集群的性能可以达到最优。对于一个3节点集群，为每个节点分配一个分片，总共3个分片。但是由于ES的不可变性的限制，系统无法对分片进行重新拆分分配，除非重新索引这个文件集合。但是我在三个节点的集群中再加入一个节点，这时候分片数量小于了节点数，在搜索上效率会降低，所以为了支持水平扩展，可以为集群分配比节点数更多的分片数，也就是说每个节点有多个分片。但是每个节点有多个分片时，需要考虑性能的问题，每个节点最好不要超过两个分片，</p>\n<p>我采用了官方给默认配置中分片数目为5，这样既可以拓展到5个节点，也可以保证性能。</p>\n<p>我的集群的其余配置如下图：</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">#节点集群名称和节点类型</span><br><span class=\"line\">cluster.name: yang-es-clusters</span><br><span class=\"line\">node.name: node-3</span><br><span class=\"line\">node.master: true</span><br><span class=\"line\">node.data: true</span><br><span class=\"line\">#同个集群其他节点的信息，ES通过广播的方式寻找同一集群的其他节点</span><br><span class=\"line\">discovery.zen.ping.unicast.hosts: [ \"0.0.0.0\", \"106.14.191.xxx\", \"120.79.191.xxx\"]</span><br><span class=\"line\">#选举主节点时需要由至少2个节点参与投票</span><br><span class=\"line\">discovery.zen.minimum_master_nodes: 2</span><br><span class=\"line\">gateway.recover_after_nodes: 1</span><br><span class=\"line\">#配置本节点的ip，默认开发9300端口用于节点间TCP通信</span><br><span class=\"line\">network.host: 0.0.0.0</span><br><span class=\"line\">network.publish_host: 106.14.227.30</span><br><span class=\"line\">network.bind_host: 0.0.0.0</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-Elsaticsearch集群至少需要有三个节点\"><a href=\"#2-Elsaticsearch集群至少需要有三个节点\" class=\"headerlink\" title=\"2. Elsaticsearch集群至少需要有三个节点\"></a>2. Elsaticsearch集群至少需要有三个节点</h4><p>上文写到我们组搭建的ES集群使用了三台服务器，这也是搭建ES集群所需的最少节点数，是因为需要防止ES集群发生脑裂。ES中维护索引状态最重要的节点是主节点，主节点是被投票选举出来的。</p>\n<h5 id=\"三个和尚投票\"><a href=\"#三个和尚投票\" class=\"headerlink\" title=\"三个和尚投票\"></a>三个和尚投票</h5><p>当主节点出现问题，从节点不能与主节点通信时，从节点会发起选举任命新的主节点，同时新的主节点会接管旧的主节点的所有工作，如果旧的主节点重新恢复并加入到集群中，新的主节点会将原来旧的主节点降级为从节点，这样就不会有冲突发生。所有这个过程都由ES自己处理，使用者无需任何参与。</p>\n<h5 id=\"两个和尚投票\"><a href=\"#两个和尚投票\" class=\"headerlink\" title=\"两个和尚投票\"></a>两个和尚投票</h5><p>但是，当只有两个节点的时候，一主（master）一从（slave），如果主从直接的通信出现问题时，从节点slave会自我提升为master，但是当恢复通信时，我们就会同时有两个master。因为此时，对于原来的主节点角度考虑，它认为是原来的从节点出现问题，现在仍然需要作为slave重新加入。这样，两个节点的时候，我们就出现了集群不知道将哪个节点选举为主节点的情况，也就是我们通常说的“分脑”。</p>\n<p>为了防止这种情况的发生，第三个节点的出现会打破平衡，解决冲突问题。</p>\n<h5 id=\"三个和尚仍然存在问题\"><a href=\"#三个和尚仍然存在问题\" class=\"headerlink\" title=\"三个和尚仍然存在问题\"></a>三个和尚仍然存在问题</h5><p>分脑的问题同样会出现在具有三或三个以上节点的集群中，为了降低发生的概率，ElasticSearch提供了一个配置 <code>discovery.zen.minimum_master_nodes</code>它规定了在选举新的master时，一个集群下最少需要的节点数。例如，一个3节点集群，这个数字为2，2个节点可以防止单个节点在脱离集群时，将其自己选举成master，相反，它会等待直到重新加入到集群中。这个数值可以通过一个公式确定：</p>\n<p>这里的配置是指当主节点宕掉掉时候至少同时需要几个节点才重新进行投票选举新的主节点，官方建议将此数目配置为<code>N / 2 + 1</code>，可以有效的防止脑裂。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure>\n<p>从图中分析可以得知，如果只有两个节点，当这两个节点通讯故障的时候，会各自选举自己为主节点，而当通讯恢复正常时候会发生冲突，这与区块链的思想不谋而合，只有控制了51%以上的节点，才可以掌控整个集群。</p>\n<p>我在配置ES的时候，主节点所在的服务器由于网络问题，经常会发生断网的现象，此时集群的状态会由绿色（正常）转变为红色（预警）状态，而当非主节点宕机的时候，集群状态会变为黄色（所有的主分片可用，但是副本分片不可用）。这个问题的解决方案只有一种，设置容易宕机的节点为数据节点，禁止其被选举为主节点。</p>\n<h3 id=\"二、Elasticsearch的查询参数优化\"><a href=\"#二、Elasticsearch的查询参数优化\" class=\"headerlink\" title=\"二、Elasticsearch的查询参数优化\"></a>二、Elasticsearch的查询参数优化</h3><h4 id=\"1-Lucene的打分模型\"><a href=\"#1-Lucene的打分模型\" class=\"headerlink\" title=\"1. Lucene的打分模型\"></a>1. Lucene的打分模型</h4><p><img src=\"http://www.biaodianfu.com/wp-content/uploads/2016/09/lucene-tf-idf.png\" alt=\"lucene-tf-idf\"></p>\n<p>由于ES是基于Lucene，所以ES也是使用的打分机制。通过上面的公式，一篇文档的分数实际上是由查询语句q和文档d作为变量的一个函数值。打分公式中有两部分不直接依赖于查询词，它们是coord和queryNorm。公式的值是这样计算的，coord和queryNorm两大部分直接乘以查询语句中每个查询词计算值的总和。另一方面，这个总和也是由每个查询词的词频(tf)，逆文档频率(idf)，查询词的权重，还有norm，也就是前面说的length norm相乘而得的结果。</p>\n<p>从中可以得出以下几条规则：</p>\n<ul>\n<li>匹配到的关键词越稀有，文档的得分就越高。</li>\n<li>文档的域越小(包含比较少的Term)，文档的得分就越高。</li>\n<li>设置的权重(索引和搜索时设置的都可以)越大，文档得分越高。</li>\n</ul>\n<p>随着Lucene的发展，打分模型也引入了新的相似度模型，并且可以在ES中指定，现在比较流行的是Okapi BM25，Divergence from randomness和Information based。</p>\n<p>BM25是基于概率模型的相似度模型，适合处理短文本，关键词的重复次数对整个文档得分影响比较大。DFR和IB比较类似，基于同名概率模型，适用于自然语言类的文本。我们的搜索引擎要搜索的字段比较少，内容也是以短文本为主，并且倾向于能够对名字和标签进行准确匹配，如果关键词在内容中多次重复，明显词条是用户所查询的结果，所以BM25更加适合我们的搜索引擎。</p>\n<h4 id=\"2-分词器的选择\"><a href=\"#2-分词器的选择\" class=\"headerlink\" title=\"2. 分词器的选择\"></a>2. 分词器的选择</h4><p>ES是基于词的搜索引擎，其能够快速的通过搜索词检索出对应的文章归功于倒排索引，使用不同的分词器对于检索效果也有重大影响。</p>\n<p>ES的默认分词器对英文句子的切割效果比较好，但用于中文句子的分割时，只会将句子分割成孤立的一个个的字，所以需要指定建立索引时的分词器和搜索分词器。我们使用的是IKAnalyzer，是目前比较流行的中文分词器之一,设置比较简单,稳定。</p>\n<p>在Sprint Boot中建立索引时候，对ES的支持度不如直接在ES里面自己建立索引可操作性高，以下是我建立索引的代码。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST http://106.14.227.30:9200/chageng/EntryDb/_mapping -H 'Content-Type:application/json' -d' &#123; \"EntryDb\": &#123; \"properties\": &#123;</span><br><span class=\"line\">    \"content\": &#123;</span><br><span class=\"line\">        \"type\": \"text\",</span><br><span class=\"line\">        \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">        \"search_analyzer\": \"ik_smart\",</span><br><span class=\"line\">        \"fields\": &#123;</span><br><span class=\"line\">            \"keyword\": &#123;</span><br><span class=\"line\">                \"type\": \"text\",</span><br><span class=\"line\">                \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">                \"search_analyzer\": \"ik_smart\"</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    \"imageList\": &#123;</span><br><span class=\"line\">        \"type\": \"text\",</span><br><span class=\"line\">        \"fields\": &#123;</span><br><span class=\"line\">            \"keyword\": &#123;</span><br><span class=\"line\">                \"type\": \"keyword\",</span><br><span class=\"line\">                \"ignore_above\": 256</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    \"like\": &#123;</span><br><span class=\"line\">        \"type\": \"long\"</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    \"name\": &#123;</span><br><span class=\"line\">        \"type\": \"text\",</span><br><span class=\"line\">        \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">        \"search_analyzer\": \"ik_smart\",</span><br><span class=\"line\">        \"fields\": &#123;</span><br><span class=\"line\">            \"keyword\": &#123;</span><br><span class=\"line\">                \"type\": \"text\",</span><br><span class=\"line\">                \"analyzer\": \"ik_max_word\",</span><br><span class=\"line\">                \"search_analyzer\": \"ik_smart\"</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-查询语句的优化\"><a href=\"#3-查询语句的优化\" class=\"headerlink\" title=\"3. 查询语句的优化\"></a>3. 查询语句的优化</h4><h5 id=\"3-1-term、match与multi-match\"><a href=\"#3-1-term、match与multi-match\" class=\"headerlink\" title=\"3.1 term、match与multi_match\"></a>3.1 term、match与multi_match</h5><p>ES中的term是代表完全匹配，也就是精确查询，搜索前不会再对搜索词进行分词，所以我们的搜索词必须是文档分词集合中的一个。以下代码将会在name中精确匹配为“小鸡快跑”的词条。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"query\"</span>:&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"term\"</span>:&#123;</span><br><span class=\"line\">        <span class=\"attr\">\"name\"</span>:<span class=\"string\">\"小鸡快跑\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<p>ES的match搜索会先对搜索词进行分词，对于最基本的match搜索来说，只要搜索词的分词集合中的一个或多个存在于文档中即可，例如，当我们搜索<code>小鸡快跑</code>，搜索词会先分词为<code>小鸡</code>和<code>快跑</code>,只要文档中包含<code>小鸡</code>和<code>快跑</code>任意一个词，都会被搜索到。</p>\n<p>如果文档1中有<code>小鸡</code>，文档2中有<code>快跑</code>，那么这两个文档都会被检索到，而如果文档3中有<code>小鸡</code>和<code>快跑</code>两个词，文档3也将被返回，并且文档3将被排在首位。所有被返回的文档将依靠_score的分数进行排序，得分的算法参考上文。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"content\"</span>: <span class=\"string\">\"小鸡快跑\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<p>ES的multi_match是对多个字段进行匹配，其中一个字段包含分词，该文档即可被搜索到并且返回。在实际使用中用的比较多。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\"><span class=\"attr\">\"bool\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"must\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"社交\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"should\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"multi_match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"query\"</span>: <span class=\"string\">\"吓得我瓜子都掉了\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"best_fields\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">                <span class=\"string\">\"name^2\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"content\"</span></span><br><span class=\"line\">            ],</span><br><span class=\"line\">\t          <span class=\"attr\">\"fuzziness\"</span>: <span class=\"string\">\"AUTO\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"tie_breaker\"</span>: <span class=\"number\">0.4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"minimum_should_match\"</span>: <span class=\"string\">\"30%\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">'</span><br></pre></td></tr></table></figure>\n<h5 id=\"3-2-组合过滤器bool\"><a href=\"#3-2-组合过滤器bool\" class=\"headerlink\" title=\"3.2 组合过滤器bool\"></a>3.2 组合过滤器bool</h5><p> <code>bool</code> 过滤器通过 <code>and</code> 、 <code>or</code> 和 <code>not</code> 逻辑组合将多个过滤器进行组合。<code>bool</code> 查询可以接受 <code>must</code> 、 <code>must_not</code> 和 <code>should</code> 参数下的多个查询语句，对查询结果进行筛选，分别对应<code>AND NOT OR</code>。<code>bool</code> 查询会为每个文档计算相关度评分 <code>_score</code> ， 再将所有匹配的 <code>must</code> 和 <code>should</code> 语句的分数 <code>_score</code> 求和，最后除以 <code>must</code> 和 <code>should</code> 语句的总数。</p>\n<p><code>must_not</code> 语句不会影响评分； 它的作用只是将不相关的文档排除。</p>\n<p><code>should</code>过滤的数量是由<code>minimum_should_match</code>参数来进行控制，该参数可以是百分比，也可以是一个数字，我在多次实验后发现40%的效果最好。</p>\n<p>以下是bool的基本用法。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\"><span class=\"attr\">\"bool\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"must\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"游戏\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"should\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"multi_match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"query\"</span>: <span class=\"string\">\"秦王\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"best_fields\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">                <span class=\"string\">\"name^5\"</span>,</span><br><span class=\"line\">              \t<span class=\"string\">\"tagList^2\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"content^1\"</span></span><br><span class=\"line\">            ],</span><br><span class=\"line\">            <span class=\"attr\">\"tie_breaker\"</span>: <span class=\"number\">0.4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"minimum_should_match\"</span>: <span class=\"string\">\"40%\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"filter\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"range\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"time\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"gte\"</span>: <span class=\"string\">\"2012-09-09\"</span>,</span><br><span class=\"line\">                <span class=\"attr\">\"lt\"</span>: <span class=\"string\">\"2019-09-09\"</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h5 id=\"3-3-boost权重控制\"><a href=\"#3-3-boost权重控制\" class=\"headerlink\" title=\"3.3 boost权重控制\"></a>3.3 boost权重控制</h5><p>在多字段匹配中，我在name tagList 和 content字段中对内容进行查询，但是想让name字段拥有有更高的权重，可以通过指定 <code>boost</code> 来控制任何查询语句的相对的权重， <code>boost</code> 的默认值为 <code>1</code> ，大于 <code>1</code> 会提升一个语句的相对权重。基本使用见上条ES语句。</p>\n<p>基于 TF/IDF 的评分模型中，如果使用了<code>boost</code>改变权重，新的评分 <code>_score</code> 会在应用权重提升之后进行归一化处理 ，并不是线性的变化。</p>\n<h5 id=\"3-4-模糊匹配\"><a href=\"#3-4-模糊匹配\" class=\"headerlink\" title=\"3.4 模糊匹配\"></a>3.4 模糊匹配</h5><p>模糊查询的工作原理是给定原始词项及构造一个编辑自动机— 像表示所有原始字符串指定编辑距离的字符串的一个大图表。然后模糊查询使用这个自动机依次高效遍历词典中的所有词项以确定是否匹配。 一旦收集了词典中存在的所有匹配项，就可以计算匹配文档列表。在搜索巨大文档时候，模糊匹配的效率很低，故可以用以下两个参数限制对性能的影响，prefix_length为不能被 “模糊化” 的初始字符数，建议设置为了3，max_expansions限制产生的模糊选项的总数量。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"multi_match\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"query\"</span>: <span class=\"string\">\"吓得我瓜子都掉了\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"best_fields\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">                <span class=\"string\">\"name^2\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"content\"</span></span><br><span class=\"line\">            ],</span><br><span class=\"line\">            <span class=\"attr\">\"fuzziness\"</span>: <span class=\"string\">\"AUTO\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"tie_breaker\"</span>: <span class=\"number\">0.4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"minimum_should_match\"</span>: <span class=\"string\">\"40%\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h5 id=\"3-5-随机评分\"><a href=\"#3-5-随机评分\" class=\"headerlink\" title=\"3.5 随机评分\"></a>3.5 随机评分</h5><p>我们的搜索词条结果集中有很多点赞数一样的词条，在指定按点赞数排序这种方式后，有相同评分 <code>_score</code> 的文档会每次都以相同次序出现，为了提高展现率，可以引入一些随机性，保证有相同评分的文档都能有均等相似的展现机率。</p>\n<p>每个用户看到不同的随机次序，但也同时希望如果是同一用户翻页浏览时，结果的相对次序能始终保持一致。这种行为被称为 一致随机（consistently random） 。</p>\n<p>引用：<a href=\"https://www.elastic.co/guide/cn/elasticsearch/guide/current/random-scoring.html\" target=\"_blank\" rel=\"noopener\">https://www.elastic.co/guide/cn/elasticsearch/guide/current/random-scoring.html</a></p>\n<p>以下是样例：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"function_score\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"filter\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match\"</span>: &#123; <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"小鸡快跑\"</span> &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"functions\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"filter\"</span>: &#123; <span class=\"attr\">\"term\"</span>: &#123; <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"小鸡\"</span> &#125;&#125;,</span><br><span class=\"line\">          <span class=\"attr\">\"weight\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"filter\"</span>: &#123; <span class=\"attr\">\"term\"</span>: &#123; <span class=\"attr\">\"tagList\"</span>: <span class=\"string\">\"游戏\"</span> &#125;&#125;,</span><br><span class=\"line\">          <span class=\"attr\">\"weight\"</span>: <span class=\"number\">2</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"random_score\"</span>: &#123; </span><br><span class=\"line\">            <span class=\"attr\">\"seed\"</span>:  <span class=\"string\">\"the users session id\"</span> </span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"score_mode\"</span>: <span class=\"string\">\"sum\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"三、Elasticsearch性能问题\"><a href=\"#三、Elasticsearch性能问题\" class=\"headerlink\" title=\"三、Elasticsearch性能问题\"></a>三、Elasticsearch性能问题</h3><h4 id=\"1-数据预热\"><a href=\"#1-数据预热\" class=\"headerlink\" title=\"1. 数据预热:\"></a>1. 数据预热:</h4><p>ES可以在查询前进行预热，将查询中十分依赖的字段的数据加载出来，可以使用Elasticsearch为类型和索引定义预热查询。</p>\n<p>定义一个新的预热查询，和普通查询没什么区别，只是它存储在Elasticsearch一个特殊的名为_warmer的索引中，以下是我的预热查询。</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -XPUT '106.14.227.30: 9200/chageng/_warmer?pretty' -H 'Content-Type: application/json' -d '</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"match_all\"</span>: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"facets\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"warming_facet\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"terms\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"field\"</span>: <span class=\"string\">\"name\"</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;'</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-优化索引\"><a href=\"#2-优化索引\" class=\"headerlink\" title=\"2. 优化索引\"></a>2. 优化索引</h4><p>我建立的索引，每个词条都包含较多的内容，不仅包括了该词条的基本信息（name，tag，content，view，like），还包括了从微博、B站、谷歌等地方爬取到的相关信息，每个词条中包含的数据比较多，对完整的词条建立索引，每次的查询速度与在mongodb里面检索持平，在做自动补全时能够有肉眼可见的延迟。</p>\n<p>出现查询速度过慢的情况有两方面的原因。第一是建立的索引包含的内容过多，比如微博、B站的数据大约是该词条的基本信息的25倍以上，而这些微博、B站的信息我们在做检索的时候并不需要对这些字段进行检索，这些无效的信息拖累了检索速度。第二是网络传输延迟，因为我们的ES集群和我们的搜索引擎服务并不在同一个机器上面，他们之间是通过网络进行通信，由于每条词条包含数据比较大，所以如果查询结果中有上百条的数据被命中，返回这些数据时需要比较多的时间。</p>\n<p>我们的解决方案是建立两个索引，第一个索引存储词条的基本信息，第二个索引存储词条的所有信息，但使用检索功能的时候，我们只需要在第一个索引中检索，将词条的基本信息返回呈现给用户，这样可以大大加快速度。为了将速度优化到极致，在不影响用户正常使用的情况下，我们又对搜索结果的数量进行了限制，每次只返回当前页面要展现的搜索条目，最快的呈现给用户结果，其余的搜索结果用异步的方式加载。当用户进入词条详细页面时，我们可以通过该词条的id，到ES中的第二个索引中查找该id词条的所有信息进行返回，这样的检索速度能够提升到28倍。</p>\n<h4 id=\"3-优化存储\"><a href=\"#3-优化存储\" class=\"headerlink\" title=\"3. 优化存储\"></a>3. 优化存储</h4><p>上文提到索引可以存储到ES中，这样的查询效率最高，那具体的数据可以存储到MySQL、MongoDb，ES三种数据库中，考虑到我们的数据类型以json文件为主，MySQL需要建立多张表来实现关系间的映射，故不做考虑。</p>\n<p>我对MongoDb存储词条的所有信息，与直接用ES存储所有的信息进行检索做了一个对比，发现两者在检索10000条数据运行时间上并没有太大差异，所以直接使用ES进行存储了所有的数据。</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"ck2a2ug0a0001viwqfyyax6ai","category_id":"ck2a2ug0k0003viwqs8c1bs5b","_id":"ck2a2ug0p0006viwq8oh0mrc6"},{"post_id":"ck2a2ug1a000bviwqq2i4qded","category_id":"ck2a2ug1c000cviwq0ivvynbm","_id":"ck2a2ug1e000fviwqaznf3gj7"},{"post_id":"ck2a2ug2a000iviwq952gugjz","category_id":"ck2a2ug0k0003viwqs8c1bs5b","_id":"ck2a2ug2f000lviwqluqgds4g"}],"PostTag":[{"post_id":"ck2a2ug0a0001viwqfyyax6ai","tag_id":"ck2a2ug0m0004viwqx2fmd9ya","_id":"ck2a2ug0r0008viwqyannok41"},{"post_id":"ck2a2ug0a0001viwqfyyax6ai","tag_id":"ck2a2ug0n0005viwqcji9iqa8","_id":"ck2a2ug0s0009viwqts7hn6lu"},{"post_id":"ck2a2ug0a0001viwqfyyax6ai","tag_id":"ck2a2ug0p0007viwqlzpssmbt","_id":"ck2a2ug0s000aviwq11hfwejr"},{"post_id":"ck2a2ug1a000bviwqq2i4qded","tag_id":"ck2a2ug1c000dviwqiu9elrr4","_id":"ck2a2ug1e000gviwq0hlbny1h"},{"post_id":"ck2a2ug1a000bviwqq2i4qded","tag_id":"ck2a2ug1d000eviwqufpn7n1q","_id":"ck2a2ug1f000hviwqxjrkyq6r"},{"post_id":"ck2a2ug2a000iviwq952gugjz","tag_id":"ck2a2ug0m0004viwqx2fmd9ya","_id":"ck2a2ug2f000jviwqork1g905"},{"post_id":"ck2a2ug2a000iviwq952gugjz","tag_id":"ck2a2ug0n0005viwqcji9iqa8","_id":"ck2a2ug2f000kviwqdk5ek66a"},{"post_id":"ck2a2ug2a000iviwq952gugjz","tag_id":"ck2a2ug0p0007viwqlzpssmbt","_id":"ck2a2ug2h000mviwq20o6izl2"}],"Tag":[{"name":"Java","_id":"ck2a2ug0m0004viwqx2fmd9ya"},{"name":"Sprint boot","_id":"ck2a2ug0n0005viwqcji9iqa8"},{"name":"Elasticsearch","_id":"ck2a2ug0p0007viwqlzpssmbt"},{"name":"paper","_id":"ck2a2ug1c000dviwqiu9elrr4"},{"name":"Db","_id":"ck2a2ug1d000eviwqufpn7n1q"}]}}